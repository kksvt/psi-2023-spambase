{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec728380",
   "metadata": {},
   "source": [
    "## Spambase Dataset\n",
    "Dataset pochodzi z [kaggle](https://www.kaggle.com/datasets/somesh24/spambase) i składa się z różnych statystyk wygenerowanych z otrzymanych maili (głównie z procentowej zawartości wybranych słów i specjalnych znaków) oraz z etykietą mówiącą o tym, czy dany e-mail jest klasyfikowany jako spam, czy też nie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a37f75af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_freq_make</th>\n",
       "      <th>word_freq_address</th>\n",
       "      <th>word_freq_all</th>\n",
       "      <th>word_freq_3d</th>\n",
       "      <th>word_freq_our</th>\n",
       "      <th>word_freq_over</th>\n",
       "      <th>word_freq_remove</th>\n",
       "      <th>word_freq_internet</th>\n",
       "      <th>word_freq_order</th>\n",
       "      <th>word_freq_mail</th>\n",
       "      <th>...</th>\n",
       "      <th>char_freq_%3B</th>\n",
       "      <th>char_freq_%28</th>\n",
       "      <th>char_freq_%5B</th>\n",
       "      <th>char_freq_%21</th>\n",
       "      <th>char_freq_%24</th>\n",
       "      <th>char_freq_%23</th>\n",
       "      <th>capital_run_length_average</th>\n",
       "      <th>capital_run_length_longest</th>\n",
       "      <th>capital_run_length_total</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.756</td>\n",
       "      <td>61</td>\n",
       "      <td>278</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.048</td>\n",
       "      <td>5.114</td>\n",
       "      <td>101</td>\n",
       "      <td>1028</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.010</td>\n",
       "      <td>9.821</td>\n",
       "      <td>485</td>\n",
       "      <td>2259</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   word_freq_make  word_freq_address  word_freq_all  word_freq_3d   \n",
       "0            0.00               0.64           0.64           0.0  \\\n",
       "1            0.21               0.28           0.50           0.0   \n",
       "2            0.06               0.00           0.71           0.0   \n",
       "3            0.00               0.00           0.00           0.0   \n",
       "4            0.00               0.00           0.00           0.0   \n",
       "\n",
       "   word_freq_our  word_freq_over  word_freq_remove  word_freq_internet   \n",
       "0           0.32            0.00              0.00                0.00  \\\n",
       "1           0.14            0.28              0.21                0.07   \n",
       "2           1.23            0.19              0.19                0.12   \n",
       "3           0.63            0.00              0.31                0.63   \n",
       "4           0.63            0.00              0.31                0.63   \n",
       "\n",
       "   word_freq_order  word_freq_mail  ...  char_freq_%3B  char_freq_%28   \n",
       "0             0.00            0.00  ...           0.00          0.000  \\\n",
       "1             0.00            0.94  ...           0.00          0.132   \n",
       "2             0.64            0.25  ...           0.01          0.143   \n",
       "3             0.31            0.63  ...           0.00          0.137   \n",
       "4             0.31            0.63  ...           0.00          0.135   \n",
       "\n",
       "   char_freq_%5B  char_freq_%21  char_freq_%24  char_freq_%23   \n",
       "0            0.0          0.778          0.000          0.000  \\\n",
       "1            0.0          0.372          0.180          0.048   \n",
       "2            0.0          0.276          0.184          0.010   \n",
       "3            0.0          0.137          0.000          0.000   \n",
       "4            0.0          0.135          0.000          0.000   \n",
       "\n",
       "   capital_run_length_average  capital_run_length_longest   \n",
       "0                       3.756                          61  \\\n",
       "1                       5.114                         101   \n",
       "2                       9.821                         485   \n",
       "3                       3.537                          40   \n",
       "4                       3.537                          40   \n",
       "\n",
       "   capital_run_length_total  class  \n",
       "0                       278      1  \n",
       "1                      1028      1  \n",
       "2                      2259      1  \n",
       "3                       191      1  \n",
       "4                       191      1  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataset = pd.read_csv('spambase_csv.csv')\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844436eb",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f98d937",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4601 entries, 0 to 4600\n",
      "Data columns (total 58 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   word_freq_make              4601 non-null   float64\n",
      " 1   word_freq_address           4601 non-null   float64\n",
      " 2   word_freq_all               4601 non-null   float64\n",
      " 3   word_freq_3d                4601 non-null   float64\n",
      " 4   word_freq_our               4601 non-null   float64\n",
      " 5   word_freq_over              4601 non-null   float64\n",
      " 6   word_freq_remove            4601 non-null   float64\n",
      " 7   word_freq_internet          4601 non-null   float64\n",
      " 8   word_freq_order             4601 non-null   float64\n",
      " 9   word_freq_mail              4601 non-null   float64\n",
      " 10  word_freq_receive           4601 non-null   float64\n",
      " 11  word_freq_will              4601 non-null   float64\n",
      " 12  word_freq_people            4601 non-null   float64\n",
      " 13  word_freq_report            4601 non-null   float64\n",
      " 14  word_freq_addresses         4601 non-null   float64\n",
      " 15  word_freq_free              4601 non-null   float64\n",
      " 16  word_freq_business          4601 non-null   float64\n",
      " 17  word_freq_email             4601 non-null   float64\n",
      " 18  word_freq_you               4601 non-null   float64\n",
      " 19  word_freq_credit            4601 non-null   float64\n",
      " 20  word_freq_your              4601 non-null   float64\n",
      " 21  word_freq_font              4601 non-null   float64\n",
      " 22  word_freq_000               4601 non-null   float64\n",
      " 23  word_freq_money             4601 non-null   float64\n",
      " 24  word_freq_hp                4601 non-null   float64\n",
      " 25  word_freq_hpl               4601 non-null   float64\n",
      " 26  word_freq_george            4601 non-null   float64\n",
      " 27  word_freq_650               4601 non-null   float64\n",
      " 28  word_freq_lab               4601 non-null   float64\n",
      " 29  word_freq_labs              4601 non-null   float64\n",
      " 30  word_freq_telnet            4601 non-null   float64\n",
      " 31  word_freq_857               4601 non-null   float64\n",
      " 32  word_freq_data              4601 non-null   float64\n",
      " 33  word_freq_415               4601 non-null   float64\n",
      " 34  word_freq_85                4601 non-null   float64\n",
      " 35  word_freq_technology        4601 non-null   float64\n",
      " 36  word_freq_1999              4601 non-null   float64\n",
      " 37  word_freq_parts             4601 non-null   float64\n",
      " 38  word_freq_pm                4601 non-null   float64\n",
      " 39  word_freq_direct            4601 non-null   float64\n",
      " 40  word_freq_cs                4601 non-null   float64\n",
      " 41  word_freq_meeting           4601 non-null   float64\n",
      " 42  word_freq_original          4601 non-null   float64\n",
      " 43  word_freq_project           4601 non-null   float64\n",
      " 44  word_freq_re                4601 non-null   float64\n",
      " 45  word_freq_edu               4601 non-null   float64\n",
      " 46  word_freq_table             4601 non-null   float64\n",
      " 47  word_freq_conference        4601 non-null   float64\n",
      " 48  char_freq_%3B               4601 non-null   float64\n",
      " 49  char_freq_%28               4601 non-null   float64\n",
      " 50  char_freq_%5B               4601 non-null   float64\n",
      " 51  char_freq_%21               4601 non-null   float64\n",
      " 52  char_freq_%24               4601 non-null   float64\n",
      " 53  char_freq_%23               4601 non-null   float64\n",
      " 54  capital_run_length_average  4601 non-null   float64\n",
      " 55  capital_run_length_longest  4601 non-null   int64  \n",
      " 56  capital_run_length_total    4601 non-null   int64  \n",
      " 57  class                       4601 non-null   int64  \n",
      "dtypes: float64(55), int64(3)\n",
      "memory usage: 2.0 MB\n"
     ]
    }
   ],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f8d895a",
   "metadata": {},
   "source": [
    "\"Niestety\" *dataset* nie zawiera żadnych kolumn z wartościami *nullowymi*, więc musimy sami stworzyć luki. Ustawmy najpierw *seed*, z którego będziemy korzystać w całym projekcie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d70af42",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1337"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfbca9a7",
   "metadata": {},
   "source": [
    "Mamy 4601 wierszy oraz 57 interesujących nas wartości w każdej (nie chcę tworzyć luk w etykietach), tj. łącznie *262,257* wartości. Powiedzmy, że chcemy, aby ok. 5% komórek było wypełnionych *NaN*ami."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53aed27c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[65538, 6, 262153, 262154, 131082, 98321, 32785, 65556, 32791, 163873]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "data = dataset.drop(columns=['class'])\n",
    "labels = dataset['class']\n",
    "\n",
    "random.seed(seed)\n",
    "\n",
    "num_columns = data.shape[1]\n",
    "num_rows = data.shape[0]\n",
    "total = num_rows * num_columns\n",
    "n = total // 20\n",
    "numbers = set()\n",
    "while len(numbers) < n:\n",
    "    numbers.add(random.randint(0, total))\n",
    "numbers = list(numbers)\n",
    "numbers[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c11d49",
   "metadata": {},
   "source": [
    "Każdą wylosowaną liczbę będziemy teraz konwertowali na odpowiedni indeks w datasecie. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b133f573",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_freq_make</th>\n",
       "      <th>word_freq_address</th>\n",
       "      <th>word_freq_all</th>\n",
       "      <th>word_freq_3d</th>\n",
       "      <th>word_freq_our</th>\n",
       "      <th>word_freq_over</th>\n",
       "      <th>word_freq_remove</th>\n",
       "      <th>word_freq_internet</th>\n",
       "      <th>word_freq_order</th>\n",
       "      <th>word_freq_mail</th>\n",
       "      <th>...</th>\n",
       "      <th>word_freq_conference</th>\n",
       "      <th>char_freq_%3B</th>\n",
       "      <th>char_freq_%28</th>\n",
       "      <th>char_freq_%5B</th>\n",
       "      <th>char_freq_%21</th>\n",
       "      <th>char_freq_%24</th>\n",
       "      <th>char_freq_%23</th>\n",
       "      <th>capital_run_length_average</th>\n",
       "      <th>capital_run_length_longest</th>\n",
       "      <th>capital_run_length_total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.756</td>\n",
       "      <td>61.0</td>\n",
       "      <td>278.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.048</td>\n",
       "      <td>5.114</td>\n",
       "      <td>101.0</td>\n",
       "      <td>1028.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.010</td>\n",
       "      <td>9.821</td>\n",
       "      <td>485.0</td>\n",
       "      <td>2259.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40.0</td>\n",
       "      <td>191.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40.0</td>\n",
       "      <td>191.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   word_freq_make  word_freq_address  word_freq_all  word_freq_3d   \n",
       "0            0.00               0.64           0.64           0.0  \\\n",
       "1            0.21               0.28           0.50           0.0   \n",
       "2            0.06               0.00           0.71           0.0   \n",
       "3            0.00               0.00           0.00           0.0   \n",
       "4            0.00               0.00           0.00           0.0   \n",
       "\n",
       "   word_freq_our  word_freq_over  word_freq_remove  word_freq_internet   \n",
       "0           0.32            0.00               NaN                0.00  \\\n",
       "1           0.14            0.28               NaN                0.07   \n",
       "2           1.23            0.19              0.19                0.12   \n",
       "3            NaN            0.00              0.31                0.63   \n",
       "4           0.63            0.00              0.31                0.63   \n",
       "\n",
       "   word_freq_order  word_freq_mail  ...  word_freq_conference  char_freq_%3B   \n",
       "0             0.00            0.00  ...                   0.0           0.00  \\\n",
       "1             0.00            0.94  ...                   NaN            NaN   \n",
       "2             0.64            0.25  ...                   0.0           0.01   \n",
       "3             0.31            0.63  ...                   0.0           0.00   \n",
       "4             0.31            0.63  ...                   0.0           0.00   \n",
       "\n",
       "   char_freq_%28  char_freq_%5B  char_freq_%21  char_freq_%24  char_freq_%23   \n",
       "0          0.000            0.0          0.778          0.000            NaN  \\\n",
       "1          0.132            0.0          0.372          0.180          0.048   \n",
       "2          0.143            0.0          0.276          0.184          0.010   \n",
       "3          0.137            0.0          0.137          0.000          0.000   \n",
       "4            NaN            0.0          0.135          0.000          0.000   \n",
       "\n",
       "   capital_run_length_average  capital_run_length_longest   \n",
       "0                       3.756                        61.0  \\\n",
       "1                       5.114                       101.0   \n",
       "2                       9.821                       485.0   \n",
       "3                       3.537                        40.0   \n",
       "4                       3.537                        40.0   \n",
       "\n",
       "   capital_run_length_total  \n",
       "0                     278.0  \n",
       "1                    1028.0  \n",
       "2                    2259.0  \n",
       "3                     191.0  \n",
       "4                     191.0  \n",
       "\n",
       "[5 rows x 57 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "for number in numbers:\n",
    "    row, column = number // num_columns, number % num_columns\n",
    "    data.iat[row, column] = np.nan\n",
    "    \n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "947f380d",
   "metadata": {},
   "source": [
    "Ponownie sprawdźmy liczbę *null*i:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3407235d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4601 entries, 0 to 4600\n",
      "Data columns (total 57 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   word_freq_make              4383 non-null   float64\n",
      " 1   word_freq_address           4359 non-null   float64\n",
      " 2   word_freq_all               4343 non-null   float64\n",
      " 3   word_freq_3d                4367 non-null   float64\n",
      " 4   word_freq_our               4385 non-null   float64\n",
      " 5   word_freq_over              4382 non-null   float64\n",
      " 6   word_freq_remove            4381 non-null   float64\n",
      " 7   word_freq_internet          4368 non-null   float64\n",
      " 8   word_freq_order             4388 non-null   float64\n",
      " 9   word_freq_mail              4369 non-null   float64\n",
      " 10  word_freq_receive           4402 non-null   float64\n",
      " 11  word_freq_will              4339 non-null   float64\n",
      " 12  word_freq_people            4376 non-null   float64\n",
      " 13  word_freq_report            4380 non-null   float64\n",
      " 14  word_freq_addresses         4353 non-null   float64\n",
      " 15  word_freq_free              4397 non-null   float64\n",
      " 16  word_freq_business          4371 non-null   float64\n",
      " 17  word_freq_email             4365 non-null   float64\n",
      " 18  word_freq_you               4359 non-null   float64\n",
      " 19  word_freq_credit            4362 non-null   float64\n",
      " 20  word_freq_your              4400 non-null   float64\n",
      " 21  word_freq_font              4372 non-null   float64\n",
      " 22  word_freq_000               4373 non-null   float64\n",
      " 23  word_freq_money             4386 non-null   float64\n",
      " 24  word_freq_hp                4372 non-null   float64\n",
      " 25  word_freq_hpl               4367 non-null   float64\n",
      " 26  word_freq_george            4392 non-null   float64\n",
      " 27  word_freq_650               4385 non-null   float64\n",
      " 28  word_freq_lab               4377 non-null   float64\n",
      " 29  word_freq_labs              4360 non-null   float64\n",
      " 30  word_freq_telnet            4361 non-null   float64\n",
      " 31  word_freq_857               4361 non-null   float64\n",
      " 32  word_freq_data              4353 non-null   float64\n",
      " 33  word_freq_415               4386 non-null   float64\n",
      " 34  word_freq_85                4373 non-null   float64\n",
      " 35  word_freq_technology        4354 non-null   float64\n",
      " 36  word_freq_1999              4349 non-null   float64\n",
      " 37  word_freq_parts             4380 non-null   float64\n",
      " 38  word_freq_pm                4360 non-null   float64\n",
      " 39  word_freq_direct            4379 non-null   float64\n",
      " 40  word_freq_cs                4376 non-null   float64\n",
      " 41  word_freq_meeting           4373 non-null   float64\n",
      " 42  word_freq_original          4385 non-null   float64\n",
      " 43  word_freq_project           4363 non-null   float64\n",
      " 44  word_freq_re                4368 non-null   float64\n",
      " 45  word_freq_edu               4370 non-null   float64\n",
      " 46  word_freq_table             4353 non-null   float64\n",
      " 47  word_freq_conference        4362 non-null   float64\n",
      " 48  char_freq_%3B               4360 non-null   float64\n",
      " 49  char_freq_%28               4372 non-null   float64\n",
      " 50  char_freq_%5B               4350 non-null   float64\n",
      " 51  char_freq_%21               4373 non-null   float64\n",
      " 52  char_freq_%24               4383 non-null   float64\n",
      " 53  char_freq_%23               4340 non-null   float64\n",
      " 54  capital_run_length_average  4398 non-null   float64\n",
      " 55  capital_run_length_longest  4375 non-null   float64\n",
      " 56  capital_run_length_total    4375 non-null   float64\n",
      "dtypes: float64(57)\n",
      "memory usage: 2.0 MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a41a118b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_freq_make</th>\n",
       "      <th>word_freq_address</th>\n",
       "      <th>word_freq_all</th>\n",
       "      <th>word_freq_3d</th>\n",
       "      <th>word_freq_our</th>\n",
       "      <th>word_freq_over</th>\n",
       "      <th>word_freq_remove</th>\n",
       "      <th>word_freq_internet</th>\n",
       "      <th>word_freq_order</th>\n",
       "      <th>word_freq_mail</th>\n",
       "      <th>word_freq_receive</th>\n",
       "      <th>word_freq_will</th>\n",
       "      <th>word_freq_people</th>\n",
       "      <th>word_freq_report</th>\n",
       "      <th>word_freq_addresses</th>\n",
       "      <th>word_freq_free</th>\n",
       "      <th>word_freq_business</th>\n",
       "      <th>word_freq_email</th>\n",
       "      <th>word_freq_you</th>\n",
       "      <th>word_freq_credit</th>\n",
       "      <th>word_freq_your</th>\n",
       "      <th>word_freq_font</th>\n",
       "      <th>word_freq_000</th>\n",
       "      <th>word_freq_money</th>\n",
       "      <th>word_freq_hp</th>\n",
       "      <th>word_freq_hpl</th>\n",
       "      <th>word_freq_george</th>\n",
       "      <th>word_freq_650</th>\n",
       "      <th>word_freq_lab</th>\n",
       "      <th>word_freq_labs</th>\n",
       "      <th>word_freq_telnet</th>\n",
       "      <th>word_freq_857</th>\n",
       "      <th>word_freq_data</th>\n",
       "      <th>word_freq_415</th>\n",
       "      <th>word_freq_85</th>\n",
       "      <th>word_freq_technology</th>\n",
       "      <th>word_freq_1999</th>\n",
       "      <th>word_freq_parts</th>\n",
       "      <th>word_freq_pm</th>\n",
       "      <th>word_freq_direct</th>\n",
       "      <th>word_freq_cs</th>\n",
       "      <th>word_freq_meeting</th>\n",
       "      <th>word_freq_original</th>\n",
       "      <th>word_freq_project</th>\n",
       "      <th>word_freq_re</th>\n",
       "      <th>word_freq_edu</th>\n",
       "      <th>word_freq_table</th>\n",
       "      <th>word_freq_conference</th>\n",
       "      <th>char_freq_%3B</th>\n",
       "      <th>char_freq_%28</th>\n",
       "      <th>char_freq_%5B</th>\n",
       "      <th>char_freq_%21</th>\n",
       "      <th>char_freq_%24</th>\n",
       "      <th>char_freq_%23</th>\n",
       "      <th>capital_run_length_average</th>\n",
       "      <th>capital_run_length_longest</th>\n",
       "      <th>capital_run_length_total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4383.000000</td>\n",
       "      <td>4359.000000</td>\n",
       "      <td>4343.000000</td>\n",
       "      <td>4367.000000</td>\n",
       "      <td>4385.000000</td>\n",
       "      <td>4382.000000</td>\n",
       "      <td>4381.000000</td>\n",
       "      <td>4368.000000</td>\n",
       "      <td>4388.000000</td>\n",
       "      <td>4369.000000</td>\n",
       "      <td>4402.000000</td>\n",
       "      <td>4339.000000</td>\n",
       "      <td>4376.000000</td>\n",
       "      <td>4380.000000</td>\n",
       "      <td>4353.000000</td>\n",
       "      <td>4397.000000</td>\n",
       "      <td>4371.000000</td>\n",
       "      <td>4365.000000</td>\n",
       "      <td>4359.000000</td>\n",
       "      <td>4362.000000</td>\n",
       "      <td>4400.000000</td>\n",
       "      <td>4372.000000</td>\n",
       "      <td>4373.000000</td>\n",
       "      <td>4386.000000</td>\n",
       "      <td>4372.000000</td>\n",
       "      <td>4367.000000</td>\n",
       "      <td>4392.000000</td>\n",
       "      <td>4385.000000</td>\n",
       "      <td>4377.000000</td>\n",
       "      <td>4360.000000</td>\n",
       "      <td>4361.000000</td>\n",
       "      <td>4361.000000</td>\n",
       "      <td>4353.000000</td>\n",
       "      <td>4386.000000</td>\n",
       "      <td>4373.000000</td>\n",
       "      <td>4354.000000</td>\n",
       "      <td>4349.000000</td>\n",
       "      <td>4380.000000</td>\n",
       "      <td>4360.000000</td>\n",
       "      <td>4379.000000</td>\n",
       "      <td>4376.000000</td>\n",
       "      <td>4373.000000</td>\n",
       "      <td>4385.000000</td>\n",
       "      <td>4363.000000</td>\n",
       "      <td>4368.000000</td>\n",
       "      <td>4370.000000</td>\n",
       "      <td>4353.000000</td>\n",
       "      <td>4362.000000</td>\n",
       "      <td>4360.000000</td>\n",
       "      <td>4372.000000</td>\n",
       "      <td>4350.000000</td>\n",
       "      <td>4373.000000</td>\n",
       "      <td>4383.000000</td>\n",
       "      <td>4340.000000</td>\n",
       "      <td>4398.000000</td>\n",
       "      <td>4375.000000</td>\n",
       "      <td>4375.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.105494</td>\n",
       "      <td>0.215361</td>\n",
       "      <td>0.280813</td>\n",
       "      <td>0.068793</td>\n",
       "      <td>0.313763</td>\n",
       "      <td>0.095842</td>\n",
       "      <td>0.115054</td>\n",
       "      <td>0.105151</td>\n",
       "      <td>0.089991</td>\n",
       "      <td>0.238718</td>\n",
       "      <td>0.060968</td>\n",
       "      <td>0.538324</td>\n",
       "      <td>0.094088</td>\n",
       "      <td>0.059881</td>\n",
       "      <td>0.047409</td>\n",
       "      <td>0.245713</td>\n",
       "      <td>0.143814</td>\n",
       "      <td>0.186685</td>\n",
       "      <td>1.661755</td>\n",
       "      <td>0.087125</td>\n",
       "      <td>0.807457</td>\n",
       "      <td>0.118792</td>\n",
       "      <td>0.101475</td>\n",
       "      <td>0.093005</td>\n",
       "      <td>0.542836</td>\n",
       "      <td>0.259166</td>\n",
       "      <td>0.772632</td>\n",
       "      <td>0.123024</td>\n",
       "      <td>0.096255</td>\n",
       "      <td>0.104206</td>\n",
       "      <td>0.065863</td>\n",
       "      <td>0.045368</td>\n",
       "      <td>0.097225</td>\n",
       "      <td>0.048525</td>\n",
       "      <td>0.105180</td>\n",
       "      <td>0.099596</td>\n",
       "      <td>0.138459</td>\n",
       "      <td>0.013146</td>\n",
       "      <td>0.079259</td>\n",
       "      <td>0.063156</td>\n",
       "      <td>0.043190</td>\n",
       "      <td>0.128658</td>\n",
       "      <td>0.045574</td>\n",
       "      <td>0.077043</td>\n",
       "      <td>0.300506</td>\n",
       "      <td>0.179421</td>\n",
       "      <td>0.005215</td>\n",
       "      <td>0.032407</td>\n",
       "      <td>0.036238</td>\n",
       "      <td>0.137593</td>\n",
       "      <td>0.017218</td>\n",
       "      <td>0.272041</td>\n",
       "      <td>0.076350</td>\n",
       "      <td>0.044526</td>\n",
       "      <td>5.246067</td>\n",
       "      <td>52.689600</td>\n",
       "      <td>280.305143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.308533</td>\n",
       "      <td>1.306364</td>\n",
       "      <td>0.505388</td>\n",
       "      <td>1.431944</td>\n",
       "      <td>0.671920</td>\n",
       "      <td>0.272309</td>\n",
       "      <td>0.394845</td>\n",
       "      <td>0.404086</td>\n",
       "      <td>0.279369</td>\n",
       "      <td>0.644470</td>\n",
       "      <td>0.204305</td>\n",
       "      <td>0.857327</td>\n",
       "      <td>0.302030</td>\n",
       "      <td>0.340456</td>\n",
       "      <td>0.252212</td>\n",
       "      <td>0.795970</td>\n",
       "      <td>0.448318</td>\n",
       "      <td>0.534015</td>\n",
       "      <td>1.765929</td>\n",
       "      <td>0.520858</td>\n",
       "      <td>1.198314</td>\n",
       "      <td>1.016130</td>\n",
       "      <td>0.350780</td>\n",
       "      <td>0.442899</td>\n",
       "      <td>1.656395</td>\n",
       "      <td>0.856240</td>\n",
       "      <td>3.384791</td>\n",
       "      <td>0.522384</td>\n",
       "      <td>0.558797</td>\n",
       "      <td>0.460649</td>\n",
       "      <td>0.407041</td>\n",
       "      <td>0.326209</td>\n",
       "      <td>0.557437</td>\n",
       "      <td>0.330978</td>\n",
       "      <td>0.533905</td>\n",
       "      <td>0.409431</td>\n",
       "      <td>0.428712</td>\n",
       "      <td>0.224730</td>\n",
       "      <td>0.438120</td>\n",
       "      <td>0.342838</td>\n",
       "      <td>0.363853</td>\n",
       "      <td>0.743579</td>\n",
       "      <td>0.221837</td>\n",
       "      <td>0.582834</td>\n",
       "      <td>1.017417</td>\n",
       "      <td>0.919423</td>\n",
       "      <td>0.072663</td>\n",
       "      <td>0.291315</td>\n",
       "      <td>0.228100</td>\n",
       "      <td>0.260008</td>\n",
       "      <td>0.110894</td>\n",
       "      <td>0.830417</td>\n",
       "      <td>0.249458</td>\n",
       "      <td>0.439785</td>\n",
       "      <td>32.399849</td>\n",
       "      <td>198.257777</td>\n",
       "      <td>602.768256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.586500</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>35.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.310000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.220000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.066000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.269500</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>94.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.390000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.110000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.630000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.260000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.188000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.322000</td>\n",
       "      <td>0.052000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.714000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>264.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.540000</td>\n",
       "      <td>14.280000</td>\n",
       "      <td>5.100000</td>\n",
       "      <td>42.810000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>5.880000</td>\n",
       "      <td>7.270000</td>\n",
       "      <td>11.110000</td>\n",
       "      <td>5.260000</td>\n",
       "      <td>18.180000</td>\n",
       "      <td>2.610000</td>\n",
       "      <td>9.670000</td>\n",
       "      <td>5.550000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>4.410000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>7.140000</td>\n",
       "      <td>9.090000</td>\n",
       "      <td>18.750000</td>\n",
       "      <td>18.180000</td>\n",
       "      <td>11.110000</td>\n",
       "      <td>17.100000</td>\n",
       "      <td>5.450000</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>20.830000</td>\n",
       "      <td>16.660000</td>\n",
       "      <td>33.330000</td>\n",
       "      <td>9.090000</td>\n",
       "      <td>11.110000</td>\n",
       "      <td>5.880000</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>4.760000</td>\n",
       "      <td>18.180000</td>\n",
       "      <td>4.760000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>7.690000</td>\n",
       "      <td>6.890000</td>\n",
       "      <td>8.330000</td>\n",
       "      <td>11.110000</td>\n",
       "      <td>4.760000</td>\n",
       "      <td>7.140000</td>\n",
       "      <td>14.280000</td>\n",
       "      <td>3.570000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>21.420000</td>\n",
       "      <td>22.050000</td>\n",
       "      <td>2.170000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>4.385000</td>\n",
       "      <td>9.752000</td>\n",
       "      <td>4.081000</td>\n",
       "      <td>32.478000</td>\n",
       "      <td>6.003000</td>\n",
       "      <td>19.829000</td>\n",
       "      <td>1102.500000</td>\n",
       "      <td>9989.000000</td>\n",
       "      <td>15841.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       word_freq_make  word_freq_address  word_freq_all  word_freq_3d  word_freq_our  word_freq_over  word_freq_remove  word_freq_internet  word_freq_order  word_freq_mail  word_freq_receive  word_freq_will  word_freq_people  word_freq_report  word_freq_addresses  word_freq_free  word_freq_business  word_freq_email  word_freq_you  word_freq_credit  word_freq_your  word_freq_font  word_freq_000  word_freq_money  word_freq_hp  word_freq_hpl  word_freq_george  word_freq_650  word_freq_lab  word_freq_labs  word_freq_telnet  word_freq_857  word_freq_data  word_freq_415  word_freq_85  word_freq_technology  word_freq_1999  word_freq_parts  word_freq_pm  word_freq_direct  word_freq_cs  word_freq_meeting  word_freq_original  word_freq_project  word_freq_re  word_freq_edu  word_freq_table  word_freq_conference  char_freq_%3B  char_freq_%28  char_freq_%5B  char_freq_%21  char_freq_%24  char_freq_%23  capital_run_length_average  capital_run_length_longest  capital_run_length_total\n",
       "count     4383.000000        4359.000000    4343.000000   4367.000000    4385.000000     4382.000000       4381.000000         4368.000000      4388.000000     4369.000000        4402.000000     4339.000000       4376.000000       4380.000000          4353.000000     4397.000000         4371.000000      4365.000000    4359.000000       4362.000000     4400.000000     4372.000000    4373.000000      4386.000000   4372.000000    4367.000000       4392.000000    4385.000000    4377.000000     4360.000000       4361.000000    4361.000000     4353.000000    4386.000000   4373.000000           4354.000000     4349.000000      4380.000000   4360.000000       4379.000000   4376.000000        4373.000000         4385.000000        4363.000000   4368.000000    4370.000000      4353.000000           4362.000000    4360.000000    4372.000000    4350.000000    4373.000000    4383.000000    4340.000000                 4398.000000                 4375.000000               4375.000000\n",
       "mean         0.105494           0.215361       0.280813      0.068793       0.313763        0.095842          0.115054            0.105151         0.089991        0.238718           0.060968        0.538324          0.094088          0.059881             0.047409        0.245713            0.143814         0.186685       1.661755          0.087125        0.807457        0.118792       0.101475         0.093005      0.542836       0.259166          0.772632       0.123024       0.096255        0.104206          0.065863       0.045368        0.097225       0.048525      0.105180              0.099596        0.138459         0.013146      0.079259          0.063156      0.043190           0.128658            0.045574           0.077043      0.300506       0.179421         0.005215              0.032407       0.036238       0.137593       0.017218       0.272041       0.076350       0.044526                    5.246067                   52.689600                280.305143\n",
       "std          0.308533           1.306364       0.505388      1.431944       0.671920        0.272309          0.394845            0.404086         0.279369        0.644470           0.204305        0.857327          0.302030          0.340456             0.252212        0.795970            0.448318         0.534015       1.765929          0.520858        1.198314        1.016130       0.350780         0.442899      1.656395       0.856240          3.384791       0.522384       0.558797        0.460649          0.407041       0.326209        0.557437       0.330978      0.533905              0.409431        0.428712         0.224730      0.438120          0.342838      0.363853           0.743579            0.221837           0.582834      1.017417       0.919423         0.072663              0.291315       0.228100       0.260008       0.110894       0.830417       0.249458       0.439785                   32.399849                  198.257777                602.768256\n",
       "min          0.000000           0.000000       0.000000      0.000000       0.000000        0.000000          0.000000            0.000000         0.000000        0.000000           0.000000        0.000000          0.000000          0.000000             0.000000        0.000000            0.000000         0.000000       0.000000          0.000000        0.000000        0.000000       0.000000         0.000000      0.000000       0.000000          0.000000       0.000000       0.000000        0.000000          0.000000       0.000000        0.000000       0.000000      0.000000              0.000000        0.000000         0.000000      0.000000          0.000000      0.000000           0.000000            0.000000           0.000000      0.000000       0.000000         0.000000              0.000000       0.000000       0.000000       0.000000       0.000000       0.000000       0.000000                    1.000000                    1.000000                  1.000000\n",
       "25%          0.000000           0.000000       0.000000      0.000000       0.000000        0.000000          0.000000            0.000000         0.000000        0.000000           0.000000        0.000000          0.000000          0.000000             0.000000        0.000000            0.000000         0.000000       0.000000          0.000000        0.000000        0.000000       0.000000         0.000000      0.000000       0.000000          0.000000       0.000000       0.000000        0.000000          0.000000       0.000000        0.000000       0.000000      0.000000              0.000000        0.000000         0.000000      0.000000          0.000000      0.000000           0.000000            0.000000           0.000000      0.000000       0.000000         0.000000              0.000000       0.000000       0.000000       0.000000       0.000000       0.000000       0.000000                    1.586500                    6.000000                 35.000000\n",
       "50%          0.000000           0.000000       0.000000      0.000000       0.000000        0.000000          0.000000            0.000000         0.000000        0.000000           0.000000        0.090000          0.000000          0.000000             0.000000        0.000000            0.000000         0.000000       1.310000          0.000000        0.220000        0.000000       0.000000         0.000000      0.000000       0.000000          0.000000       0.000000       0.000000        0.000000          0.000000       0.000000        0.000000       0.000000      0.000000              0.000000        0.000000         0.000000      0.000000          0.000000      0.000000           0.000000            0.000000           0.000000      0.000000       0.000000         0.000000              0.000000       0.000000       0.066000       0.000000       0.000000       0.000000       0.000000                    2.269500                   15.000000                 94.000000\n",
       "75%          0.000000           0.000000       0.420000      0.000000       0.390000        0.000000          0.000000            0.000000         0.000000        0.160000           0.000000        0.800000          0.000000          0.000000             0.000000        0.110000            0.000000         0.000000       2.630000          0.000000        1.260000        0.000000       0.000000         0.000000      0.000000       0.000000          0.000000       0.000000       0.000000        0.000000          0.000000       0.000000        0.000000       0.000000      0.000000              0.000000        0.000000         0.000000      0.000000          0.000000      0.000000           0.000000            0.000000           0.000000      0.100000       0.000000         0.000000              0.000000       0.000000       0.188000       0.000000       0.322000       0.052000       0.000000                    3.714000                   43.000000                264.000000\n",
       "max          4.540000          14.280000       5.100000     42.810000      10.000000        5.880000          7.270000           11.110000         5.260000       18.180000           2.610000        9.670000          5.550000         10.000000             4.410000       20.000000            7.140000         9.090000      18.750000         18.180000       11.110000       17.100000       5.450000        12.500000     20.830000      16.660000         33.330000       9.090000      11.110000        5.880000         12.500000       4.760000       18.180000       4.760000     20.000000              7.690000        6.890000         8.330000     11.110000          4.760000      7.140000          14.280000            3.570000          20.000000     21.420000      22.050000         2.170000             10.000000       4.385000       9.752000       4.081000      32.478000       6.003000      19.829000                 1102.500000                 9989.000000              15841.000000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5eb11e7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word_freq_make\n",
      "0.00    3384\n",
      "0.10      49\n",
      "0.09      39\n",
      "0.17      36\n",
      "0.08      30\n",
      "0.05      23\n",
      "0.07      20\n",
      "0.33      19\n",
      "0.34      19\n",
      "0.06      17\n",
      "0.14      16\n",
      "0.19      16\n",
      "0.26      16\n",
      "0.12      16\n",
      "0.23      15\n",
      "0.43      15\n",
      "0.27      14\n",
      "0.13      14\n",
      "0.32      14\n",
      "0.31      13\n",
      "0.18      13\n",
      "0.40      13\n",
      "0.16      13\n",
      "0.15      13\n",
      "0.11      12\n",
      "0.51      12\n",
      "0.29      12\n",
      "0.44      12\n",
      "0.54      12\n",
      "0.30      12\n",
      "0.49      12\n",
      "0.39      12\n",
      "0.47      12\n",
      "0.25      11\n",
      "0.58      11\n",
      "0.46      11\n",
      "2.00      11\n",
      "0.22      11\n",
      "0.35      11\n",
      "0.20      10\n",
      "0.52       9\n",
      "0.90       9\n",
      "0.67       9\n",
      "0.28       9\n",
      "0.41       8\n",
      "0.50       8\n",
      "0.59       8\n",
      "0.36       8\n",
      "0.04       7\n",
      "0.42       7\n",
      "0.77       7\n",
      "0.76       7\n",
      "0.45       7\n",
      "1.24       7\n",
      "0.74       7\n",
      "0.71       7\n",
      "0.87       7\n",
      "0.68       6\n",
      "0.64       6\n",
      "0.60       6\n",
      "0.21       6\n",
      "0.73       6\n",
      "0.38       6\n",
      "0.48       6\n",
      "0.24       6\n",
      "0.37       6\n",
      "0.78       5\n",
      "0.56       5\n",
      "1.18       5\n",
      "0.53       5\n",
      "1.00       5\n",
      "0.62       5\n",
      "0.02       4\n",
      "1.03       4\n",
      "0.95       4\n",
      "0.84       4\n",
      "0.70       4\n",
      "0.75       4\n",
      "0.66       4\n",
      "1.17       4\n",
      "0.03       4\n",
      "0.65       4\n",
      "0.86       4\n",
      "0.85       3\n",
      "0.97       3\n",
      "1.19       3\n",
      "1.04       3\n",
      "0.69       3\n",
      "0.01       3\n",
      "1.63       3\n",
      "1.47       3\n",
      "1.06       3\n",
      "0.80       3\n",
      "1.26       3\n",
      "1.23       3\n",
      "0.72       3\n",
      "2.32       3\n",
      "0.98       3\n",
      "0.89       3\n",
      "0.63       3\n",
      "0.55       2\n",
      "0.82       2\n",
      "0.99       2\n",
      "0.79       2\n",
      "0.93       2\n",
      "1.02       2\n",
      "1.05       2\n",
      "2.77       2\n",
      "2.27       2\n",
      "0.96       2\n",
      "4.34       1\n",
      "3.03       1\n",
      "0.83       1\n",
      "3.84       1\n",
      "1.12       1\n",
      "2.85       1\n",
      "1.39       1\n",
      "1.31       1\n",
      "1.08       1\n",
      "1.49       1\n",
      "1.88       1\n",
      "4.00       1\n",
      "3.94       1\n",
      "1.42       1\n",
      "1.75       1\n",
      "0.57       1\n",
      "1.07       1\n",
      "1.16       1\n",
      "1.09       1\n",
      "1.11       1\n",
      "0.81       1\n",
      "1.14       1\n",
      "4.54       1\n",
      "2.43       1\n",
      "0.61       1\n",
      "1.44       1\n",
      "1.61       1\n",
      "1.36       1\n",
      "2.12       1\n",
      "2.35       1\n",
      "1.01       1\n",
      "0.88       1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "word_freq_address\n",
      "0.00     3516\n",
      "14.28      34\n",
      "0.08       26\n",
      "0.10       23\n",
      "0.17       22\n",
      "0.19       22\n",
      "0.20       21\n",
      "0.26       18\n",
      "0.39       17\n",
      "0.16       16\n",
      "0.49       16\n",
      "0.28       16\n",
      "0.22       15\n",
      "0.46       15\n",
      "0.41       13\n",
      "0.14       13\n",
      "0.55       13\n",
      "0.33       12\n",
      "0.56       12\n",
      "0.27       12\n",
      "0.35       11\n",
      "0.30       11\n",
      "0.31       11\n",
      "0.25       11\n",
      "0.18       11\n",
      "0.34       11\n",
      "0.42       11\n",
      "0.05       11\n",
      "0.29       11\n",
      "0.38       10\n",
      "0.37        9\n",
      "0.11        9\n",
      "0.09        9\n",
      "0.13        9\n",
      "0.44        9\n",
      "0.43        9\n",
      "0.32        8\n",
      "0.12        8\n",
      "0.68        8\n",
      "0.90        8\n",
      "0.02        8\n",
      "0.24        8\n",
      "0.40        7\n",
      "0.23        7\n",
      "0.80        7\n",
      "0.47        6\n",
      "1.32        6\n",
      "0.50        6\n",
      "0.57        6\n",
      "0.36        6\n",
      "0.06        6\n",
      "0.72        6\n",
      "0.54        5\n",
      "0.75        5\n",
      "0.66        5\n",
      "1.25        5\n",
      "0.04        5\n",
      "0.63        5\n",
      "0.07        5\n",
      "0.81        5\n",
      "0.62        5\n",
      "0.64        5\n",
      "0.45        5\n",
      "0.15        4\n",
      "0.89        4\n",
      "0.03        4\n",
      "1.63        4\n",
      "0.59        4\n",
      "0.95        4\n",
      "0.67        4\n",
      "0.53        4\n",
      "1.36        3\n",
      "0.65        3\n",
      "0.21        3\n",
      "0.51        3\n",
      "0.58        3\n",
      "0.84        3\n",
      "1.16        3\n",
      "0.52        3\n",
      "0.48        3\n",
      "0.94        3\n",
      "2.12        3\n",
      "0.85        3\n",
      "0.74        3\n",
      "0.82        3\n",
      "0.60        3\n",
      "1.47        3\n",
      "1.35        2\n",
      "0.78        2\n",
      "2.35        2\n",
      "0.88        2\n",
      "2.07        2\n",
      "1.86        2\n",
      "0.01        2\n",
      "1.28        2\n",
      "1.08        2\n",
      "0.76        2\n",
      "0.70        2\n",
      "1.12        2\n",
      "1.26        2\n",
      "1.96        2\n",
      "1.31        2\n",
      "1.03        2\n",
      "1.11        2\n",
      "0.71        2\n",
      "1.07        2\n",
      "0.69        2\n",
      "1.52        1\n",
      "2.50        1\n",
      "0.77        1\n",
      "0.91        1\n",
      "1.10        1\n",
      "0.99        1\n",
      "0.79        1\n",
      "1.17        1\n",
      "0.61        1\n",
      "1.23        1\n",
      "4.10        1\n",
      "1.33        1\n",
      "1.92        1\n",
      "1.61        1\n",
      "3.27        1\n",
      "1.85        1\n",
      "3.52        1\n",
      "0.87        1\n",
      "3.03        1\n",
      "2.70        1\n",
      "1.38        1\n",
      "1.42        1\n",
      "1.78        1\n",
      "9.52        1\n",
      "1.57        1\n",
      "3.36        1\n",
      "1.62        1\n",
      "6.34        1\n",
      "1.76        1\n",
      "5.47        1\n",
      "1.05        1\n",
      "2.08        1\n",
      "0.92        1\n",
      "1.56        1\n",
      "1.09        1\n",
      "1.22        1\n",
      "1.15        1\n",
      "2.66        1\n",
      "1.72        1\n",
      "1.14        1\n",
      "1.01        1\n",
      "3.05        1\n",
      "1.65        1\n",
      "4.76        1\n",
      "7.01        1\n",
      "2.43        1\n",
      "4.54        1\n",
      "1.19        1\n",
      "1.00        1\n",
      "1.20        1\n",
      "0.96        1\n",
      "2.40        1\n",
      "1.49        1\n",
      "2.46        1\n",
      "4.16        1\n",
      "2.59        1\n",
      "3.68        1\n",
      "2.01        1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "word_freq_all\n",
      "0.00    2558\n",
      "0.32      47\n",
      "0.29      40\n",
      "0.55      39\n",
      "0.36      28\n",
      "0.40      28\n",
      "0.27      26\n",
      "0.10      26\n",
      "0.71      25\n",
      "0.47      24\n",
      "0.59      24\n",
      "0.35      24\n",
      "0.56      23\n",
      "0.64      23\n",
      "0.15      22\n",
      "0.25      22\n",
      "0.38      22\n",
      "0.48      21\n",
      "0.26      21\n",
      "0.52      21\n",
      "0.08      20\n",
      "0.31      20\n",
      "0.28      20\n",
      "0.51      19\n",
      "0.24      19\n",
      "0.33      19\n",
      "0.22      19\n",
      "0.18      19\n",
      "0.67      18\n",
      "0.42      18\n",
      "1.31      18\n",
      "0.46      18\n",
      "0.17      18\n",
      "0.57      17\n",
      "0.19      17\n",
      "0.76      17\n",
      "0.41      16\n",
      "0.12      16\n",
      "0.20      16\n",
      "0.62      16\n",
      "0.77      15\n",
      "1.01      15\n",
      "0.34      15\n",
      "0.30      15\n",
      "0.23      15\n",
      "0.70      15\n",
      "0.09      15\n",
      "0.37      15\n",
      "0.58      15\n",
      "0.54      14\n",
      "0.16      14\n",
      "0.11      14\n",
      "0.78      14\n",
      "0.43      14\n",
      "0.68      13\n",
      "0.74      13\n",
      "0.21      13\n",
      "0.50      13\n",
      "0.53      13\n",
      "0.94      12\n",
      "0.66      12\n",
      "0.72      12\n",
      "0.44      12\n",
      "0.81      11\n",
      "1.58      11\n",
      "0.87      11\n",
      "0.39      11\n",
      "0.61      11\n",
      "0.14      10\n",
      "0.80      10\n",
      "0.49      10\n",
      "0.63      10\n",
      "0.60      10\n",
      "0.13      10\n",
      "0.69      10\n",
      "0.90       9\n",
      "0.88       9\n",
      "0.73       9\n",
      "0.82       8\n",
      "1.29       8\n",
      "1.24       8\n",
      "0.45       8\n",
      "0.84       8\n",
      "1.00       8\n",
      "1.09       8\n",
      "1.47       8\n",
      "0.86       8\n",
      "1.06       8\n",
      "0.05       7\n",
      "1.02       7\n",
      "1.19       7\n",
      "1.63       7\n",
      "0.93       7\n",
      "0.91       7\n",
      "0.99       7\n",
      "1.05       7\n",
      "0.79       7\n",
      "0.95       6\n",
      "1.11       6\n",
      "1.81       6\n",
      "0.97       6\n",
      "0.89       6\n",
      "1.14       6\n",
      "1.21       6\n",
      "1.35       6\n",
      "1.08       6\n",
      "0.03       6\n",
      "1.16       6\n",
      "1.33       6\n",
      "1.26       5\n",
      "0.65       5\n",
      "1.17       5\n",
      "1.07       5\n",
      "0.98       5\n",
      "0.07       5\n",
      "0.06       5\n",
      "0.75       5\n",
      "1.56       5\n",
      "0.83       5\n",
      "1.25       5\n",
      "1.23       4\n",
      "2.50       4\n",
      "1.10       4\n",
      "0.85       4\n",
      "1.13       4\n",
      "2.56       4\n",
      "2.04       4\n",
      "1.70       4\n",
      "2.27       4\n",
      "1.20       4\n",
      "1.96       4\n",
      "1.18       4\n",
      "1.04       3\n",
      "1.03       3\n",
      "3.03       3\n",
      "1.66       3\n",
      "3.70       3\n",
      "1.40       3\n",
      "1.85       3\n",
      "1.90       3\n",
      "1.61       3\n",
      "1.12       3\n",
      "1.28       3\n",
      "1.45       3\n",
      "1.49       3\n",
      "2.38       3\n",
      "1.38       2\n",
      "1.88       2\n",
      "1.83       2\n",
      "2.43       2\n",
      "0.96       2\n",
      "4.00       2\n",
      "2.12       2\n",
      "1.44       2\n",
      "1.22       2\n",
      "1.34       2\n",
      "1.50       2\n",
      "1.36       2\n",
      "3.44       2\n",
      "2.32       2\n",
      "3.22       2\n",
      "1.92       2\n",
      "1.15       2\n",
      "0.04       2\n",
      "1.68       2\n",
      "1.72       2\n",
      "0.92       2\n",
      "1.51       2\n",
      "1.42       2\n",
      "1.69       1\n",
      "1.60       1\n",
      "2.06       1\n",
      "1.39       1\n",
      "5.10       1\n",
      "4.34       1\n",
      "3.38       1\n",
      "2.63       1\n",
      "2.17       1\n",
      "2.08       1\n",
      "4.54       1\n",
      "1.98       1\n",
      "3.61       1\n",
      "2.09       1\n",
      "3.57       1\n",
      "2.77       1\n",
      "2.94       1\n",
      "3.00       1\n",
      "1.43       1\n",
      "2.91       1\n",
      "2.25       1\n",
      "1.53       1\n",
      "1.32       1\n",
      "1.77       1\n",
      "2.22       1\n",
      "1.65       1\n",
      "1.64       1\n",
      "2.99       1\n",
      "1.62       1\n",
      "1.79       1\n",
      "1.97       1\n",
      "1.55       1\n",
      "3.48       1\n",
      "2.15       1\n",
      "2.34       1\n",
      "2.00       1\n",
      "1.94       1\n",
      "2.24       1\n",
      "3.84       1\n",
      "3.79       1\n",
      "2.41       1\n",
      "1.46       1\n",
      "2.35       1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "word_freq_3d\n",
      "0.00     4321\n",
      "0.17        2\n",
      "0.58        2\n",
      "0.21        2\n",
      "35.46       2\n",
      "0.42        2\n",
      "0.87        1\n",
      "0.13        1\n",
      "42.73       1\n",
      "0.55        1\n",
      "0.44        1\n",
      "7.07        1\n",
      "1.33        1\n",
      "1.29        1\n",
      "19.73       1\n",
      "0.57        1\n",
      "0.06        1\n",
      "1.35        1\n",
      "0.11        1\n",
      "0.14        1\n",
      "0.15        1\n",
      "0.04        1\n",
      "19.16       1\n",
      "0.52        1\n",
      "1.16        1\n",
      "0.16        1\n",
      "0.19        1\n",
      "0.95        1\n",
      "5.03        1\n",
      "7.18        1\n",
      "13.63       1\n",
      "0.81        1\n",
      "1.26        1\n",
      "42.81       1\n",
      "0.10        1\n",
      "0.49        1\n",
      "1.91        1\n",
      "40.13       1\n",
      "0.91        1\n",
      "9.16        1\n",
      "4.31        1\n",
      "0.31        1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "word_freq_our\n",
      "0.00     2717\n",
      "0.36       27\n",
      "0.32       26\n",
      "0.80       24\n",
      "0.19       22\n",
      "0.14       22\n",
      "0.29       21\n",
      "0.53       21\n",
      "0.68       21\n",
      "0.13       20\n",
      "0.26       20\n",
      "0.65       20\n",
      "0.23       19\n",
      "0.43       19\n",
      "0.34       19\n",
      "0.33       19\n",
      "0.09       18\n",
      "0.15       18\n",
      "0.45       18\n",
      "0.22       18\n",
      "0.64       18\n",
      "0.40       18\n",
      "0.38       18\n",
      "0.28       17\n",
      "0.39       17\n",
      "0.44       17\n",
      "0.27       17\n",
      "0.42       16\n",
      "0.52       16\n",
      "0.10       16\n",
      "0.17       16\n",
      "0.12       16\n",
      "0.30       16\n",
      "0.25       16\n",
      "0.87       15\n",
      "0.20       15\n",
      "0.08       15\n",
      "0.16       15\n",
      "0.54       15\n",
      "0.05       15\n",
      "0.85       14\n",
      "0.35       14\n",
      "1.11       14\n",
      "0.47       14\n",
      "0.31       14\n",
      "0.60       14\n",
      "0.24       13\n",
      "0.51       12\n",
      "0.76       12\n",
      "0.49       11\n",
      "0.67       11\n",
      "0.37       11\n",
      "0.48       11\n",
      "0.63       11\n",
      "0.58       11\n",
      "0.21       11\n",
      "0.04       11\n",
      "0.81       11\n",
      "0.61       10\n",
      "1.14       10\n",
      "0.55       10\n",
      "0.59       10\n",
      "0.66       10\n",
      "1.44       10\n",
      "1.17       10\n",
      "0.41       10\n",
      "0.56       10\n",
      "0.82        9\n",
      "0.46        9\n",
      "1.05        9\n",
      "1.03        9\n",
      "0.90        9\n",
      "0.88        9\n",
      "0.94        9\n",
      "0.18        9\n",
      "1.21        8\n",
      "1.45        8\n",
      "0.73        8\n",
      "0.69        8\n",
      "1.04        8\n",
      "0.78        8\n",
      "0.07        8\n",
      "0.84        8\n",
      "1.28        8\n",
      "0.89        8\n",
      "0.11        8\n",
      "0.50        8\n",
      "0.71        8\n",
      "0.75        7\n",
      "0.72        7\n",
      "1.07        7\n",
      "0.62        7\n",
      "1.57        7\n",
      "1.85        7\n",
      "1.06        6\n",
      "1.52        6\n",
      "1.59        6\n",
      "1.02        6\n",
      "1.29        6\n",
      "1.15        6\n",
      "1.13        6\n",
      "1.16        6\n",
      "0.99        6\n",
      "0.96        6\n",
      "0.93        6\n",
      "0.57        6\n",
      "1.25        5\n",
      "2.94        5\n",
      "1.26        5\n",
      "2.04        5\n",
      "0.77        5\n",
      "0.70        5\n",
      "1.33        5\n",
      "0.02        5\n",
      "1.30        5\n",
      "0.95        5\n",
      "0.91        5\n",
      "1.09        5\n",
      "0.74        5\n",
      "1.56        5\n",
      "2.25        5\n",
      "1.63        5\n",
      "2.38        4\n",
      "1.79        4\n",
      "1.34        4\n",
      "1.58        4\n",
      "1.43        4\n",
      "1.46        4\n",
      "1.92        4\n",
      "1.47        4\n",
      "1.40        4\n",
      "1.35        4\n",
      "0.83        4\n",
      "1.75        4\n",
      "1.00        4\n",
      "1.38        4\n",
      "2.63        4\n",
      "1.23        4\n",
      "1.49        4\n",
      "1.12        4\n",
      "2.23        4\n",
      "1.10        4\n",
      "2.06        4\n",
      "1.08        3\n",
      "1.01        3\n",
      "1.27        3\n",
      "1.66        3\n",
      "4.76        3\n",
      "3.22        3\n",
      "0.79        3\n",
      "2.17        3\n",
      "3.44        3\n",
      "0.98        3\n",
      "2.22        3\n",
      "1.54        3\n",
      "1.48        3\n",
      "1.51        3\n",
      "6.25        3\n",
      "1.41        3\n",
      "1.55        3\n",
      "1.61        3\n",
      "2.50        3\n",
      "1.18        3\n",
      "1.65        3\n",
      "1.36        3\n",
      "1.31        3\n",
      "0.92        3\n",
      "1.81        3\n",
      "2.46        2\n",
      "2.00        2\n",
      "1.93        2\n",
      "0.97        2\n",
      "1.60        2\n",
      "1.91        2\n",
      "2.83        2\n",
      "3.84        2\n",
      "1.22        2\n",
      "2.15        2\n",
      "4.54        2\n",
      "4.08        2\n",
      "1.77        2\n",
      "0.86        2\n",
      "2.70        2\n",
      "1.53        2\n",
      "0.06        2\n",
      "1.24        2\n",
      "3.48        2\n",
      "1.89        2\n",
      "3.09        2\n",
      "2.43        2\n",
      "1.39        2\n",
      "3.12        2\n",
      "1.70        2\n",
      "1.32        2\n",
      "1.82        2\n",
      "2.08        1\n",
      "5.55        1\n",
      "1.62        1\n",
      "2.32        1\n",
      "2.01        1\n",
      "1.69        1\n",
      "9.09        1\n",
      "1.50        1\n",
      "2.54        1\n",
      "10.00       1\n",
      "1.19        1\n",
      "3.52        1\n",
      "1.73        1\n",
      "4.16        1\n",
      "2.02        1\n",
      "5.26        1\n",
      "3.07        1\n",
      "5.00        1\n",
      "2.42        1\n",
      "7.14        1\n",
      "0.03        1\n",
      "2.85        1\n",
      "2.18        1\n",
      "3.27        1\n",
      "8.33        1\n",
      "3.92        1\n",
      "2.19        1\n",
      "3.03        1\n",
      "1.71        1\n",
      "2.10        1\n",
      "2.33        1\n",
      "7.69        1\n",
      "4.25        1\n",
      "2.24        1\n",
      "1.67        1\n",
      "3.33        1\n",
      "2.91        1\n",
      "3.69        1\n",
      "1.88        1\n",
      "2.53        1\n",
      "3.98        1\n",
      "1.37        1\n",
      "1.78        1\n",
      "2.80        1\n",
      "2.29        1\n",
      "2.16        1\n",
      "2.45        1\n",
      "1.20        1\n",
      "2.27        1\n",
      "1.42        1\n",
      "3.70        1\n",
      "1.68        1\n",
      "2.89        1\n",
      "2.48        1\n",
      "2.03        1\n",
      "1.72        1\n",
      "2.90        1\n",
      "1.90        1\n",
      "1.96        1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "word_freq_over\n",
      "0.00    3426\n",
      "0.09      31\n",
      "0.10      30\n",
      "0.19      25\n",
      "0.03      24\n",
      "0.08      23\n",
      "0.16      23\n",
      "0.11      22\n",
      "0.32      20\n",
      "0.25      20\n",
      "0.13      20\n",
      "0.36      19\n",
      "0.20      18\n",
      "0.05      18\n",
      "0.22      17\n",
      "0.38      16\n",
      "0.65      16\n",
      "0.23      16\n",
      "0.17      16\n",
      "0.80      15\n",
      "0.12      15\n",
      "0.57      14\n",
      "0.34      14\n",
      "0.26      14\n",
      "0.27      14\n",
      "0.29      13\n",
      "0.60      13\n",
      "0.64      13\n",
      "0.44      12\n",
      "0.18      11\n",
      "0.14      11\n",
      "0.51      11\n",
      "1.02      11\n",
      "0.30      11\n",
      "0.62      11\n",
      "0.24      11\n",
      "0.43      10\n",
      "0.15      10\n",
      "0.40       9\n",
      "0.49       9\n",
      "0.21       9\n",
      "0.33       9\n",
      "0.55       9\n",
      "0.35       9\n",
      "0.39       9\n",
      "0.28       8\n",
      "0.47       8\n",
      "0.48       8\n",
      "0.45       8\n",
      "0.37       7\n",
      "0.74       7\n",
      "0.07       7\n",
      "0.56       7\n",
      "0.42       7\n",
      "0.61       6\n",
      "0.04       6\n",
      "0.73       6\n",
      "1.32       6\n",
      "0.63       6\n",
      "0.58       6\n",
      "0.98       6\n",
      "1.29       6\n",
      "0.06       6\n",
      "0.41       6\n",
      "0.78       5\n",
      "0.79       5\n",
      "0.54       5\n",
      "0.66       5\n",
      "0.59       5\n",
      "0.46       5\n",
      "0.53       4\n",
      "0.87       4\n",
      "0.31       4\n",
      "1.12       4\n",
      "0.67       4\n",
      "0.77       4\n",
      "0.90       3\n",
      "0.50       3\n",
      "0.02       3\n",
      "0.91       3\n",
      "0.69       3\n",
      "1.05       3\n",
      "1.10       3\n",
      "1.01       3\n",
      "1.27       3\n",
      "0.94       3\n",
      "0.70       3\n",
      "0.99       3\n",
      "0.68       3\n",
      "0.84       3\n",
      "1.88       3\n",
      "0.76       3\n",
      "0.72       2\n",
      "0.71       2\n",
      "1.20       2\n",
      "0.93       2\n",
      "0.86       2\n",
      "2.10       2\n",
      "1.04       2\n",
      "0.92       2\n",
      "1.21       2\n",
      "1.28       2\n",
      "1.00       1\n",
      "1.34       1\n",
      "0.01       1\n",
      "0.82       1\n",
      "1.17       1\n",
      "1.07       1\n",
      "2.63       1\n",
      "1.03       1\n",
      "5.88       1\n",
      "3.44       1\n",
      "2.94       1\n",
      "0.89       1\n",
      "3.57       1\n",
      "1.63       1\n",
      "1.57       1\n",
      "0.75       1\n",
      "1.36       1\n",
      "1.26       1\n",
      "1.25       1\n",
      "0.95       1\n",
      "1.14       1\n",
      "2.30       1\n",
      "0.85       1\n",
      "1.47       1\n",
      "1.61       1\n",
      "0.52       1\n",
      "1.09       1\n",
      "2.43       1\n",
      "2.54       1\n",
      "0.81       1\n",
      "1.49       1\n",
      "1.64       1\n",
      "1.06       1\n",
      "1.11       1\n",
      "0.96       1\n",
      "1.42       1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "word_freq_remove\n",
      "0.00    3611\n",
      "0.08      30\n",
      "0.05      20\n",
      "0.50      18\n",
      "0.19      18\n",
      "0.32      17\n",
      "0.16      14\n",
      "0.10      14\n",
      "0.25      14\n",
      "0.40      14\n",
      "0.20      13\n",
      "0.06      12\n",
      "0.31      12\n",
      "0.14      11\n",
      "0.68      11\n",
      "0.38      11\n",
      "0.33      11\n",
      "0.03      10\n",
      "0.23      10\n",
      "0.17      10\n",
      "0.49      10\n",
      "0.09      10\n",
      "0.15       9\n",
      "0.44       8\n",
      "0.45       8\n",
      "0.64       8\n",
      "0.90       8\n",
      "0.13       7\n",
      "0.58       7\n",
      "0.07       7\n",
      "1.47       7\n",
      "0.37       7\n",
      "0.56       6\n",
      "0.27       6\n",
      "0.29       6\n",
      "0.28       6\n",
      "0.86       6\n",
      "0.18       6\n",
      "1.08       6\n",
      "0.11       6\n",
      "0.74       6\n",
      "0.60       6\n",
      "1.05       6\n",
      "0.48       6\n",
      "0.73       6\n",
      "0.41       6\n",
      "0.04       6\n",
      "0.46       6\n",
      "1.12       6\n",
      "0.42       6\n",
      "0.36       6\n",
      "0.67       5\n",
      "0.80       5\n",
      "0.43       5\n",
      "1.63       5\n",
      "1.56       5\n",
      "0.34       5\n",
      "0.61       5\n",
      "0.62       5\n",
      "1.07       5\n",
      "0.65       5\n",
      "0.70       5\n",
      "1.04       5\n",
      "0.26       5\n",
      "0.59       5\n",
      "1.78       4\n",
      "0.24       4\n",
      "0.72       4\n",
      "1.25       4\n",
      "1.96       4\n",
      "1.65       4\n",
      "0.55       4\n",
      "2.22       4\n",
      "0.66       4\n",
      "0.98       4\n",
      "0.02       4\n",
      "0.57       4\n",
      "1.03       4\n",
      "0.53       4\n",
      "0.63       4\n",
      "0.51       4\n",
      "0.22       4\n",
      "1.23       4\n",
      "0.35       4\n",
      "0.94       4\n",
      "2.20       3\n",
      "0.96       3\n",
      "1.00       3\n",
      "1.33       3\n",
      "1.16       3\n",
      "2.28       3\n",
      "0.91       3\n",
      "0.30       3\n",
      "0.69       3\n",
      "0.21       3\n",
      "0.12       3\n",
      "0.76       3\n",
      "1.58       3\n",
      "1.11       3\n",
      "0.39       3\n",
      "0.52       3\n",
      "0.97       3\n",
      "0.54       2\n",
      "0.87       2\n",
      "1.21       2\n",
      "1.06       2\n",
      "0.81       2\n",
      "7.27       2\n",
      "2.25       2\n",
      "0.95       2\n",
      "1.43       2\n",
      "1.41       2\n",
      "1.61       2\n",
      "0.82       2\n",
      "0.47       2\n",
      "3.12       2\n",
      "1.09       2\n",
      "0.93       2\n",
      "2.94       2\n",
      "2.23       2\n",
      "1.02       2\n",
      "1.36       2\n",
      "0.79       2\n",
      "0.84       2\n",
      "4.00       1\n",
      "1.20       1\n",
      "1.45       1\n",
      "1.13       1\n",
      "1.60       1\n",
      "2.18       1\n",
      "1.15       1\n",
      "5.40       1\n",
      "1.34       1\n",
      "1.69       1\n",
      "0.99       1\n",
      "2.29       1\n",
      "2.98       1\n",
      "1.14       1\n",
      "2.30       1\n",
      "2.01       1\n",
      "2.04       1\n",
      "2.00       1\n",
      "1.86       1\n",
      "3.07       1\n",
      "3.27       1\n",
      "2.56       1\n",
      "2.41       1\n",
      "0.83       1\n",
      "2.53       1\n",
      "1.94       1\n",
      "4.08       1\n",
      "1.27       1\n",
      "1.01       1\n",
      "1.37       1\n",
      "1.18       1\n",
      "4.54       1\n",
      "1.38       1\n",
      "2.32       1\n",
      "2.16       1\n",
      "0.85       1\n",
      "1.66       1\n",
      "1.31       1\n",
      "1.28       1\n",
      "2.10       1\n",
      "2.73       1\n",
      "2.46       1\n",
      "0.77       1\n",
      "1.48       1\n",
      "0.88       1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "word_freq_internet\n",
      "0.00     3592\n",
      "0.05       24\n",
      "0.32       19\n",
      "0.17       19\n",
      "0.10       18\n",
      "0.18       17\n",
      "0.33       16\n",
      "0.26       16\n",
      "0.08       15\n",
      "0.16       15\n",
      "0.25       14\n",
      "0.19       14\n",
      "0.35       14\n",
      "0.20       13\n",
      "0.06       12\n",
      "0.12       12\n",
      "0.09       12\n",
      "0.50       11\n",
      "0.28       11\n",
      "0.04       11\n",
      "0.27       11\n",
      "0.29       11\n",
      "0.42       10\n",
      "0.40       10\n",
      "0.52       10\n",
      "0.14       10\n",
      "0.46       10\n",
      "0.07       10\n",
      "0.38       10\n",
      "0.59       10\n",
      "0.57        9\n",
      "0.13        9\n",
      "0.37        8\n",
      "0.31        8\n",
      "0.64        8\n",
      "0.23        8\n",
      "0.45        8\n",
      "0.30        8\n",
      "0.58        7\n",
      "0.21        7\n",
      "0.34        7\n",
      "0.51        7\n",
      "0.53        7\n",
      "0.24        6\n",
      "0.11        6\n",
      "1.08        6\n",
      "0.47        6\n",
      "0.49        6\n",
      "0.84        6\n",
      "0.55        6\n",
      "0.82        6\n",
      "0.43        6\n",
      "0.36        6\n",
      "0.62        6\n",
      "0.63        5\n",
      "1.04        5\n",
      "0.65        5\n",
      "0.83        5\n",
      "0.03        5\n",
      "1.36        5\n",
      "0.02        5\n",
      "0.67        5\n",
      "1.12        5\n",
      "1.16        4\n",
      "0.74        4\n",
      "0.15        4\n",
      "0.54        4\n",
      "0.44        4\n",
      "0.56        4\n",
      "1.28        3\n",
      "1.47        3\n",
      "0.98        3\n",
      "0.99        3\n",
      "0.97        3\n",
      "0.86        3\n",
      "0.79        3\n",
      "0.73        3\n",
      "1.01        3\n",
      "1.41        3\n",
      "1.25        3\n",
      "1.29        3\n",
      "1.20        3\n",
      "0.48        3\n",
      "1.40        3\n",
      "0.71        3\n",
      "0.39        3\n",
      "1.09        2\n",
      "0.60        2\n",
      "1.21        2\n",
      "1.06        2\n",
      "1.39        2\n",
      "0.93        2\n",
      "2.50        2\n",
      "0.61        2\n",
      "1.03        2\n",
      "2.22        2\n",
      "1.17        2\n",
      "1.11        2\n",
      "2.04        2\n",
      "0.22        2\n",
      "0.01        2\n",
      "1.31        2\n",
      "1.85        2\n",
      "3.12        2\n",
      "1.78        2\n",
      "1.00        2\n",
      "1.37        2\n",
      "1.26        2\n",
      "3.57        1\n",
      "2.07        1\n",
      "1.24        1\n",
      "1.27        1\n",
      "1.46        1\n",
      "1.60        1\n",
      "2.95        1\n",
      "0.77        1\n",
      "4.00        1\n",
      "1.57        1\n",
      "2.80        1\n",
      "1.32        1\n",
      "4.23        1\n",
      "0.88        1\n",
      "1.35        1\n",
      "3.19        1\n",
      "2.63        1\n",
      "3.97        1\n",
      "3.04        1\n",
      "0.41        1\n",
      "5.88        1\n",
      "11.11       1\n",
      "0.85        1\n",
      "2.94        1\n",
      "0.72        1\n",
      "1.61        1\n",
      "2.96        1\n",
      "3.33        1\n",
      "2.53        1\n",
      "2.02        1\n",
      "0.91        1\n",
      "1.05        1\n",
      "0.89        1\n",
      "2.24        1\n",
      "2.34        1\n",
      "2.98        1\n",
      "2.45        1\n",
      "1.86        1\n",
      "1.45        1\n",
      "1.10        1\n",
      "1.81        1\n",
      "2.82        1\n",
      "4.62        1\n",
      "3.63        1\n",
      "1.30        1\n",
      "1.33        1\n",
      "6.06        1\n",
      "1.62        1\n",
      "1.19        1\n",
      "0.95        1\n",
      "1.14        1\n",
      "2.20        1\n",
      "0.66        1\n",
      "2.38        1\n",
      "1.58        1\n",
      "0.80        1\n",
      "0.92        1\n",
      "0.68        1\n",
      "1.65        1\n",
      "4.68        1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "word_freq_order\n",
      "0.00    3651\n",
      "0.08      24\n",
      "0.09      24\n",
      "0.80      18\n",
      "0.10      16\n",
      "0.16      15\n",
      "0.23      15\n",
      "0.05      14\n",
      "0.24      14\n",
      "0.32      13\n",
      "0.06      13\n",
      "0.40      13\n",
      "0.20      13\n",
      "0.44      13\n",
      "0.59      12\n",
      "0.29      12\n",
      "0.54      12\n",
      "0.27      12\n",
      "0.28      12\n",
      "0.31      11\n",
      "0.25      11\n",
      "0.58      11\n",
      "0.48      10\n",
      "0.35      10\n",
      "0.38      10\n",
      "0.66      10\n",
      "0.13      10\n",
      "0.57      10\n",
      "0.37       9\n",
      "0.52       9\n",
      "0.75       9\n",
      "0.19       9\n",
      "0.34       9\n",
      "0.87       8\n",
      "0.22       8\n",
      "1.15       7\n",
      "0.07       7\n",
      "0.42       7\n",
      "0.17       7\n",
      "0.65       7\n",
      "0.60       6\n",
      "0.50       6\n",
      "0.68       6\n",
      "1.38       6\n",
      "0.33       6\n",
      "0.36       6\n",
      "0.62       6\n",
      "0.61       6\n",
      "0.56       6\n",
      "0.74       5\n",
      "0.11       5\n",
      "1.28       5\n",
      "1.02       5\n",
      "0.55       5\n",
      "0.49       5\n",
      "0.69       5\n",
      "0.67       5\n",
      "0.91       5\n",
      "1.42       5\n",
      "1.47       5\n",
      "0.82       5\n",
      "0.15       5\n",
      "0.03       4\n",
      "1.04       4\n",
      "0.30       4\n",
      "0.79       4\n",
      "0.90       4\n",
      "0.04       4\n",
      "0.53       4\n",
      "0.76       4\n",
      "0.47       4\n",
      "1.17       4\n",
      "0.43       4\n",
      "0.89       3\n",
      "0.41       3\n",
      "0.83       3\n",
      "0.63       3\n",
      "1.32       3\n",
      "1.63       3\n",
      "0.14       3\n",
      "0.94       3\n",
      "0.39       3\n",
      "1.11       3\n",
      "1.03       3\n",
      "0.12       3\n",
      "0.64       3\n",
      "0.77       3\n",
      "0.02       2\n",
      "0.73       2\n",
      "0.51       2\n",
      "0.21       2\n",
      "0.92       2\n",
      "1.16       2\n",
      "0.88       2\n",
      "1.20       2\n",
      "1.55       2\n",
      "0.71       2\n",
      "0.26       2\n",
      "1.01       2\n",
      "1.30       2\n",
      "0.46       2\n",
      "0.78       2\n",
      "0.97       2\n",
      "1.14       2\n",
      "1.41       2\n",
      "0.70       2\n",
      "0.72       2\n",
      "0.93       2\n",
      "1.33       1\n",
      "2.50       1\n",
      "0.95       1\n",
      "3.23       1\n",
      "2.48       1\n",
      "1.12       1\n",
      "1.08       1\n",
      "0.01       1\n",
      "1.18       1\n",
      "0.99       1\n",
      "1.81       1\n",
      "1.61       1\n",
      "2.29       1\n",
      "1.10       1\n",
      "1.94       1\n",
      "1.69       1\n",
      "1.26       1\n",
      "1.31       1\n",
      "0.84       1\n",
      "0.45       1\n",
      "3.33       1\n",
      "0.85       1\n",
      "1.09       1\n",
      "1.43       1\n",
      "1.34       1\n",
      "1.35       1\n",
      "2.38       1\n",
      "2.35       1\n",
      "1.21       1\n",
      "2.59       1\n",
      "1.27       1\n",
      "1.49       1\n",
      "2.12       1\n",
      "1.52       1\n",
      "1.36       1\n",
      "5.26       1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "word_freq_mail\n",
      "0.00     3133\n",
      "0.08       27\n",
      "0.39       24\n",
      "0.10       22\n",
      "0.27       20\n",
      "0.17       20\n",
      "0.29       20\n",
      "0.19       18\n",
      "0.35       18\n",
      "0.23       17\n",
      "0.75       17\n",
      "0.49       17\n",
      "0.05       16\n",
      "0.68       16\n",
      "0.16       15\n",
      "1.47       15\n",
      "0.36       14\n",
      "0.80       14\n",
      "0.43       13\n",
      "0.12       13\n",
      "0.45       13\n",
      "0.31       13\n",
      "0.81       13\n",
      "0.20       13\n",
      "0.42       12\n",
      "0.54       12\n",
      "0.51       11\n",
      "0.52       11\n",
      "0.55       11\n",
      "0.11       11\n",
      "0.33       11\n",
      "0.56       11\n",
      "0.40       11\n",
      "0.58       11\n",
      "0.21       11\n",
      "0.69       10\n",
      "0.53       10\n",
      "0.76       10\n",
      "0.62       10\n",
      "0.47       10\n",
      "0.66       10\n",
      "0.38       10\n",
      "0.13       10\n",
      "0.64        9\n",
      "0.22        9\n",
      "1.32        9\n",
      "0.65        9\n",
      "0.50        9\n",
      "0.67        9\n",
      "0.37        9\n",
      "0.57        8\n",
      "0.63        8\n",
      "0.78        8\n",
      "0.93        8\n",
      "0.06        8\n",
      "0.82        8\n",
      "0.09        8\n",
      "0.41        8\n",
      "0.74        8\n",
      "1.02        8\n",
      "0.84        8\n",
      "1.19        7\n",
      "0.61        7\n",
      "1.01        7\n",
      "1.12        7\n",
      "0.97        7\n",
      "1.63        7\n",
      "0.26        7\n",
      "0.48        7\n",
      "0.44        7\n",
      "1.04        6\n",
      "0.87        6\n",
      "0.25        6\n",
      "0.34        6\n",
      "1.88        6\n",
      "0.24        6\n",
      "1.56        6\n",
      "1.25        6\n",
      "1.08        6\n",
      "1.15        5\n",
      "0.28        5\n",
      "0.32        5\n",
      "0.59        5\n",
      "0.79        5\n",
      "1.21        5\n",
      "1.20        5\n",
      "1.05        5\n",
      "0.94        5\n",
      "1.07        5\n",
      "1.49        5\n",
      "0.15        5\n",
      "0.83        5\n",
      "1.36        5\n",
      "1.81        5\n",
      "1.31        5\n",
      "0.14        5\n",
      "0.77        5\n",
      "1.80        4\n",
      "0.72        4\n",
      "0.30        4\n",
      "0.46        4\n",
      "1.35        4\n",
      "1.16        4\n",
      "0.95        4\n",
      "1.78        4\n",
      "0.88        4\n",
      "1.59        4\n",
      "0.73        4\n",
      "0.71        4\n",
      "2.43        4\n",
      "1.44        4\n",
      "1.28        4\n",
      "1.23        4\n",
      "0.91        4\n",
      "1.03        3\n",
      "2.00        3\n",
      "2.38        3\n",
      "0.04        3\n",
      "1.18        3\n",
      "0.98        3\n",
      "0.60        3\n",
      "1.85        3\n",
      "1.11        3\n",
      "0.85        3\n",
      "1.09        3\n",
      "2.32        3\n",
      "1.27        3\n",
      "2.56        3\n",
      "1.00        3\n",
      "1.38        3\n",
      "1.96        3\n",
      "0.07        3\n",
      "2.17        3\n",
      "0.90        3\n",
      "1.92        3\n",
      "1.72        3\n",
      "1.40        3\n",
      "1.45        3\n",
      "1.33        3\n",
      "3.77        3\n",
      "1.29        3\n",
      "0.18        3\n",
      "0.70        3\n",
      "1.24        3\n",
      "3.70        2\n",
      "1.94        2\n",
      "5.26        2\n",
      "1.66        2\n",
      "1.34        2\n",
      "1.57        2\n",
      "2.50        2\n",
      "1.70        2\n",
      "2.48        2\n",
      "2.12        2\n",
      "1.17        2\n",
      "3.33        2\n",
      "1.54        2\n",
      "4.09        2\n",
      "1.22        2\n",
      "1.13        2\n",
      "1.30        2\n",
      "1.50        2\n",
      "0.99        2\n",
      "0.92        2\n",
      "1.26        2\n",
      "1.14        2\n",
      "2.88        2\n",
      "0.96        2\n",
      "1.74        2\n",
      "2.35        2\n",
      "1.51        2\n",
      "0.86        2\n",
      "1.79        2\n",
      "1.86        2\n",
      "1.76        2\n",
      "1.62        2\n",
      "3.00        1\n",
      "2.63        1\n",
      "1.60        1\n",
      "1.06        1\n",
      "1.61        1\n",
      "1.37        1\n",
      "4.54        1\n",
      "1.83        1\n",
      "2.65        1\n",
      "5.12        1\n",
      "1.55        1\n",
      "1.10        1\n",
      "18.18       1\n",
      "1.46        1\n",
      "1.71        1\n",
      "2.80        1\n",
      "1.82        1\n",
      "4.70        1\n",
      "2.64        1\n",
      "2.55        1\n",
      "1.43        1\n",
      "3.03        1\n",
      "2.70        1\n",
      "1.42        1\n",
      "2.27        1\n",
      "2.77        1\n",
      "4.76        1\n",
      "2.36        1\n",
      "0.03        1\n",
      "4.32        1\n",
      "11.11       1\n",
      "3.91        1\n",
      "1.52        1\n",
      "1.58        1\n",
      "0.01        1\n",
      "1.91        1\n",
      "4.10        1\n",
      "4.81        1\n",
      "3.78        1\n",
      "2.75        1\n",
      "1.67        1\n",
      "4.25        1\n",
      "3.57        1\n",
      "3.75        1\n",
      "3.92        1\n",
      "2.02        1\n",
      "2.86        1\n",
      "1.89        1\n",
      "1.90        1\n",
      "2.11        1\n",
      "1.95        1\n",
      "5.00        1\n",
      "1.41        1\n",
      "2.22        1\n",
      "1.68        1\n",
      "7.55        1\n",
      "2.73        1\n",
      "1.65        1\n",
      "2.41        1\n",
      "2.09        1\n",
      "3.68        1\n",
      "2.40        1\n",
      "0.89        1\n",
      "2.98        1\n",
      "2.68        1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "word_freq_receive\n",
      "0.00    3714\n",
      "0.10      27\n",
      "0.17      25\n",
      "0.26      25\n",
      "0.30      23\n",
      "0.14      20\n",
      "0.29      20\n",
      "0.08      19\n",
      "0.31      19\n",
      "0.11      17\n",
      "0.23      17\n",
      "0.12      16\n",
      "0.34      16\n",
      "0.39      15\n",
      "0.09      15\n",
      "0.25      14\n",
      "0.38      14\n",
      "0.27      14\n",
      "0.36      13\n",
      "0.48      13\n",
      "0.20      12\n",
      "0.05      12\n",
      "2.00      11\n",
      "0.28      11\n",
      "0.16      11\n",
      "0.33      11\n",
      "0.40       9\n",
      "0.06       9\n",
      "0.15       9\n",
      "0.21       9\n",
      "0.22       8\n",
      "0.72       8\n",
      "0.54       8\n",
      "0.19       8\n",
      "0.24       8\n",
      "0.35       7\n",
      "0.47       7\n",
      "0.13       6\n",
      "0.42       6\n",
      "0.74       6\n",
      "0.37       6\n",
      "0.32       5\n",
      "0.64       5\n",
      "0.18       5\n",
      "0.02       5\n",
      "0.50       5\n",
      "0.58       5\n",
      "0.46       5\n",
      "0.07       5\n",
      "0.41       5\n",
      "1.47       5\n",
      "0.62       4\n",
      "0.68       4\n",
      "0.03       4\n",
      "0.65       4\n",
      "0.52       4\n",
      "0.76       3\n",
      "0.55       3\n",
      "1.36       3\n",
      "0.78       3\n",
      "1.02       3\n",
      "0.45       3\n",
      "0.90       3\n",
      "1.20       3\n",
      "1.21       3\n",
      "0.60       3\n",
      "0.04       3\n",
      "0.44       3\n",
      "0.96       3\n",
      "0.67       2\n",
      "0.73       2\n",
      "0.71       2\n",
      "1.11       2\n",
      "0.57       2\n",
      "0.84       2\n",
      "0.49       2\n",
      "0.43       2\n",
      "0.56       2\n",
      "1.23       2\n",
      "0.63       2\n",
      "0.66       1\n",
      "1.07       1\n",
      "0.83       1\n",
      "0.87       1\n",
      "0.86       1\n",
      "0.53       1\n",
      "1.31       1\n",
      "0.77       1\n",
      "0.61       1\n",
      "0.99       1\n",
      "1.10       1\n",
      "1.26       1\n",
      "1.51       1\n",
      "0.91       1\n",
      "1.28       1\n",
      "1.63       1\n",
      "1.22       1\n",
      "1.53       1\n",
      "0.89       1\n",
      "2.61       1\n",
      "0.75       1\n",
      "1.65       1\n",
      "0.98       1\n",
      "0.70       1\n",
      "1.29       1\n",
      "0.82       1\n",
      "2.06       1\n",
      "1.15       1\n",
      "0.51       1\n",
      "1.12       1\n",
      "0.93       1\n",
      "1.05       1\n",
      "0.88       1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "word_freq_will\n",
      "0.00    2155\n",
      "0.33      33\n",
      "0.64      32\n",
      "0.32      28\n",
      "0.55      28\n",
      "0.72      25\n",
      "0.54      25\n",
      "0.70      24\n",
      "0.30      23\n",
      "0.50      23\n",
      "0.68      23\n",
      "0.52      23\n",
      "0.60      22\n",
      "0.34      22\n",
      "0.31      22\n",
      "0.84      21\n",
      "0.59      21\n",
      "0.25      21\n",
      "0.38      20\n",
      "0.51      20\n",
      "0.47      19\n",
      "0.62      19\n",
      "0.56      19\n",
      "0.36      19\n",
      "0.81      19\n",
      "0.76      19\n",
      "1.31      19\n",
      "0.85      18\n",
      "0.90      18\n",
      "0.45      18\n",
      "0.27      17\n",
      "0.65      17\n",
      "0.57      17\n",
      "0.44      17\n",
      "0.41      17\n",
      "0.24      16\n",
      "2.00      16\n",
      "0.71      16\n",
      "0.69      16\n",
      "1.28      16\n",
      "1.06      16\n",
      "0.73      16\n",
      "0.80      15\n",
      "0.88      15\n",
      "0.97      15\n",
      "0.98      15\n",
      "0.48      15\n",
      "0.43      15\n",
      "1.29      15\n",
      "0.26      15\n",
      "0.79      14\n",
      "0.58      14\n",
      "0.46      14\n",
      "0.28      14\n",
      "1.04      14\n",
      "1.07      14\n",
      "0.19      14\n",
      "0.95      13\n",
      "0.42      13\n",
      "0.74      13\n",
      "0.63      13\n",
      "1.38      13\n",
      "0.86      13\n",
      "0.39      12\n",
      "0.75      12\n",
      "0.40      12\n",
      "1.16      12\n",
      "1.00      12\n",
      "0.37      12\n",
      "0.89      12\n",
      "0.78      12\n",
      "0.35      11\n",
      "1.58      11\n",
      "1.30      11\n",
      "1.01      11\n",
      "0.66      11\n",
      "0.99      11\n",
      "0.29      11\n",
      "0.96      11\n",
      "1.09      11\n",
      "0.67      11\n",
      "0.92      11\n",
      "0.53      11\n",
      "0.49      10\n",
      "0.82      10\n",
      "1.03      10\n",
      "1.02      10\n",
      "0.15      10\n",
      "1.25      10\n",
      "1.17      10\n",
      "1.40      10\n",
      "0.22       9\n",
      "0.18       9\n",
      "0.77       9\n",
      "0.87       9\n",
      "1.23       9\n",
      "1.19       9\n",
      "1.43       9\n",
      "0.09       8\n",
      "1.49       8\n",
      "1.14       8\n",
      "1.51       8\n",
      "0.16       8\n",
      "1.33       8\n",
      "1.61       8\n",
      "0.23       8\n",
      "0.17       8\n",
      "0.14       7\n",
      "0.93       7\n",
      "1.05       7\n",
      "1.37       7\n",
      "0.94       7\n",
      "3.57       7\n",
      "0.61       7\n",
      "1.57       7\n",
      "0.83       7\n",
      "0.13       7\n",
      "1.75       7\n",
      "2.18       7\n",
      "1.24       7\n",
      "1.81       7\n",
      "1.78       6\n",
      "2.32       6\n",
      "3.33       6\n",
      "2.38       6\n",
      "1.69       6\n",
      "1.27       6\n",
      "1.72       6\n",
      "1.11       6\n",
      "1.21       6\n",
      "1.48       6\n",
      "1.26       6\n",
      "1.44       6\n",
      "2.22       5\n",
      "0.21       5\n",
      "1.90       5\n",
      "1.39       5\n",
      "1.12       5\n",
      "1.41       5\n",
      "1.56       5\n",
      "1.42       5\n",
      "0.91       5\n",
      "1.85       5\n",
      "3.03       5\n",
      "2.08       5\n",
      "1.60       5\n",
      "1.62       5\n",
      "2.63       5\n",
      "1.53       5\n",
      "1.59       5\n",
      "1.66       5\n",
      "2.07       5\n",
      "1.15       5\n",
      "1.22       5\n",
      "1.91       5\n",
      "1.36       5\n",
      "1.63       4\n",
      "2.40       4\n",
      "2.25       4\n",
      "2.17       4\n",
      "5.26       4\n",
      "0.12       4\n",
      "1.13       4\n",
      "1.47       4\n",
      "2.35       4\n",
      "4.76       4\n",
      "0.11       4\n",
      "3.17       4\n",
      "2.94       4\n",
      "1.52       4\n",
      "4.54       4\n",
      "0.10       4\n",
      "1.92       4\n",
      "2.58       4\n",
      "1.20       4\n",
      "2.46       4\n",
      "2.13       4\n",
      "1.84       4\n",
      "1.35       4\n",
      "1.45       3\n",
      "3.22       3\n",
      "0.06       3\n",
      "1.10       3\n",
      "1.46       3\n",
      "2.70       3\n",
      "2.85       3\n",
      "5.88       3\n",
      "2.81       3\n",
      "3.70       3\n",
      "1.67       3\n",
      "1.08       3\n",
      "4.16       3\n",
      "1.96       3\n",
      "2.04       3\n",
      "1.34       3\n",
      "2.52       3\n",
      "2.29       3\n",
      "2.43       3\n",
      "1.80       3\n",
      "0.02       3\n",
      "3.12       3\n",
      "2.06       3\n",
      "2.50       3\n",
      "1.18       3\n",
      "2.27       3\n",
      "1.74       3\n",
      "1.94       3\n",
      "1.55       3\n",
      "0.20       3\n",
      "4.34       2\n",
      "2.24       2\n",
      "2.01       2\n",
      "1.71       2\n",
      "2.26       2\n",
      "7.69       2\n",
      "3.44       2\n",
      "6.25       2\n",
      "2.89       2\n",
      "3.63       2\n",
      "2.77       2\n",
      "1.32       2\n",
      "1.97       2\n",
      "3.84       2\n",
      "4.58       2\n",
      "5.00       2\n",
      "2.53       2\n",
      "1.98       2\n",
      "1.73       2\n",
      "2.12       2\n",
      "1.76       2\n",
      "1.65       2\n",
      "2.05       2\n",
      "2.65       2\n",
      "2.80       2\n",
      "2.10       2\n",
      "2.75       2\n",
      "1.86       2\n",
      "0.07       2\n",
      "1.88       2\n",
      "2.33       2\n",
      "0.08       2\n",
      "2.31       2\n",
      "3.92       2\n",
      "1.50       2\n",
      "2.23       1\n",
      "0.05       1\n",
      "9.67       1\n",
      "2.99       1\n",
      "3.25       1\n",
      "3.00       1\n",
      "5.55       1\n",
      "1.70       1\n",
      "6.29       1\n",
      "3.52       1\n",
      "4.28       1\n",
      "4.42       1\n",
      "2.60       1\n",
      "4.22       1\n",
      "2.90       1\n",
      "1.68       1\n",
      "4.09       1\n",
      "3.72       1\n",
      "3.27       1\n",
      "2.02       1\n",
      "2.09       1\n",
      "4.08       1\n",
      "4.72       1\n",
      "3.26       1\n",
      "3.94       1\n",
      "1.93       1\n",
      "4.65       1\n",
      "3.75       1\n",
      "2.42       1\n",
      "6.45       1\n",
      "4.61       1\n",
      "2.61       1\n",
      "1.79       1\n",
      "1.83       1\n",
      "3.39       1\n",
      "3.66       1\n",
      "3.32       1\n",
      "5.12       1\n",
      "2.15       1\n",
      "2.39       1\n",
      "3.76       1\n",
      "0.04       1\n",
      "1.89       1\n",
      "2.30       1\n",
      "4.10       1\n",
      "1.82       1\n",
      "2.64       1\n",
      "3.10       1\n",
      "3.09       1\n",
      "2.76       1\n",
      "2.73       1\n",
      "3.79       1\n",
      "4.90       1\n",
      "3.19       1\n",
      "2.28       1\n",
      "4.25       1\n",
      "2.19       1\n",
      "3.38       1\n",
      "2.48       1\n",
      "3.97       1\n",
      "3.08       1\n",
      "1.54       1\n",
      "2.88       1\n",
      "2.49       1\n",
      "2.16       1\n",
      "2.14       1\n",
      "6.06       1\n",
      "3.30       1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "word_freq_people\n",
      "0.00    3565\n",
      "0.17      42\n",
      "0.30      29\n",
      "0.19      28\n",
      "0.32      26\n",
      "0.27      19\n",
      "0.25      17\n",
      "0.12      16\n",
      "0.29      15\n",
      "0.20      15\n",
      "0.38      15\n",
      "0.08      15\n",
      "0.65      14\n",
      "0.14      14\n",
      "0.31      14\n",
      "0.28      12\n",
      "0.11      12\n",
      "0.22      12\n",
      "0.09      12\n",
      "0.54      12\n",
      "0.06      12\n",
      "0.37      12\n",
      "0.16      11\n",
      "0.10      10\n",
      "0.56      10\n",
      "0.60      10\n",
      "0.15      10\n",
      "0.55       9\n",
      "0.13       9\n",
      "0.90       8\n",
      "0.40       8\n",
      "0.52       8\n",
      "0.66       8\n",
      "0.21       8\n",
      "0.33       8\n",
      "0.42       8\n",
      "0.26       7\n",
      "0.46       7\n",
      "0.58       7\n",
      "0.93       7\n",
      "0.47       7\n",
      "0.57       7\n",
      "0.87       7\n",
      "0.62       7\n",
      "0.48       6\n",
      "0.41       6\n",
      "0.92       6\n",
      "0.23       6\n",
      "0.79       6\n",
      "0.45       6\n",
      "0.61       6\n",
      "0.86       6\n",
      "0.67       5\n",
      "0.07       5\n",
      "0.68       5\n",
      "0.51       5\n",
      "0.76       5\n",
      "0.59       5\n",
      "0.18       5\n",
      "0.34       5\n",
      "0.44       4\n",
      "0.03       4\n",
      "0.04       4\n",
      "0.50       4\n",
      "0.53       4\n",
      "0.74       4\n",
      "0.24       4\n",
      "0.80       4\n",
      "0.78       4\n",
      "0.05       4\n",
      "0.39       3\n",
      "1.29       3\n",
      "0.02       3\n",
      "0.69       3\n",
      "0.35       3\n",
      "0.91       3\n",
      "0.94       3\n",
      "1.47       3\n",
      "0.89       3\n",
      "0.43       3\n",
      "1.01       3\n",
      "1.52       3\n",
      "5.55       3\n",
      "0.36       3\n",
      "1.54       2\n",
      "0.70       2\n",
      "1.00       2\n",
      "1.58       2\n",
      "1.33       2\n",
      "1.06       2\n",
      "0.81       2\n",
      "0.97       2\n",
      "0.49       2\n",
      "1.40       2\n",
      "1.44       2\n",
      "1.53       2\n",
      "0.73       2\n",
      "1.08       2\n",
      "1.81       2\n",
      "1.85       2\n",
      "1.09       2\n",
      "1.10       2\n",
      "0.84       2\n",
      "0.72       2\n",
      "1.26       2\n",
      "0.63       2\n",
      "0.71       2\n",
      "0.95       2\n",
      "1.62       1\n",
      "1.39       1\n",
      "1.12       1\n",
      "1.16       1\n",
      "1.91       1\n",
      "1.88       1\n",
      "1.37       1\n",
      "1.49       1\n",
      "2.46       1\n",
      "0.82       1\n",
      "1.25       1\n",
      "1.36       1\n",
      "0.01       1\n",
      "1.17       1\n",
      "1.80       1\n",
      "1.02       1\n",
      "2.94       1\n",
      "1.50       1\n",
      "2.22       1\n",
      "0.99       1\n",
      "1.13       1\n",
      "1.03       1\n",
      "2.56       1\n",
      "1.15       1\n",
      "1.32       1\n",
      "1.72       1\n",
      "2.58       1\n",
      "0.98       1\n",
      "1.38       1\n",
      "1.20       1\n",
      "1.51       1\n",
      "0.64       1\n",
      "0.75       1\n",
      "1.60       1\n",
      "1.21       1\n",
      "2.04       1\n",
      "0.85       1\n",
      "1.61       1\n",
      "1.76       1\n",
      "1.56       1\n",
      "2.63       1\n",
      "1.05       1\n",
      "2.71       1\n",
      "1.11       1\n",
      "0.83       1\n",
      "2.38       1\n",
      "1.41       1\n",
      "2.50       1\n",
      "0.96       1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "word_freq_report\n",
      "0.00     4040\n",
      "0.36       18\n",
      "0.08       16\n",
      "0.05       14\n",
      "0.17       12\n",
      "0.06        9\n",
      "0.11        8\n",
      "1.19        8\n",
      "0.19        8\n",
      "0.07        8\n",
      "0.09        7\n",
      "0.87        6\n",
      "0.16        6\n",
      "0.10        6\n",
      "0.60        6\n",
      "0.58        6\n",
      "0.20        5\n",
      "1.69        5\n",
      "1.23        5\n",
      "1.27        4\n",
      "0.13        4\n",
      "0.33        4\n",
      "0.23        4\n",
      "1.26        4\n",
      "0.37        4\n",
      "0.38        4\n",
      "2.06        4\n",
      "0.14        3\n",
      "0.22        3\n",
      "0.46        3\n",
      "2.94        3\n",
      "1.28        3\n",
      "1.48        3\n",
      "1.20        3\n",
      "1.08        3\n",
      "0.66        3\n",
      "0.32        3\n",
      "1.06        3\n",
      "1.14        3\n",
      "0.34        3\n",
      "0.12        3\n",
      "0.03        2\n",
      "0.92        2\n",
      "0.28        2\n",
      "0.47        2\n",
      "0.45        2\n",
      "0.44        2\n",
      "2.04        2\n",
      "1.75        2\n",
      "0.51        2\n",
      "0.02        2\n",
      "0.25        2\n",
      "0.54        2\n",
      "1.07        2\n",
      "2.32        2\n",
      "0.88        2\n",
      "1.15        2\n",
      "1.49        2\n",
      "0.95        2\n",
      "1.24        2\n",
      "0.18        2\n",
      "0.67        2\n",
      "1.09        2\n",
      "5.12        1\n",
      "2.63        1\n",
      "0.98        1\n",
      "0.80        1\n",
      "5.55        1\n",
      "3.44        1\n",
      "1.36        1\n",
      "0.74        1\n",
      "1.78        1\n",
      "1.03        1\n",
      "1.35        1\n",
      "2.08        1\n",
      "0.15        1\n",
      "0.01        1\n",
      "1.17        1\n",
      "0.86        1\n",
      "1.61        1\n",
      "1.58        1\n",
      "4.34        1\n",
      "10.00       1\n",
      "0.76        1\n",
      "2.85        1\n",
      "1.82        1\n",
      "0.31        1\n",
      "0.24        1\n",
      "1.96        1\n",
      "1.67        1\n",
      "3.84        1\n",
      "2.50        1\n",
      "1.79        1\n",
      "0.26        1\n",
      "1.39        1\n",
      "0.85        1\n",
      "0.91        1\n",
      "0.48        1\n",
      "0.52        1\n",
      "0.70        1\n",
      "0.69        1\n",
      "0.49        1\n",
      "0.53        1\n",
      "1.32        1\n",
      "0.39        1\n",
      "2.10        1\n",
      "1.16        1\n",
      "1.05        1\n",
      "2.61        1\n",
      "3.12        1\n",
      "4.76        1\n",
      "0.30        1\n",
      "1.41        1\n",
      "1.22        1\n",
      "1.56        1\n",
      "1.65        1\n",
      "1.34        1\n",
      "1.43        1\n",
      "1.04        1\n",
      "1.80        1\n",
      "1.10        1\n",
      "2.05        1\n",
      "0.83        1\n",
      "0.89        1\n",
      "0.40        1\n",
      "0.73        1\n",
      "0.27        1\n",
      "0.35        1\n",
      "0.64        1\n",
      "1.29        1\n",
      "0.21        1\n",
      "1.59        1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "word_freq_addresses\n",
      "0.00    4041\n",
      "0.03      21\n",
      "1.61      12\n",
      "0.18      10\n",
      "0.17      10\n",
      "0.05       9\n",
      "0.16       9\n",
      "0.14       8\n",
      "1.15       8\n",
      "0.02       8\n",
      "2.21       8\n",
      "0.34       7\n",
      "0.12       6\n",
      "0.09       6\n",
      "0.26       5\n",
      "0.15       5\n",
      "0.13       5\n",
      "0.29       5\n",
      "2.31       4\n",
      "0.66       4\n",
      "0.68       4\n",
      "0.62       4\n",
      "0.32       4\n",
      "0.20       4\n",
      "0.25       4\n",
      "1.10       3\n",
      "0.63       3\n",
      "1.14       3\n",
      "0.19       3\n",
      "0.50       3\n",
      "0.69       3\n",
      "0.24       3\n",
      "0.47       3\n",
      "0.07       3\n",
      "2.12       3\n",
      "0.39       3\n",
      "0.78       3\n",
      "1.27       3\n",
      "0.28       3\n",
      "0.06       3\n",
      "0.08       3\n",
      "0.65       2\n",
      "1.50       2\n",
      "0.37       2\n",
      "1.16       2\n",
      "1.28       2\n",
      "0.60       2\n",
      "0.71       2\n",
      "0.58       2\n",
      "0.61       2\n",
      "0.10       2\n",
      "0.42       2\n",
      "0.40       2\n",
      "1.04       2\n",
      "0.55       2\n",
      "0.44       2\n",
      "0.35       2\n",
      "0.30       2\n",
      "0.23       2\n",
      "0.76       2\n",
      "1.92       2\n",
      "0.45       2\n",
      "1.46       2\n",
      "2.16       2\n",
      "1.00       2\n",
      "1.49       1\n",
      "4.41       1\n",
      "0.41       1\n",
      "0.01       1\n",
      "0.46       1\n",
      "0.59       1\n",
      "2.24       1\n",
      "1.19       1\n",
      "0.27       1\n",
      "1.94       1\n",
      "0.33       1\n",
      "0.51       1\n",
      "1.11       1\n",
      "0.83       1\n",
      "1.75       1\n",
      "0.86       1\n",
      "0.81       1\n",
      "1.44       1\n",
      "1.47       1\n",
      "1.70       1\n",
      "0.84       1\n",
      "1.17       1\n",
      "1.58       1\n",
      "2.38       1\n",
      "1.51       1\n",
      "1.66       1\n",
      "1.57       1\n",
      "0.89       1\n",
      "2.22       1\n",
      "1.07       1\n",
      "0.22       1\n",
      "2.06       1\n",
      "1.81       1\n",
      "1.42       1\n",
      "0.31       1\n",
      "0.97       1\n",
      "0.79       1\n",
      "0.54       1\n",
      "0.53       1\n",
      "1.88       1\n",
      "1.60       1\n",
      "0.04       1\n",
      "0.77       1\n",
      "1.02       1\n",
      "2.09       1\n",
      "2.05       1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "word_freq_free\n",
      "0.00     3205\n",
      "0.10       33\n",
      "0.32       30\n",
      "0.25       23\n",
      "0.23       22\n",
      "0.38       21\n",
      "0.19       18\n",
      "0.08       17\n",
      "0.14       17\n",
      "0.58       17\n",
      "0.13       16\n",
      "0.48       16\n",
      "0.26       16\n",
      "0.36       15\n",
      "0.47       15\n",
      "0.30       15\n",
      "0.17       14\n",
      "0.80       13\n",
      "0.11       13\n",
      "0.09       13\n",
      "0.44       12\n",
      "0.64       12\n",
      "0.29       12\n",
      "0.49       12\n",
      "0.54       12\n",
      "0.31       12\n",
      "0.66       12\n",
      "0.37       11\n",
      "0.55       11\n",
      "0.40       11\n",
      "0.98       11\n",
      "0.41       11\n",
      "0.68       11\n",
      "0.27       11\n",
      "0.45       11\n",
      "0.22       11\n",
      "0.60       11\n",
      "0.33       10\n",
      "0.50       10\n",
      "0.21       10\n",
      "0.16       10\n",
      "0.24       10\n",
      "0.62       10\n",
      "0.56       10\n",
      "0.87        9\n",
      "0.86        9\n",
      "0.34        8\n",
      "0.82        8\n",
      "1.61        8\n",
      "0.05        8\n",
      "0.43        8\n",
      "0.35        8\n",
      "1.11        8\n",
      "1.25        7\n",
      "0.70        7\n",
      "1.05        7\n",
      "0.12        7\n",
      "1.28        7\n",
      "0.51        7\n",
      "0.78        6\n",
      "0.79        6\n",
      "0.20        6\n",
      "0.90        6\n",
      "0.46        6\n",
      "0.69        6\n",
      "0.53        6\n",
      "0.81        6\n",
      "0.15        6\n",
      "0.06        6\n",
      "0.77        6\n",
      "0.42        6\n",
      "2.94        6\n",
      "0.91        5\n",
      "0.52        5\n",
      "0.63        5\n",
      "1.36        5\n",
      "0.39        5\n",
      "0.61        5\n",
      "0.74        5\n",
      "1.63        5\n",
      "0.92        5\n",
      "0.57        5\n",
      "1.26        5\n",
      "0.96        5\n",
      "1.23        5\n",
      "1.33        5\n",
      "1.44        4\n",
      "2.04        4\n",
      "1.65        4\n",
      "0.02        4\n",
      "0.59        4\n",
      "0.94        4\n",
      "2.17        4\n",
      "1.13        4\n",
      "1.19        4\n",
      "0.88        4\n",
      "0.84        4\n",
      "0.72        4\n",
      "2.22        4\n",
      "0.71        4\n",
      "1.81        4\n",
      "1.85        4\n",
      "0.67        4\n",
      "0.03        4\n",
      "1.35        3\n",
      "2.06        3\n",
      "1.56        3\n",
      "0.99        3\n",
      "2.40        3\n",
      "0.28        3\n",
      "1.38        3\n",
      "1.01        3\n",
      "0.07        3\n",
      "2.50        3\n",
      "1.41        3\n",
      "1.03        3\n",
      "1.34        3\n",
      "1.72        3\n",
      "1.74        3\n",
      "0.76        3\n",
      "0.85        3\n",
      "0.65        3\n",
      "4.00        3\n",
      "1.29        3\n",
      "3.33        3\n",
      "1.16        3\n",
      "1.57        3\n",
      "0.83        3\n",
      "1.08        3\n",
      "1.07        2\n",
      "2.83        2\n",
      "1.40        2\n",
      "2.15        2\n",
      "2.91        2\n",
      "0.75        2\n",
      "2.46        2\n",
      "3.34        2\n",
      "1.42        2\n",
      "1.31        2\n",
      "2.47        2\n",
      "1.98        2\n",
      "2.43        2\n",
      "7.35        2\n",
      "1.00        2\n",
      "1.04        2\n",
      "0.97        2\n",
      "1.47        2\n",
      "1.39        2\n",
      "1.88        2\n",
      "1.06        2\n",
      "1.66        2\n",
      "7.69        2\n",
      "3.03        2\n",
      "1.10        2\n",
      "2.63        2\n",
      "1.09        2\n",
      "0.73        2\n",
      "1.96        2\n",
      "2.08        2\n",
      "2.59        2\n",
      "1.49        2\n",
      "0.93        2\n",
      "1.43        2\n",
      "3.70        2\n",
      "1.92        2\n",
      "1.80        2\n",
      "0.01        2\n",
      "2.32        2\n",
      "20.00       2\n",
      "1.82        2\n",
      "1.14        2\n",
      "2.13        2\n",
      "1.30        2\n",
      "3.12        2\n",
      "1.68        2\n",
      "1.02        2\n",
      "0.89        2\n",
      "1.75        2\n",
      "6.25        2\n",
      "0.95        2\n",
      "2.10        1\n",
      "6.02        1\n",
      "3.07        1\n",
      "4.91        1\n",
      "1.78        1\n",
      "6.09        1\n",
      "2.12        1\n",
      "5.35        1\n",
      "4.27        1\n",
      "1.52        1\n",
      "3.35        1\n",
      "4.97        1\n",
      "4.54        1\n",
      "5.91        1\n",
      "2.58        1\n",
      "1.55        1\n",
      "3.57        1\n",
      "1.46        1\n",
      "2.42        1\n",
      "3.26        1\n",
      "2.81        1\n",
      "1.27        1\n",
      "3.15        1\n",
      "10.00       1\n",
      "1.22        1\n",
      "3.38        1\n",
      "2.16        1\n",
      "1.12        1\n",
      "3.89        1\n",
      "2.20        1\n",
      "2.77        1\n",
      "4.76        1\n",
      "1.45        1\n",
      "2.23        1\n",
      "1.50        1\n",
      "1.59        1\n",
      "2.25        1\n",
      "2.07        1\n",
      "6.52        1\n",
      "1.24        1\n",
      "10.16       1\n",
      "5.40        1\n",
      "0.18        1\n",
      "3.54        1\n",
      "1.64        1\n",
      "1.94        1\n",
      "6.45        1\n",
      "4.65        1\n",
      "2.98        1\n",
      "2.00        1\n",
      "3.51        1\n",
      "1.93        1\n",
      "2.14        1\n",
      "1.54        1\n",
      "2.56        1\n",
      "2.85        1\n",
      "3.27        1\n",
      "5.00        1\n",
      "1.89        1\n",
      "4.59        1\n",
      "1.95        1\n",
      "1.18        1\n",
      "1.97        1\n",
      "1.21        1\n",
      "2.75        1\n",
      "1.58        1\n",
      "1.86        1\n",
      "1.87        1\n",
      "0.04        1\n",
      "3.97        1\n",
      "1.17        1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "word_freq_business\n",
      "0.00    3459\n",
      "0.32      26\n",
      "0.08      24\n",
      "0.37      21\n",
      "0.19      19\n",
      "0.10      18\n",
      "0.17      17\n",
      "0.70      16\n",
      "0.44      16\n",
      "0.20      16\n",
      "0.54      15\n",
      "0.12      14\n",
      "0.53      14\n",
      "0.36      13\n",
      "0.09      13\n",
      "0.48      12\n",
      "0.24      12\n",
      "0.33      12\n",
      "0.27      11\n",
      "0.14      11\n",
      "0.69      11\n",
      "0.30      11\n",
      "0.43      11\n",
      "0.13      10\n",
      "0.34      10\n",
      "0.62      10\n",
      "0.42      10\n",
      "0.11      10\n",
      "0.72      10\n",
      "0.58      10\n",
      "0.46      10\n",
      "0.22      10\n",
      "0.64       9\n",
      "0.29       9\n",
      "0.41       9\n",
      "0.31       9\n",
      "0.28       9\n",
      "0.23       8\n",
      "0.25       8\n",
      "0.45       8\n",
      "0.96       8\n",
      "0.06       8\n",
      "0.47       7\n",
      "0.50       7\n",
      "0.15       7\n",
      "0.80       7\n",
      "0.52       7\n",
      "0.05       7\n",
      "0.95       7\n",
      "0.76       7\n",
      "0.39       6\n",
      "0.90       6\n",
      "0.40       6\n",
      "0.38       6\n",
      "0.07       6\n",
      "0.60       6\n",
      "0.68       6\n",
      "0.21       6\n",
      "0.82       5\n",
      "0.66       5\n",
      "0.65       5\n",
      "0.16       5\n",
      "0.18       5\n",
      "0.67       5\n",
      "0.71       5\n",
      "0.99       5\n",
      "0.63       5\n",
      "0.04       5\n",
      "0.87       5\n",
      "0.26       5\n",
      "1.41       5\n",
      "0.03       5\n",
      "1.25       5\n",
      "0.75       5\n",
      "0.73       5\n",
      "1.58       4\n",
      "0.77       4\n",
      "1.05       4\n",
      "0.81       4\n",
      "0.86       4\n",
      "1.01       4\n",
      "0.78       4\n",
      "1.74       4\n",
      "0.61       4\n",
      "1.30       4\n",
      "1.23       4\n",
      "0.91       4\n",
      "0.84       4\n",
      "0.02       3\n",
      "2.94       3\n",
      "1.47       3\n",
      "1.00       3\n",
      "0.98       3\n",
      "1.17       3\n",
      "1.56       3\n",
      "2.79       3\n",
      "1.68       3\n",
      "1.63       3\n",
      "1.29       3\n",
      "1.04       3\n",
      "2.73       3\n",
      "0.59       3\n",
      "3.73       2\n",
      "0.49       2\n",
      "1.13       2\n",
      "2.06       2\n",
      "2.95       2\n",
      "1.54       2\n",
      "1.07       2\n",
      "0.89       2\n",
      "0.51       2\n",
      "0.01       2\n",
      "3.40       2\n",
      "1.95       2\n",
      "0.57       2\n",
      "1.11       2\n",
      "1.37       2\n",
      "0.92       2\n",
      "2.85       2\n",
      "1.70       2\n",
      "2.00       2\n",
      "1.60       2\n",
      "1.61       2\n",
      "0.74       2\n",
      "2.80       2\n",
      "1.06       2\n",
      "3.88       2\n",
      "1.03       2\n",
      "1.24       2\n",
      "0.97       2\n",
      "1.72       1\n",
      "1.31       1\n",
      "1.19       1\n",
      "0.56       1\n",
      "1.46       1\n",
      "2.82       1\n",
      "2.04       1\n",
      "3.49       1\n",
      "1.16       1\n",
      "5.12       1\n",
      "1.84       1\n",
      "3.44       1\n",
      "1.92       1\n",
      "3.29       1\n",
      "3.57       1\n",
      "0.88       1\n",
      "2.63       1\n",
      "1.89       1\n",
      "1.32       1\n",
      "1.18       1\n",
      "1.67       1\n",
      "1.69       1\n",
      "1.48       1\n",
      "1.78       1\n",
      "0.55       1\n",
      "0.35       1\n",
      "1.64       1\n",
      "5.06       1\n",
      "3.15       1\n",
      "1.40       1\n",
      "2.65       1\n",
      "1.39       1\n",
      "7.14       1\n",
      "1.15       1\n",
      "2.32       1\n",
      "1.35       1\n",
      "1.49       1\n",
      "1.50       1\n",
      "2.93       1\n",
      "3.84       1\n",
      "2.33       1\n",
      "0.79       1\n",
      "1.26       1\n",
      "3.33       1\n",
      "2.22       1\n",
      "1.73       1\n",
      "1.55       1\n",
      "4.50       1\n",
      "1.09       1\n",
      "1.65       1\n",
      "1.79       1\n",
      "1.08       1\n",
      "1.14       1\n",
      "1.36       1\n",
      "2.66       1\n",
      "1.43       1\n",
      "2.53       1\n",
      "4.87       1\n",
      "4.81       1\n",
      "3.38       1\n",
      "2.87       1\n",
      "1.45       1\n",
      "2.98       1\n",
      "1.83       1\n",
      "1.90       1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "word_freq_email\n",
      "0.00    3375\n",
      "1.11      20\n",
      "0.05      19\n",
      "0.06      17\n",
      "0.08      17\n",
      "0.33      15\n",
      "0.32      15\n",
      "0.12      15\n",
      "0.19      14\n",
      "0.03      13\n",
      "0.44      13\n",
      "0.38      13\n",
      "0.36      12\n",
      "0.29      12\n",
      "0.07      12\n",
      "0.90      11\n",
      "0.55      11\n",
      "0.46      11\n",
      "0.40      10\n",
      "0.37      10\n",
      "0.34      10\n",
      "0.39      10\n",
      "0.58      10\n",
      "0.11       9\n",
      "0.50       9\n",
      "0.93       9\n",
      "0.42       9\n",
      "0.27       9\n",
      "0.26       9\n",
      "0.22       9\n",
      "0.57       9\n",
      "0.16       8\n",
      "0.82       8\n",
      "0.35       8\n",
      "0.21       8\n",
      "0.31       8\n",
      "0.23       8\n",
      "0.54       8\n",
      "0.28       8\n",
      "0.20       8\n",
      "0.30       8\n",
      "2.04       7\n",
      "0.25       7\n",
      "0.24       7\n",
      "0.43       7\n",
      "1.01       7\n",
      "0.45       7\n",
      "1.81       7\n",
      "0.86       7\n",
      "0.62       7\n",
      "0.14       7\n",
      "0.56       7\n",
      "0.51       7\n",
      "0.17       7\n",
      "0.80       7\n",
      "0.59       7\n",
      "1.56       7\n",
      "0.13       7\n",
      "0.65       6\n",
      "1.73       6\n",
      "0.48       6\n",
      "1.25       6\n",
      "0.68       6\n",
      "1.29       6\n",
      "0.89       6\n",
      "0.02       6\n",
      "1.40       6\n",
      "0.70       6\n",
      "0.76       6\n",
      "0.15       6\n",
      "0.53       6\n",
      "1.26       5\n",
      "0.67       5\n",
      "1.36       5\n",
      "0.52       5\n",
      "0.60       5\n",
      "0.61       5\n",
      "0.47       5\n",
      "0.84       5\n",
      "0.88       5\n",
      "0.18       5\n",
      "1.19       5\n",
      "1.02       4\n",
      "0.01       4\n",
      "2.17       4\n",
      "1.61       4\n",
      "1.52       4\n",
      "0.72       4\n",
      "0.85       4\n",
      "0.87       4\n",
      "0.49       4\n",
      "0.10       4\n",
      "1.12       4\n",
      "1.31       4\n",
      "1.88       4\n",
      "0.78       4\n",
      "1.16       4\n",
      "1.37       4\n",
      "0.74       4\n",
      "0.04       4\n",
      "1.17       4\n",
      "1.96       4\n",
      "1.57       3\n",
      "1.13       3\n",
      "0.83       3\n",
      "0.75       3\n",
      "1.54       3\n",
      "1.03       3\n",
      "1.20       3\n",
      "0.63       3\n",
      "0.96       3\n",
      "0.91       3\n",
      "1.83       3\n",
      "1.28       3\n",
      "1.92       3\n",
      "1.91       3\n",
      "2.12       3\n",
      "1.43       3\n",
      "1.50       3\n",
      "0.81       3\n",
      "1.27       3\n",
      "0.79       3\n",
      "1.46       3\n",
      "0.95       3\n",
      "0.69       3\n",
      "3.44       3\n",
      "1.10       3\n",
      "0.92       3\n",
      "0.41       3\n",
      "1.49       3\n",
      "0.77       2\n",
      "1.33       2\n",
      "1.69       2\n",
      "0.66       2\n",
      "2.20       2\n",
      "1.67       2\n",
      "1.62       2\n",
      "1.98       2\n",
      "1.55       2\n",
      "2.32       2\n",
      "3.57       2\n",
      "1.60       2\n",
      "1.78       2\n",
      "1.66       2\n",
      "0.64       2\n",
      "1.05       2\n",
      "2.46       2\n",
      "1.85       2\n",
      "1.08       2\n",
      "1.39       2\n",
      "2.23       2\n",
      "2.85       2\n",
      "4.16       2\n",
      "0.94       2\n",
      "0.09       2\n",
      "1.06       2\n",
      "1.18       2\n",
      "0.71       2\n",
      "1.47       2\n",
      "0.97       2\n",
      "0.73       2\n",
      "1.58       2\n",
      "2.38       2\n",
      "3.18       2\n",
      "1.51       1\n",
      "1.32       1\n",
      "1.42       1\n",
      "3.22       1\n",
      "0.99       1\n",
      "1.53       1\n",
      "1.24       1\n",
      "2.01       1\n",
      "1.23       1\n",
      "1.04       1\n",
      "3.00       1\n",
      "7.69       1\n",
      "2.77       1\n",
      "1.21       1\n",
      "2.10       1\n",
      "1.22       1\n",
      "3.48       1\n",
      "2.87       1\n",
      "1.15       1\n",
      "2.07       1\n",
      "3.70       1\n",
      "3.52       1\n",
      "2.00       1\n",
      "4.44       1\n",
      "1.84       1\n",
      "1.75       1\n",
      "1.59       1\n",
      "2.63       1\n",
      "2.56       1\n",
      "2.22       1\n",
      "3.03       1\n",
      "1.44       1\n",
      "2.41       1\n",
      "1.00       1\n",
      "2.33       1\n",
      "2.26       1\n",
      "1.30       1\n",
      "1.70       1\n",
      "4.10       1\n",
      "1.07       1\n",
      "1.41       1\n",
      "4.83       1\n",
      "1.79       1\n",
      "1.68       1\n",
      "0.98       1\n",
      "6.66       1\n",
      "1.72       1\n",
      "5.33       1\n",
      "2.45       1\n",
      "3.43       1\n",
      "2.05       1\n",
      "2.47       1\n",
      "1.09       1\n",
      "5.26       1\n",
      "2.43       1\n",
      "4.51       1\n",
      "2.11       1\n",
      "1.45       1\n",
      "9.09       1\n",
      "1.65       1\n",
      "1.14       1\n",
      "1.94       1\n",
      "4.87       1\n",
      "1.38       1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "word_freq_you\n",
      "0.00    1289\n",
      "1.31      35\n",
      "2.56      23\n",
      "2.00      23\n",
      "3.33      21\n",
      "        ... \n",
      "3.83       1\n",
      "7.10       1\n",
      "7.09       1\n",
      "2.42       1\n",
      "6.89       1\n",
      "Name: count, Length: 569, dtype: int64\n",
      "\n",
      "word_freq_credit\n",
      "0.00     3962\n",
      "0.17       21\n",
      "0.20       19\n",
      "0.23       15\n",
      "0.14       15\n",
      "0.16       12\n",
      "0.24       10\n",
      "0.06        9\n",
      "0.05        8\n",
      "0.39        8\n",
      "0.09        8\n",
      "0.19        8\n",
      "0.13        7\n",
      "2.61        6\n",
      "0.50        6\n",
      "0.12        6\n",
      "4.26        6\n",
      "0.69        5\n",
      "0.47        5\n",
      "0.40        5\n",
      "0.30        5\n",
      "1.02        5\n",
      "0.26        5\n",
      "0.49        4\n",
      "1.15        4\n",
      "0.48        4\n",
      "0.33        4\n",
      "0.76        4\n",
      "0.68        4\n",
      "1.47        4\n",
      "0.29        4\n",
      "0.32        4\n",
      "0.15        4\n",
      "0.38        4\n",
      "5.19        3\n",
      "0.42        3\n",
      "0.03        3\n",
      "0.22        3\n",
      "0.41        3\n",
      "0.46        3\n",
      "0.31        3\n",
      "4.10        3\n",
      "0.98        3\n",
      "0.59        3\n",
      "0.45        3\n",
      "0.34        3\n",
      "1.68        3\n",
      "0.35        3\n",
      "2.20        3\n",
      "0.18        3\n",
      "0.04        3\n",
      "2.67        2\n",
      "0.01        2\n",
      "0.53        2\n",
      "0.67        2\n",
      "1.97        2\n",
      "2.70        2\n",
      "3.18        2\n",
      "1.26        2\n",
      "0.10        2\n",
      "1.10        2\n",
      "1.81        2\n",
      "0.93        2\n",
      "0.44        2\n",
      "1.58        2\n",
      "2.82        2\n",
      "1.98        2\n",
      "0.87        2\n",
      "2.31        2\n",
      "1.21        1\n",
      "0.27        1\n",
      "3.03        1\n",
      "4.96        1\n",
      "6.25        1\n",
      "1.22        1\n",
      "1.73        1\n",
      "2.09        1\n",
      "1.20        1\n",
      "1.45        1\n",
      "1.67        1\n",
      "1.95        1\n",
      "3.80        1\n",
      "1.49        1\n",
      "0.64        1\n",
      "0.37        1\n",
      "1.03        1\n",
      "0.60        1\n",
      "0.86        1\n",
      "1.07        1\n",
      "0.07        1\n",
      "3.12        1\n",
      "2.58        1\n",
      "0.02        1\n",
      "1.89        1\n",
      "0.78        1\n",
      "2.53        1\n",
      "0.43        1\n",
      "3.15        1\n",
      "2.57        1\n",
      "2.22        1\n",
      "1.04        1\n",
      "0.08        1\n",
      "1.23        1\n",
      "2.64        1\n",
      "0.55        1\n",
      "3.42        1\n",
      "2.26        1\n",
      "2.14        1\n",
      "0.89        1\n",
      "1.05        1\n",
      "1.61        1\n",
      "1.16        1\n",
      "18.18       1\n",
      "2.46        1\n",
      "1.31        1\n",
      "1.35        1\n",
      "1.28        1\n",
      "0.25        1\n",
      "2.19        1\n",
      "2.08        1\n",
      "5.22        1\n",
      "3.53        1\n",
      "3.09        1\n",
      "1.65        1\n",
      "6.32        1\n",
      "5.33        1\n",
      "0.21        1\n",
      "1.36        1\n",
      "1.32        1\n",
      "0.81        1\n",
      "3.26        1\n",
      "1.57        1\n",
      "2.98        1\n",
      "2.54        1\n",
      "2.36        1\n",
      "2.38        1\n",
      "2.68        1\n",
      "1.13        1\n",
      "0.51        1\n",
      "0.74        1\n",
      "0.92        1\n",
      "1.55        1\n",
      "4.76        1\n",
      "1.60        1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "word_freq_your\n",
      "0.00     2083\n",
      "0.42       22\n",
      "1.36       21\n",
      "0.70       21\n",
      "1.16       20\n",
      "0.64       20\n",
      "1.23       19\n",
      "1.35       18\n",
      "1.10       18\n",
      "1.21       17\n",
      "0.94       17\n",
      "1.08       17\n",
      "1.09       17\n",
      "1.25       17\n",
      "1.38       16\n",
      "1.06       16\n",
      "1.40       16\n",
      "1.03       15\n",
      "5.26       15\n",
      "0.86       15\n",
      "1.49       15\n",
      "0.92       15\n",
      "1.12       15\n",
      "0.33       15\n",
      "0.68       14\n",
      "0.81       14\n",
      "0.90       14\n",
      "2.00       14\n",
      "0.17       13\n",
      "0.22       13\n",
      "1.75       13\n",
      "0.38       13\n",
      "1.28       13\n",
      "0.54       13\n",
      "0.47       12\n",
      "0.67       12\n",
      "0.85       12\n",
      "1.04       12\n",
      "1.47       12\n",
      "1.44       12\n",
      "1.19       12\n",
      "0.65       12\n",
      "0.62       12\n",
      "0.51       12\n",
      "0.73       12\n",
      "0.52       12\n",
      "1.30       12\n",
      "0.29       11\n",
      "0.40       11\n",
      "0.78       11\n",
      "1.69       11\n",
      "1.15       11\n",
      "1.05       11\n",
      "0.87       11\n",
      "0.58       11\n",
      "0.99       11\n",
      "0.69       11\n",
      "1.72       11\n",
      "0.96       11\n",
      "1.66       11\n",
      "1.11       11\n",
      "0.46       11\n",
      "1.26       11\n",
      "0.97       11\n",
      "1.14       10\n",
      "0.66       10\n",
      "0.39       10\n",
      "1.92       10\n",
      "1.02       10\n",
      "0.43       10\n",
      "0.63       10\n",
      "1.29       10\n",
      "1.32       10\n",
      "8.00       10\n",
      "0.77       10\n",
      "0.31       10\n",
      "1.96       10\n",
      "0.60       10\n",
      "1.50       10\n",
      "0.95       10\n",
      "0.32       10\n",
      "0.88       10\n",
      "1.51       10\n",
      "0.93        9\n",
      "0.71        9\n",
      "2.17        9\n",
      "2.12        9\n",
      "1.07        9\n",
      "1.45        9\n",
      "0.27        9\n",
      "0.15        9\n",
      "0.55        9\n",
      "0.37        9\n",
      "1.01        9\n",
      "0.41        9\n",
      "1.56        9\n",
      "1.34        9\n",
      "1.41        9\n",
      "2.38        9\n",
      "1.17        9\n",
      "0.16        9\n",
      "1.42        9\n",
      "1.20        9\n",
      "0.25        9\n",
      "0.23        9\n",
      "3.24        8\n",
      "2.35        8\n",
      "0.50        8\n",
      "0.72        8\n",
      "3.25        8\n",
      "0.14        8\n",
      "1.24        8\n",
      "1.00        8\n",
      "1.53        8\n",
      "0.45        8\n",
      "0.36        8\n",
      "2.40        8\n",
      "0.44        8\n",
      "0.61        8\n",
      "0.76        8\n",
      "0.75        8\n",
      "0.74        8\n",
      "3.27        8\n",
      "1.33        8\n",
      "1.31        8\n",
      "0.20        8\n",
      "2.94        8\n",
      "2.22        8\n",
      "1.63        8\n",
      "1.88        8\n",
      "2.04        8\n",
      "0.56        8\n",
      "0.19        8\n",
      "0.24        8\n",
      "2.73        8\n",
      "0.89        7\n",
      "1.60        7\n",
      "1.73        7\n",
      "2.75        7\n",
      "0.49        7\n",
      "3.17        7\n",
      "0.12        7\n",
      "1.58        7\n",
      "2.31        7\n",
      "0.48        7\n",
      "1.27        7\n",
      "3.03        7\n",
      "0.80        7\n",
      "1.48        7\n",
      "0.82        7\n",
      "1.13        7\n",
      "1.86        7\n",
      "2.20        7\n",
      "2.10        7\n",
      "1.80        7\n",
      "2.72        7\n",
      "2.03        7\n",
      "0.98        7\n",
      "0.26        7\n",
      "0.28        7\n",
      "1.46        7\n",
      "0.59        7\n",
      "1.78        7\n",
      "1.91        6\n",
      "0.83        6\n",
      "3.38        6\n",
      "2.83        6\n",
      "2.02        6\n",
      "0.34        6\n",
      "2.63        6\n",
      "0.91        6\n",
      "1.43        6\n",
      "2.50        6\n",
      "1.87        6\n",
      "2.06        6\n",
      "1.68        6\n",
      "3.84        6\n",
      "0.06        6\n",
      "1.61        6\n",
      "0.30        6\n",
      "1.74        6\n",
      "0.57        6\n",
      "1.18        5\n",
      "1.99        5\n",
      "3.33        5\n",
      "0.35        5\n",
      "2.01        5\n",
      "3.50        5\n",
      "1.94        5\n",
      "4.16        5\n",
      "1.22        5\n",
      "1.85        5\n",
      "2.46        5\n",
      "1.59        5\n",
      "1.76        5\n",
      "0.53        5\n",
      "0.18        5\n",
      "2.70        5\n",
      "1.67        5\n",
      "1.81        5\n",
      "0.84        5\n",
      "0.09        5\n",
      "0.08        4\n",
      "2.64        4\n",
      "2.30        4\n",
      "0.10        4\n",
      "2.41        4\n",
      "0.07        4\n",
      "2.81        4\n",
      "2.08        4\n",
      "1.54        4\n",
      "2.18        4\n",
      "2.19        4\n",
      "3.70        4\n",
      "0.02        4\n",
      "1.77        4\n",
      "2.88        4\n",
      "1.57        4\n",
      "4.00        4\n",
      "1.39        4\n",
      "2.32        4\n",
      "2.43        4\n",
      "2.53        4\n",
      "2.56        4\n",
      "3.19        4\n",
      "1.93        4\n",
      "3.14        4\n",
      "2.54        4\n",
      "6.66        4\n",
      "3.57        4\n",
      "2.15        4\n",
      "2.65        4\n",
      "1.55        4\n",
      "2.29        3\n",
      "2.80        3\n",
      "0.79        3\n",
      "0.21        3\n",
      "1.62        3\n",
      "0.13        3\n",
      "5.18        3\n",
      "2.59        3\n",
      "3.07        3\n",
      "2.36        3\n",
      "3.22        3\n",
      "1.90        3\n",
      "3.30        3\n",
      "2.44        3\n",
      "2.58        3\n",
      "3.26        3\n",
      "3.61        3\n",
      "4.48        3\n",
      "2.11        3\n",
      "2.05        3\n",
      "1.84        3\n",
      "3.09        3\n",
      "2.92        3\n",
      "2.98        3\n",
      "1.37        3\n",
      "1.64        3\n",
      "2.09        3\n",
      "2.51        3\n",
      "2.95        3\n",
      "2.47        3\n",
      "3.79        3\n",
      "2.85        3\n",
      "1.52        3\n",
      "2.48        3\n",
      "7.14        2\n",
      "1.98        2\n",
      "0.05        2\n",
      "2.24        2\n",
      "0.04        2\n",
      "2.66        2\n",
      "2.90        2\n",
      "3.32        2\n",
      "4.87        2\n",
      "2.16        2\n",
      "5.19        2\n",
      "2.61        2\n",
      "2.97        2\n",
      "4.02        2\n",
      "3.94        2\n",
      "4.54        2\n",
      "2.27        2\n",
      "1.70        2\n",
      "2.42        2\n",
      "2.45        2\n",
      "3.75        2\n",
      "4.34        2\n",
      "3.52        2\n",
      "3.48        2\n",
      "5.33        2\n",
      "3.44        2\n",
      "4.76        2\n",
      "2.82        2\n",
      "1.79        2\n",
      "1.65        2\n",
      "4.12        2\n",
      "3.87        2\n",
      "2.67        2\n",
      "2.21        2\n",
      "2.77        2\n",
      "3.00        2\n",
      "4.41        2\n",
      "2.76        2\n",
      "3.35        2\n",
      "3.63        2\n",
      "2.23        2\n",
      "3.73        2\n",
      "2.34        2\n",
      "5.55        2\n",
      "3.36        2\n",
      "1.71        2\n",
      "3.02        2\n",
      "3.95        2\n",
      "2.60        2\n",
      "5.06        1\n",
      "3.34        1\n",
      "3.80        1\n",
      "4.47        1\n",
      "0.11        1\n",
      "4.44        1\n",
      "0.03        1\n",
      "1.82        1\n",
      "3.18        1\n",
      "1.95        1\n",
      "3.82        1\n",
      "2.28        1\n",
      "3.01        1\n",
      "5.47        1\n",
      "9.09        1\n",
      "3.69        1\n",
      "3.10        1\n",
      "3.93        1\n",
      "3.90        1\n",
      "2.89        1\n",
      "6.89        1\n",
      "3.04        1\n",
      "5.12        1\n",
      "9.52        1\n",
      "0.01        1\n",
      "6.52        1\n",
      "3.31        1\n",
      "3.08        1\n",
      "2.87        1\n",
      "6.17        1\n",
      "3.85        1\n",
      "3.40        1\n",
      "10.71       1\n",
      "4.28        1\n",
      "3.43        1\n",
      "8.69        1\n",
      "2.14        1\n",
      "5.14        1\n",
      "11.11       1\n",
      "4.52        1\n",
      "4.51        1\n",
      "5.10        1\n",
      "4.46        1\n",
      "4.65        1\n",
      "2.13        1\n",
      "2.91        1\n",
      "3.60        1\n",
      "5.97        1\n",
      "4.04        1\n",
      "6.41        1\n",
      "6.54        1\n",
      "4.68        1\n",
      "5.40        1\n",
      "4.97        1\n",
      "3.20        1\n",
      "5.04        1\n",
      "5.88        1\n",
      "4.56        1\n",
      "2.25        1\n",
      "5.67        1\n",
      "2.37        1\n",
      "1.83        1\n",
      "5.36        1\n",
      "3.12        1\n",
      "5.29        1\n",
      "4.81        1\n",
      "1.97        1\n",
      "2.99        1\n",
      "3.71        1\n",
      "4.60        1\n",
      "3.53        1\n",
      "2.62        1\n",
      "3.72        1\n",
      "1.89        1\n",
      "3.89        1\n",
      "3.54        1\n",
      "3.59        1\n",
      "3.37        1\n",
      "2.78        1\n",
      "3.21        1\n",
      "7.40        1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "word_freq_font\n",
      "0.00     4260\n",
      "0.17        3\n",
      "17.10       2\n",
      "8.33        2\n",
      "1.61        2\n",
      "0.84        2\n",
      "0.20        2\n",
      "0.21        2\n",
      "8.29        2\n",
      "0.31        2\n",
      "9.17        2\n",
      "1.29        2\n",
      "0.62        2\n",
      "0.07        2\n",
      "0.36        2\n",
      "6.75        2\n",
      "1.93        2\n",
      "0.22        2\n",
      "9.83        1\n",
      "1.92        1\n",
      "2.98        1\n",
      "1.87        1\n",
      "2.00        1\n",
      "12.80       1\n",
      "0.38        1\n",
      "9.95        1\n",
      "0.86        1\n",
      "0.55        1\n",
      "6.29        1\n",
      "10.17       1\n",
      "7.32        1\n",
      "0.80        1\n",
      "3.47        1\n",
      "2.43        1\n",
      "0.25        1\n",
      "10.38       1\n",
      "9.09        1\n",
      "10.25       1\n",
      "11.42       1\n",
      "7.22        1\n",
      "1.05        1\n",
      "0.11        1\n",
      "0.29        1\n",
      "10.86       1\n",
      "6.92        1\n",
      "7.12        1\n",
      "5.78        1\n",
      "0.65        1\n",
      "1.67        1\n",
      "2.24        1\n",
      "3.75        1\n",
      "9.33        1\n",
      "1.28        1\n",
      "1.23        1\n",
      "1.63        1\n",
      "9.48        1\n",
      "9.04        1\n",
      "2.94        1\n",
      "1.33        1\n",
      "1.26        1\n",
      "0.12        1\n",
      "0.46        1\n",
      "4.49        1\n",
      "9.29        1\n",
      "0.92        1\n",
      "1.50        1\n",
      "9.50        1\n",
      "8.82        1\n",
      "4.07        1\n",
      "3.86        1\n",
      "7.97        1\n",
      "0.43        1\n",
      "5.55        1\n",
      "8.58        1\n",
      "8.84        1\n",
      "7.33        1\n",
      "4.57        1\n",
      "7.08        1\n",
      "13.34       1\n",
      "0.81        1\n",
      "0.27        1\n",
      "10.82       1\n",
      "0.93        1\n",
      "12.60       1\n",
      "8.06        1\n",
      "2.93        1\n",
      "15.43       1\n",
      "10.58       1\n",
      "7.63        1\n",
      "9.53        1\n",
      "2.72        1\n",
      "0.68        1\n",
      "7.36        1\n",
      "6.41        1\n",
      "0.58        1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "word_freq_000\n",
      "0.00    3726\n",
      "0.34      25\n",
      "0.36      19\n",
      "0.60      16\n",
      "0.08      15\n",
      "0.85      14\n",
      "0.48      13\n",
      "0.09      12\n",
      "0.39      11\n",
      "0.15      11\n",
      "0.05      10\n",
      "0.13      10\n",
      "0.64      10\n",
      "0.44       9\n",
      "0.55       9\n",
      "0.10       9\n",
      "0.35       9\n",
      "0.46       9\n",
      "0.19       9\n",
      "0.31       8\n",
      "0.62       8\n",
      "0.49       8\n",
      "0.38       8\n",
      "0.40       8\n",
      "0.51       7\n",
      "0.76       7\n",
      "0.78       7\n",
      "0.37       7\n",
      "0.84       7\n",
      "0.11       6\n",
      "0.17       6\n",
      "0.74       6\n",
      "2.20       6\n",
      "0.23       6\n",
      "0.75       6\n",
      "0.50       6\n",
      "0.06       6\n",
      "0.27       6\n",
      "0.59       6\n",
      "0.45       6\n",
      "0.21       6\n",
      "0.80       5\n",
      "0.20       5\n",
      "0.22       5\n",
      "0.14       5\n",
      "0.52       5\n",
      "0.29       5\n",
      "0.12       5\n",
      "0.72       5\n",
      "0.25       5\n",
      "0.04       4\n",
      "0.47       4\n",
      "1.59       4\n",
      "0.07       4\n",
      "0.41       4\n",
      "0.16       4\n",
      "0.73       4\n",
      "0.58       4\n",
      "1.14       4\n",
      "1.44       4\n",
      "0.95       4\n",
      "1.05       4\n",
      "1.38       4\n",
      "1.12       4\n",
      "1.62       4\n",
      "0.56       4\n",
      "0.28       3\n",
      "1.42       3\n",
      "1.85       3\n",
      "0.68       3\n",
      "2.53       3\n",
      "0.53       3\n",
      "0.61       3\n",
      "1.66       3\n",
      "1.02       3\n",
      "1.34       3\n",
      "1.47       3\n",
      "1.16       3\n",
      "0.77       3\n",
      "0.82       3\n",
      "0.42       3\n",
      "1.35       3\n",
      "0.33       3\n",
      "0.18       3\n",
      "1.28       3\n",
      "0.94       3\n",
      "0.90       3\n",
      "0.24       3\n",
      "1.36       3\n",
      "1.25       2\n",
      "2.59       2\n",
      "0.98       2\n",
      "0.32       2\n",
      "1.48       2\n",
      "0.91       2\n",
      "0.01       2\n",
      "1.83       2\n",
      "0.79       2\n",
      "1.00       2\n",
      "1.18       2\n",
      "1.09       2\n",
      "0.63       2\n",
      "0.65       2\n",
      "0.54       2\n",
      "1.10       2\n",
      "1.58       2\n",
      "1.11       2\n",
      "1.03       2\n",
      "1.07       2\n",
      "1.19       2\n",
      "1.08       2\n",
      "0.96       2\n",
      "0.97       2\n",
      "2.10       2\n",
      "0.43       2\n",
      "1.61       2\n",
      "3.38       2\n",
      "1.41       2\n",
      "1.31       2\n",
      "0.99       1\n",
      "2.04       1\n",
      "1.88       1\n",
      "1.92       1\n",
      "4.76       1\n",
      "0.87       1\n",
      "1.01       1\n",
      "4.01       1\n",
      "3.62       1\n",
      "4.32       1\n",
      "1.51       1\n",
      "0.86       1\n",
      "2.12       1\n",
      "3.17       1\n",
      "2.85       1\n",
      "0.71       1\n",
      "1.23       1\n",
      "1.96       1\n",
      "1.13       1\n",
      "0.89       1\n",
      "0.30       1\n",
      "0.70       1\n",
      "1.78       1\n",
      "1.39       1\n",
      "2.05       1\n",
      "1.82       1\n",
      "2.24       1\n",
      "0.66       1\n",
      "1.30       1\n",
      "5.45       1\n",
      "1.06       1\n",
      "2.70       1\n",
      "1.90       1\n",
      "1.53       1\n",
      "0.69       1\n",
      "2.35       1\n",
      "1.57       1\n",
      "3.57       1\n",
      "0.03       1\n",
      "0.81       1\n",
      "1.45       1\n",
      "0.02       1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "word_freq_money\n",
      "0.00     3689\n",
      "0.08       28\n",
      "0.32       24\n",
      "0.30       23\n",
      "0.34       23\n",
      "0.09       22\n",
      "0.10       17\n",
      "0.20       16\n",
      "0.38       14\n",
      "0.05       14\n",
      "1.31       13\n",
      "0.44       13\n",
      "0.33       13\n",
      "0.22       13\n",
      "0.17       12\n",
      "0.06       12\n",
      "0.29       12\n",
      "0.46       11\n",
      "0.60       11\n",
      "0.84       11\n",
      "0.18       10\n",
      "0.42        9\n",
      "0.31        9\n",
      "0.16        9\n",
      "0.19        9\n",
      "0.54        9\n",
      "0.27        8\n",
      "0.28        8\n",
      "0.47        8\n",
      "0.77        8\n",
      "0.12        8\n",
      "0.23        8\n",
      "0.52        8\n",
      "0.26        8\n",
      "0.41        8\n",
      "0.40        8\n",
      "0.43        7\n",
      "0.76        7\n",
      "0.63        7\n",
      "0.24        6\n",
      "0.72        6\n",
      "0.35        6\n",
      "1.38        6\n",
      "0.58        6\n",
      "0.49        6\n",
      "0.37        5\n",
      "0.61        5\n",
      "1.14        5\n",
      "0.71        5\n",
      "0.65        5\n",
      "0.39        5\n",
      "0.50        5\n",
      "0.51        5\n",
      "0.74        5\n",
      "0.59        5\n",
      "0.36        4\n",
      "0.96        4\n",
      "0.68        4\n",
      "0.69        4\n",
      "0.48        4\n",
      "0.57        4\n",
      "0.45        4\n",
      "1.29        4\n",
      "0.55        3\n",
      "0.90        3\n",
      "0.56        3\n",
      "0.82        3\n",
      "1.16        3\n",
      "0.70        3\n",
      "0.64        3\n",
      "0.53        3\n",
      "6.66        3\n",
      "1.88        3\n",
      "0.62        3\n",
      "0.14        3\n",
      "0.25        3\n",
      "0.67        3\n",
      "1.04        3\n",
      "0.81        2\n",
      "4.41        2\n",
      "1.07        2\n",
      "0.98        2\n",
      "0.07        2\n",
      "0.21        2\n",
      "9.09        2\n",
      "0.93        2\n",
      "0.80        2\n",
      "1.36        2\n",
      "0.04        2\n",
      "0.78        2\n",
      "1.32        2\n",
      "1.47        2\n",
      "0.87        2\n",
      "0.11        2\n",
      "0.02        2\n",
      "0.79        2\n",
      "1.17        1\n",
      "1.01        1\n",
      "1.11        1\n",
      "1.08        1\n",
      "5.98        1\n",
      "1.20        1\n",
      "1.26        1\n",
      "1.41        1\n",
      "0.15        1\n",
      "1.61        1\n",
      "1.60        1\n",
      "1.40        1\n",
      "0.03        1\n",
      "0.13        1\n",
      "1.73        1\n",
      "1.66        1\n",
      "1.83        1\n",
      "1.69        1\n",
      "9.75        1\n",
      "0.75        1\n",
      "1.46        1\n",
      "2.45        1\n",
      "1.10        1\n",
      "2.32        1\n",
      "1.50        1\n",
      "0.66        1\n",
      "12.50       1\n",
      "1.28        1\n",
      "1.23        1\n",
      "1.94        1\n",
      "0.99        1\n",
      "1.56        1\n",
      "3.61        1\n",
      "1.42        1\n",
      "1.00        1\n",
      "1.09        1\n",
      "0.83        1\n",
      "1.05        1\n",
      "1.96        1\n",
      "0.73        1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "word_freq_hp\n",
      "0.00     3338\n",
      "0.49       12\n",
      "0.34       10\n",
      "1.58       10\n",
      "0.64        9\n",
      "2.63        9\n",
      "0.90        9\n",
      "1.83        8\n",
      "0.47        8\n",
      "1.76        8\n",
      "1.19        8\n",
      "2.22        8\n",
      "2.06        7\n",
      "1.69        7\n",
      "1.81        7\n",
      "1.61        7\n",
      "0.96        7\n",
      "0.78        7\n",
      "0.62        7\n",
      "0.52        7\n",
      "0.19        7\n",
      "0.67        7\n",
      "1.78        7\n",
      "0.44        7\n",
      "1.72        7\n",
      "0.27        6\n",
      "16.66       6\n",
      "0.75        6\n",
      "0.56        6\n",
      "9.52        6\n",
      "0.28        6\n",
      "0.81        6\n",
      "0.23        6\n",
      "0.46        6\n",
      "0.57        6\n",
      "1.16        6\n",
      "0.68        6\n",
      "0.55        6\n",
      "1.04        5\n",
      "1.31        5\n",
      "2.32        5\n",
      "0.35        5\n",
      "1.38        5\n",
      "1.25        5\n",
      "0.99        5\n",
      "1.75        5\n",
      "8.69        5\n",
      "1.36        5\n",
      "1.29        5\n",
      "0.50        5\n",
      "0.86        5\n",
      "0.72        5\n",
      "2.38        5\n",
      "0.87        5\n",
      "1.40        5\n",
      "0.79        5\n",
      "4.00        5\n",
      "0.21        5\n",
      "0.51        5\n",
      "0.26        5\n",
      "0.38        5\n",
      "0.80        4\n",
      "0.48        4\n",
      "1.49        4\n",
      "1.12        4\n",
      "15.38       4\n",
      "0.39        4\n",
      "0.65        4\n",
      "0.05        4\n",
      "1.90        4\n",
      "8.33        4\n",
      "1.28        4\n",
      "0.37        4\n",
      "3.44        4\n",
      "1.93        4\n",
      "2.15        4\n",
      "2.77        4\n",
      "0.36        4\n",
      "2.54        4\n",
      "1.79        4\n",
      "0.13        4\n",
      "0.74        4\n",
      "2.18        4\n",
      "2.04        4\n",
      "8.00        4\n",
      "3.84        4\n",
      "0.85        4\n",
      "1.27        4\n",
      "0.32        4\n",
      "0.29        4\n",
      "0.42        4\n",
      "3.03        4\n",
      "0.33        4\n",
      "1.96        4\n",
      "0.31        4\n",
      "1.53        4\n",
      "2.56        4\n",
      "3.47        4\n",
      "0.63        4\n",
      "1.11        4\n",
      "0.93        4\n",
      "0.30        4\n",
      "0.95        4\n",
      "0.58        3\n",
      "1.66        3\n",
      "3.48        3\n",
      "1.84        3\n",
      "0.53        3\n",
      "3.12        3\n",
      "9.09        3\n",
      "0.40        3\n",
      "3.14        3\n",
      "2.46        3\n",
      "2.97        3\n",
      "1.14        3\n",
      "1.47        3\n",
      "0.61        3\n",
      "1.56        3\n",
      "2.00        3\n",
      "1.33        3\n",
      "1.17        3\n",
      "0.59        3\n",
      "3.17        3\n",
      "1.35        3\n",
      "1.22        3\n",
      "1.41        3\n",
      "3.50        3\n",
      "3.63        3\n",
      "1.45        3\n",
      "2.79        3\n",
      "0.17        3\n",
      "2.09        3\n",
      "0.02        3\n",
      "1.99        3\n",
      "1.05        3\n",
      "2.31        3\n",
      "5.12        3\n",
      "1.07        3\n",
      "3.30        3\n",
      "2.12        3\n",
      "0.77        3\n",
      "3.34        3\n",
      "1.52        3\n",
      "1.34        3\n",
      "2.40        3\n",
      "4.34        3\n",
      "2.48        3\n",
      "1.01        3\n",
      "1.98        3\n",
      "1.60        3\n",
      "0.14        3\n",
      "2.89        3\n",
      "0.83        3\n",
      "0.69        3\n",
      "1.10        3\n",
      "3.70        3\n",
      "5.55        3\n",
      "7.14        3\n",
      "4.08        3\n",
      "1.09        3\n",
      "1.85        3\n",
      "2.02        3\n",
      "0.76        3\n",
      "3.06        3\n",
      "13.04       3\n",
      "0.97        3\n",
      "2.80        3\n",
      "1.21        3\n",
      "2.53        3\n",
      "0.60        2\n",
      "0.41        2\n",
      "3.11        2\n",
      "1.87        2\n",
      "1.30        2\n",
      "4.44        2\n",
      "2.20        2\n",
      "2.49        2\n",
      "1.63        2\n",
      "6.89        2\n",
      "0.54        2\n",
      "2.23        2\n",
      "2.26        2\n",
      "4.65        2\n",
      "3.29        2\n",
      "1.00        2\n",
      "0.73        2\n",
      "2.08        2\n",
      "2.01        2\n",
      "1.13        2\n",
      "0.10        2\n",
      "3.20        2\n",
      "1.68        2\n",
      "2.70        2\n",
      "2.72        2\n",
      "10.00       2\n",
      "0.22        2\n",
      "4.16        2\n",
      "1.74        2\n",
      "6.25        2\n",
      "2.73        2\n",
      "0.88        2\n",
      "4.76        2\n",
      "3.10        2\n",
      "7.69        2\n",
      "2.64        2\n",
      "0.25        2\n",
      "2.07        2\n",
      "1.70        2\n",
      "20.00       2\n",
      "0.92        2\n",
      "0.04        2\n",
      "1.57        2\n",
      "4.22        2\n",
      "0.66        2\n",
      "0.43        2\n",
      "12.50       2\n",
      "1.06        2\n",
      "2.68        2\n",
      "4.47        2\n",
      "11.11       2\n",
      "0.20        2\n",
      "1.46        2\n",
      "1.37        2\n",
      "0.16        2\n",
      "0.11        2\n",
      "4.70        2\n",
      "3.57        2\n",
      "0.09        2\n",
      "3.73        2\n",
      "2.13        2\n",
      "2.29        2\n",
      "3.00        2\n",
      "4.50        2\n",
      "1.03        2\n",
      "3.37        2\n",
      "1.18        2\n",
      "2.57        2\n",
      "0.45        2\n",
      "2.66        2\n",
      "2.51        2\n",
      "5.37        1\n",
      "18.18       1\n",
      "3.53        1\n",
      "1.73        1\n",
      "7.46        1\n",
      "2.43        1\n",
      "1.02        1\n",
      "1.44        1\n",
      "3.91        1\n",
      "2.98        1\n",
      "5.88        1\n",
      "6.79        1\n",
      "2.42        1\n",
      "1.97        1\n",
      "2.45        1\n",
      "1.43        1\n",
      "6.64        1\n",
      "2.27        1\n",
      "6.06        1\n",
      "4.62        1\n",
      "1.54        1\n",
      "1.32        1\n",
      "6.03        1\n",
      "3.92        1\n",
      "3.33        1\n",
      "2.94        1\n",
      "8.10        1\n",
      "0.18        1\n",
      "3.95        1\n",
      "3.04        1\n",
      "2.93        1\n",
      "3.76        1\n",
      "3.02        1\n",
      "5.68        1\n",
      "5.14        1\n",
      "0.98        1\n",
      "3.21        1\n",
      "1.64        1\n",
      "1.55        1\n",
      "4.37        1\n",
      "2.14        1\n",
      "2.90        1\n",
      "6.00        1\n",
      "4.87        1\n",
      "1.20        1\n",
      "4.21        1\n",
      "0.03        1\n",
      "1.15        1\n",
      "4.90        1\n",
      "2.69        1\n",
      "7.20        1\n",
      "2.83        1\n",
      "1.26        1\n",
      "9.33        1\n",
      "2.71        1\n",
      "3.88        1\n",
      "3.52        1\n",
      "2.65        1\n",
      "1.50        1\n",
      "4.58        1\n",
      "5.43        1\n",
      "1.80        1\n",
      "12.88       1\n",
      "4.51        1\n",
      "5.16        1\n",
      "4.54        1\n",
      "5.45        1\n",
      "2.33        1\n",
      "3.82        1\n",
      "9.83        1\n",
      "3.75        1\n",
      "2.74        1\n",
      "3.79        1\n",
      "7.60        1\n",
      "5.57        1\n",
      "3.45        1\n",
      "3.58        1\n",
      "5.40        1\n",
      "2.88        1\n",
      "20.83       1\n",
      "3.96        1\n",
      "13.93       1\n",
      "0.91        1\n",
      "2.59        1\n",
      "1.71        1\n",
      "3.49        1\n",
      "3.60        1\n",
      "1.24        1\n",
      "0.70        1\n",
      "3.51        1\n",
      "3.54        1\n",
      "2.25        1\n",
      "0.71        1\n",
      "3.05        1\n",
      "2.05        1\n",
      "2.96        1\n",
      "1.94        1\n",
      "4.98        1\n",
      "5.52        1\n",
      "4.13        1\n",
      "5.34        1\n",
      "1.86        1\n",
      "1.88        1\n",
      "2.87        1\n",
      "0.24        1\n",
      "4.89        1\n",
      "4.30        1\n",
      "4.41        1\n",
      "3.23        1\n",
      "9.62        1\n",
      "1.89        1\n",
      "6.08        1\n",
      "2.99        1\n",
      "5.86        1\n",
      "2.61        1\n",
      "5.66        1\n",
      "4.05        1\n",
      "4.42        1\n",
      "3.41        1\n",
      "5.26        1\n",
      "10.76       1\n",
      "6.74        1\n",
      "3.64        1\n",
      "3.16        1\n",
      "1.39        1\n",
      "4.20        1\n",
      "1.23        1\n",
      "7.61        1\n",
      "1.82        1\n",
      "2.35        1\n",
      "5.71        1\n",
      "6.92        1\n",
      "2.85        1\n",
      "9.30        1\n",
      "2.03        1\n",
      "2.17        1\n",
      "1.62        1\n",
      "2.30        1\n",
      "1.65        1\n",
      "2.86        1\n",
      "0.08        1\n",
      "4.48        1\n",
      "0.89        1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "word_freq_hpl\n",
      "0.00     3603\n",
      "0.74       12\n",
      "0.68       10\n",
      "1.19       10\n",
      "0.69        9\n",
      "0.64        8\n",
      "0.57        8\n",
      "0.26        8\n",
      "0.58        8\n",
      "0.49        7\n",
      "0.62        7\n",
      "0.61        7\n",
      "0.66        7\n",
      "1.28        7\n",
      "0.42        7\n",
      "0.54        7\n",
      "1.06        7\n",
      "0.30        7\n",
      "0.90        7\n",
      "0.50        6\n",
      "0.34        6\n",
      "0.87        6\n",
      "0.78        6\n",
      "0.85        6\n",
      "0.76        6\n",
      "2.63        6\n",
      "1.05        6\n",
      "0.33        6\n",
      "0.86        6\n",
      "0.23        6\n",
      "0.44        6\n",
      "0.97        6\n",
      "1.36        5\n",
      "1.20        5\n",
      "1.72        5\n",
      "0.59        5\n",
      "1.02        5\n",
      "0.10        5\n",
      "0.32        5\n",
      "1.11        5\n",
      "0.72        5\n",
      "0.35        5\n",
      "1.49        5\n",
      "1.16        5\n",
      "1.17        5\n",
      "0.55        5\n",
      "1.35        5\n",
      "0.25        5\n",
      "0.27        5\n",
      "0.80        5\n",
      "0.48        5\n",
      "3.44        5\n",
      "4.16        5\n",
      "3.57        5\n",
      "0.81        5\n",
      "2.32        4\n",
      "1.01        4\n",
      "1.78        4\n",
      "0.53        4\n",
      "2.56        4\n",
      "3.84        4\n",
      "4.76        4\n",
      "0.73        4\n",
      "0.43        4\n",
      "0.29        4\n",
      "1.03        4\n",
      "0.38        4\n",
      "1.58        4\n",
      "0.20        4\n",
      "0.71        4\n",
      "1.44        4\n",
      "0.05        4\n",
      "0.96        4\n",
      "0.11        4\n",
      "1.60        4\n",
      "0.52        4\n",
      "2.77        4\n",
      "2.04        4\n",
      "0.67        4\n",
      "0.39        4\n",
      "0.51        4\n",
      "0.79        4\n",
      "0.28        4\n",
      "1.33        3\n",
      "0.31        3\n",
      "1.26        3\n",
      "0.63        3\n",
      "1.23        3\n",
      "0.17        3\n",
      "1.81        3\n",
      "2.17        3\n",
      "4.00        3\n",
      "1.98        3\n",
      "0.37        3\n",
      "1.96        3\n",
      "0.21        3\n",
      "1.13        3\n",
      "0.40        3\n",
      "0.22        3\n",
      "1.09        3\n",
      "1.00        3\n",
      "1.69        3\n",
      "0.70        3\n",
      "0.92        3\n",
      "0.41        3\n",
      "1.87        3\n",
      "1.66        3\n",
      "1.40        3\n",
      "1.93        3\n",
      "0.84        3\n",
      "0.47        3\n",
      "1.61        3\n",
      "0.15        3\n",
      "1.38        3\n",
      "4.34        3\n",
      "2.22        3\n",
      "1.65        3\n",
      "0.98        3\n",
      "1.57        3\n",
      "2.00        3\n",
      "2.35        3\n",
      "0.36        3\n",
      "2.11        2\n",
      "5.40        2\n",
      "0.24        2\n",
      "0.45        2\n",
      "1.22        2\n",
      "0.13        2\n",
      "1.76        2\n",
      "3.12        2\n",
      "0.77        2\n",
      "3.22        2\n",
      "3.03        2\n",
      "3.26        2\n",
      "0.65        2\n",
      "1.56        2\n",
      "4.41        2\n",
      "2.38        2\n",
      "1.52        2\n",
      "9.09        2\n",
      "0.09        2\n",
      "2.64        2\n",
      "3.89        2\n",
      "1.12        2\n",
      "2.98        2\n",
      "1.50        2\n",
      "1.30        2\n",
      "1.70        2\n",
      "2.23        2\n",
      "0.91        2\n",
      "0.99        2\n",
      "2.58        2\n",
      "6.38        2\n",
      "0.83        2\n",
      "3.70        2\n",
      "1.59        2\n",
      "2.53        2\n",
      "1.31        2\n",
      "4.08        2\n",
      "1.86        2\n",
      "2.34        2\n",
      "1.21        2\n",
      "2.57        2\n",
      "4.05        2\n",
      "7.69        2\n",
      "1.14        2\n",
      "0.46        2\n",
      "1.25        2\n",
      "2.19        2\n",
      "1.07        2\n",
      "2.48        2\n",
      "0.16        1\n",
      "0.75        1\n",
      "1.45        1\n",
      "4.68        1\n",
      "1.37        1\n",
      "0.07        1\n",
      "3.41        1\n",
      "7.53        1\n",
      "8.00        1\n",
      "1.82        1\n",
      "0.56        1\n",
      "2.07        1\n",
      "3.50        1\n",
      "4.87        1\n",
      "0.19        1\n",
      "1.97        1\n",
      "4.24        1\n",
      "1.10        1\n",
      "0.89        1\n",
      "1.34        1\n",
      "3.63        1\n",
      "2.81        1\n",
      "3.15        1\n",
      "2.03        1\n",
      "2.06        1\n",
      "1.79        1\n",
      "6.56        1\n",
      "2.73        1\n",
      "3.88        1\n",
      "0.95        1\n",
      "1.54        1\n",
      "3.19        1\n",
      "6.52        1\n",
      "0.88        1\n",
      "16.66       1\n",
      "4.91        1\n",
      "3.49        1\n",
      "0.18        1\n",
      "0.94        1\n",
      "2.36        1\n",
      "0.60        1\n",
      "1.63        1\n",
      "3.97        1\n",
      "2.27        1\n",
      "4.70        1\n",
      "1.27        1\n",
      "2.97        1\n",
      "2.59        1\n",
      "2.61        1\n",
      "8.33        1\n",
      "10.86       1\n",
      "3.92        1\n",
      "2.85        1\n",
      "1.85        1\n",
      "2.54        1\n",
      "1.29        1\n",
      "1.08        1\n",
      "0.08        1\n",
      "2.80        1\n",
      "2.75        1\n",
      "2.66        1\n",
      "1.39        1\n",
      "4.54        1\n",
      "2.30        1\n",
      "1.80        1\n",
      "2.68        1\n",
      "3.17        1\n",
      "3.93        1\n",
      "1.77        1\n",
      "1.46        1\n",
      "0.04        1\n",
      "0.93        1\n",
      "7.40        1\n",
      "6.06        1\n",
      "1.32        1\n",
      "2.08        1\n",
      "6.00        1\n",
      "1.47        1\n",
      "3.47        1\n",
      "1.74        1\n",
      "3.52        1\n",
      "2.45        1\n",
      "0.82        1\n",
      "1.42        1\n",
      "3.20        1\n",
      "2.72        1\n",
      "5.21        1\n",
      "3.56        1\n",
      "1.84        1\n",
      "5.51        1\n",
      "6.15        1\n",
      "6.89        1\n",
      "1.04        1\n",
      "3.87        1\n",
      "1.53        1\n",
      "6.49        1\n",
      "3.00        1\n",
      "2.20        1\n",
      "3.96        1\n",
      "2.47        1\n",
      "2.18        1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "word_freq_george\n",
      "0.00     3646\n",
      "20.00      78\n",
      "25.00      15\n",
      "0.05       15\n",
      "0.70       13\n",
      "4.76        9\n",
      "0.08        9\n",
      "16.66       9\n",
      "2.00        8\n",
      "4.34        7\n",
      "3.03        7\n",
      "1.17        7\n",
      "0.68        7\n",
      "2.63        7\n",
      "4.16        7\n",
      "0.11        6\n",
      "1.36        6\n",
      "7.69        6\n",
      "1.66        6\n",
      "1.40        6\n",
      "0.88        6\n",
      "1.63        6\n",
      "2.56        6\n",
      "14.28       6\n",
      "1.20        6\n",
      "0.18        5\n",
      "0.86        5\n",
      "1.47        5\n",
      "0.49        5\n",
      "1.16        5\n",
      "1.12        5\n",
      "1.19        5\n",
      "0.67        5\n",
      "0.32        5\n",
      "0.07        5\n",
      "0.28        5\n",
      "0.06        5\n",
      "0.12        5\n",
      "1.52        5\n",
      "0.16        5\n",
      "2.77        5\n",
      "0.54        5\n",
      "5.00        4\n",
      "1.37        4\n",
      "0.85        4\n",
      "0.09        4\n",
      "4.00        4\n",
      "0.38        4\n",
      "9.09        4\n",
      "11.11       4\n",
      "0.10        4\n",
      "0.97        4\n",
      "0.47        4\n",
      "0.90        4\n",
      "1.06        4\n",
      "1.21        4\n",
      "1.88        4\n",
      "1.72        4\n",
      "1.86        4\n",
      "33.33       4\n",
      "0.87        4\n",
      "2.12        4\n",
      "0.24        4\n",
      "1.76        4\n",
      "0.52        4\n",
      "3.57        4\n",
      "1.92        4\n",
      "2.04        4\n",
      "1.02        4\n",
      "1.25        3\n",
      "1.91        3\n",
      "2.38        3\n",
      "1.49        3\n",
      "4.54        3\n",
      "0.72        3\n",
      "0.03        3\n",
      "0.29        3\n",
      "0.83        3\n",
      "3.44        3\n",
      "1.56        3\n",
      "0.02        3\n",
      "5.88        3\n",
      "1.51        3\n",
      "1.23        3\n",
      "0.20        3\n",
      "0.01        3\n",
      "2.22        3\n",
      "3.33        3\n",
      "2.32        3\n",
      "5.55        3\n",
      "0.64        3\n",
      "0.93        3\n",
      "0.39        3\n",
      "1.58        3\n",
      "0.81        3\n",
      "0.58        3\n",
      "1.28        3\n",
      "0.77        3\n",
      "0.50        3\n",
      "0.22        3\n",
      "0.04        3\n",
      "1.05        3\n",
      "1.38        3\n",
      "2.17        3\n",
      "1.54        3\n",
      "1.01        3\n",
      "3.12        3\n",
      "1.85        3\n",
      "0.55        3\n",
      "0.17        3\n",
      "0.35        3\n",
      "0.53        3\n",
      "0.13        2\n",
      "2.27        2\n",
      "1.70        2\n",
      "1.81        2\n",
      "0.71        2\n",
      "12.50       2\n",
      "0.45        2\n",
      "0.66        2\n",
      "2.35        2\n",
      "1.08        2\n",
      "0.80        2\n",
      "0.59        2\n",
      "2.94        2\n",
      "0.76        2\n",
      "2.59        2\n",
      "0.65        2\n",
      "0.91        2\n",
      "1.11        2\n",
      "3.70        2\n",
      "0.25        2\n",
      "2.85        2\n",
      "1.07        2\n",
      "1.33        2\n",
      "0.61        2\n",
      "0.92        2\n",
      "0.75        2\n",
      "1.26        2\n",
      "2.43        2\n",
      "3.22        2\n",
      "0.48        2\n",
      "1.98        2\n",
      "1.35        2\n",
      "0.96        2\n",
      "1.00        2\n",
      "1.04        2\n",
      "0.73        2\n",
      "1.14        2\n",
      "1.69        2\n",
      "0.43        2\n",
      "3.50        2\n",
      "1.29        2\n",
      "2.70        2\n",
      "2.73        2\n",
      "0.51        2\n",
      "1.22        2\n",
      "2.15        1\n",
      "1.80        1\n",
      "8.33        1\n",
      "2.50        1\n",
      "0.23        1\n",
      "0.74        1\n",
      "1.62        1\n",
      "0.63        1\n",
      "2.41        1\n",
      "2.20        1\n",
      "1.94        1\n",
      "1.78        1\n",
      "0.40        1\n",
      "2.67        1\n",
      "6.25        1\n",
      "1.09        1\n",
      "0.19        1\n",
      "2.01        1\n",
      "2.60        1\n",
      "0.31        1\n",
      "3.84        1\n",
      "1.03        1\n",
      "1.24        1\n",
      "3.47        1\n",
      "2.30        1\n",
      "2.06        1\n",
      "2.28        1\n",
      "0.21        1\n",
      "1.34        1\n",
      "1.31        1\n",
      "2.19        1\n",
      "0.62        1\n",
      "1.50        1\n",
      "1.32        1\n",
      "8.88        1\n",
      "7.31        1\n",
      "0.30        1\n",
      "3.06        1\n",
      "2.25        1\n",
      "1.65        1\n",
      "1.18        1\n",
      "1.75        1\n",
      "0.69        1\n",
      "6.66        1\n",
      "0.57        1\n",
      "0.37        1\n",
      "1.45        1\n",
      "0.95        1\n",
      "0.33        1\n",
      "2.08        1\n",
      "1.46        1\n",
      "0.84        1\n",
      "3.10        1\n",
      "1.96        1\n",
      "1.43        1\n",
      "2.75        1\n",
      "5.12        1\n",
      "2.46        1\n",
      "2.02        1\n",
      "3.15        1\n",
      "0.82        1\n",
      "2.88        1\n",
      "1.42        1\n",
      "0.99        1\n",
      "3.17        1\n",
      "0.42        1\n",
      "1.61        1\n",
      "1.97        1\n",
      "1.13        1\n",
      "1.41        1\n",
      "4.28        1\n",
      "0.14        1\n",
      "2.24        1\n",
      "0.27        1\n",
      "13.33       1\n",
      "4.44        1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "word_freq_650\n",
      "0.00    3939\n",
      "0.24       7\n",
      "4.76       7\n",
      "2.04       7\n",
      "0.68       6\n",
      "0.66       6\n",
      "0.15       6\n",
      "0.29       5\n",
      "0.58       5\n",
      "0.50       5\n",
      "0.39       5\n",
      "0.63       5\n",
      "0.64       5\n",
      "0.54       5\n",
      "0.59       5\n",
      "0.10       5\n",
      "0.25       4\n",
      "1.28       4\n",
      "0.88       4\n",
      "1.31       4\n",
      "0.43       4\n",
      "0.19       4\n",
      "0.17       4\n",
      "0.74       4\n",
      "4.34       4\n",
      "2.77       4\n",
      "0.86       4\n",
      "0.73       4\n",
      "0.49       4\n",
      "0.32       4\n",
      "2.32       4\n",
      "0.28       4\n",
      "0.78       3\n",
      "0.45       3\n",
      "3.70       3\n",
      "1.01       3\n",
      "0.67       3\n",
      "0.33       3\n",
      "3.12       3\n",
      "0.93       3\n",
      "0.13       3\n",
      "0.08       3\n",
      "0.80       3\n",
      "0.04       3\n",
      "1.56       3\n",
      "0.56       3\n",
      "0.57       3\n",
      "0.41       3\n",
      "0.72       3\n",
      "0.38       3\n",
      "2.38       3\n",
      "0.34       3\n",
      "1.26       3\n",
      "0.22       3\n",
      "3.57       3\n",
      "0.76       3\n",
      "0.44       3\n",
      "0.06       3\n",
      "0.42       3\n",
      "0.05       3\n",
      "1.08       3\n",
      "0.27       3\n",
      "1.74       3\n",
      "0.52       3\n",
      "0.48       3\n",
      "1.20       3\n",
      "0.85       3\n",
      "0.35       3\n",
      "0.55       3\n",
      "1.33       3\n",
      "0.16       3\n",
      "0.37       2\n",
      "0.26       2\n",
      "3.44       2\n",
      "0.51       2\n",
      "1.35       2\n",
      "1.50       2\n",
      "0.75       2\n",
      "2.53       2\n",
      "1.72       2\n",
      "1.23       2\n",
      "0.09       2\n",
      "0.77       2\n",
      "0.12       2\n",
      "1.17       2\n",
      "2.73       2\n",
      "1.87       2\n",
      "0.81       2\n",
      "3.03       2\n",
      "1.66       2\n",
      "0.65       2\n",
      "1.75       2\n",
      "0.02       2\n",
      "1.05       2\n",
      "0.20       2\n",
      "1.47       2\n",
      "0.21       2\n",
      "0.62       2\n",
      "1.22       2\n",
      "1.58       2\n",
      "1.44       2\n",
      "0.61       2\n",
      "2.34       2\n",
      "0.91       2\n",
      "1.11       2\n",
      "1.19       2\n",
      "1.70       2\n",
      "0.46       2\n",
      "0.70       2\n",
      "1.94       2\n",
      "0.23       2\n",
      "0.89       2\n",
      "0.31       2\n",
      "4.00       2\n",
      "0.90       2\n",
      "0.60       2\n",
      "1.69       2\n",
      "2.43       2\n",
      "1.96       2\n",
      "2.00       2\n",
      "0.96       2\n",
      "2.35       2\n",
      "1.57       2\n",
      "0.99       2\n",
      "3.84       1\n",
      "1.49       1\n",
      "2.94       1\n",
      "1.12       1\n",
      "4.16       1\n",
      "0.36       1\n",
      "2.63       1\n",
      "1.25       1\n",
      "1.73       1\n",
      "3.29       1\n",
      "0.11       1\n",
      "1.13       1\n",
      "4.25       1\n",
      "1.39       1\n",
      "1.78       1\n",
      "5.88       1\n",
      "1.06       1\n",
      "2.23       1\n",
      "2.81       1\n",
      "1.29       1\n",
      "1.51       1\n",
      "0.87       1\n",
      "0.97       1\n",
      "1.14       1\n",
      "1.48       1\n",
      "1.03       1\n",
      "2.22       1\n",
      "1.45       1\n",
      "1.86       1\n",
      "0.98       1\n",
      "9.09       1\n",
      "2.56       1\n",
      "2.19       1\n",
      "2.08       1\n",
      "3.33       1\n",
      "1.38       1\n",
      "1.02       1\n",
      "2.46       1\n",
      "4.65       1\n",
      "2.97       1\n",
      "4.44       1\n",
      "1.85       1\n",
      "3.92       1\n",
      "3.38       1\n",
      "1.37       1\n",
      "0.30       1\n",
      "2.10       1\n",
      "4.54       1\n",
      "0.92       1\n",
      "1.62       1\n",
      "1.18       1\n",
      "0.40       1\n",
      "1.30       1\n",
      "2.27       1\n",
      "1.09       1\n",
      "2.91       1\n",
      "0.82       1\n",
      "2.15       1\n",
      "0.03       1\n",
      "1.16       1\n",
      "0.94       1\n",
      "1.00       1\n",
      "2.24       1\n",
      "1.36       1\n",
      "1.07       1\n",
      "1.42       1\n",
      "1.81       1\n",
      "2.02       1\n",
      "2.66       1\n",
      "3.17       1\n",
      "1.27       1\n",
      "0.18       1\n",
      "2.20       1\n",
      "0.53       1\n",
      "2.17       1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "word_freq_lab\n",
      "0.00     4025\n",
      "0.50        9\n",
      "0.58        8\n",
      "0.68        7\n",
      "4.76        6\n",
      "0.02        6\n",
      "0.39        6\n",
      "0.22        5\n",
      "0.51        5\n",
      "0.32        5\n",
      "0.64        5\n",
      "0.55        5\n",
      "0.20        5\n",
      "0.54        5\n",
      "0.86        5\n",
      "2.00        5\n",
      "0.15        4\n",
      "0.28        4\n",
      "1.31        4\n",
      "0.24        4\n",
      "0.76        4\n",
      "0.93        4\n",
      "0.61        4\n",
      "0.26        4\n",
      "0.35        4\n",
      "0.05        4\n",
      "0.33        4\n",
      "0.12        4\n",
      "0.17        4\n",
      "0.90        4\n",
      "4.16        3\n",
      "0.72        3\n",
      "0.19        3\n",
      "0.63        3\n",
      "0.82        3\n",
      "0.14        3\n",
      "0.41        3\n",
      "0.80        3\n",
      "1.58        3\n",
      "1.28        3\n",
      "0.29        3\n",
      "0.03        3\n",
      "0.42        3\n",
      "0.49        3\n",
      "0.53        3\n",
      "4.34        3\n",
      "1.75        3\n",
      "0.01        3\n",
      "0.11        3\n",
      "0.13        3\n",
      "0.65        3\n",
      "0.66        3\n",
      "0.27        3\n",
      "0.34        3\n",
      "2.04        3\n",
      "0.46        3\n",
      "0.87        2\n",
      "0.30        2\n",
      "0.16        2\n",
      "1.53        2\n",
      "10.00       2\n",
      "3.22        2\n",
      "0.37        2\n",
      "1.26        2\n",
      "1.85        2\n",
      "0.40        2\n",
      "0.84        2\n",
      "1.03        2\n",
      "3.12        2\n",
      "0.25        2\n",
      "1.72        2\n",
      "1.20        2\n",
      "0.47        2\n",
      "2.32        2\n",
      "4.54        2\n",
      "0.38        2\n",
      "0.31        2\n",
      "0.48        2\n",
      "2.22        2\n",
      "3.84        2\n",
      "0.60        2\n",
      "3.57        2\n",
      "0.99        2\n",
      "1.08        2\n",
      "1.19        2\n",
      "1.66        2\n",
      "0.52        2\n",
      "0.75        2\n",
      "1.47        2\n",
      "0.92        1\n",
      "0.07        1\n",
      "7.40        1\n",
      "0.09        1\n",
      "0.78        1\n",
      "0.44        1\n",
      "3.03        1\n",
      "0.97        1\n",
      "0.74        1\n",
      "0.43        1\n",
      "2.56        1\n",
      "1.24        1\n",
      "1.41        1\n",
      "1.81        1\n",
      "1.52        1\n",
      "4.00        1\n",
      "1.34        1\n",
      "5.26        1\n",
      "2.70        1\n",
      "0.85        1\n",
      "2.64        1\n",
      "0.88        1\n",
      "1.44        1\n",
      "2.08        1\n",
      "0.23        1\n",
      "0.77        1\n",
      "1.93        1\n",
      "0.67        1\n",
      "0.71        1\n",
      "0.36        1\n",
      "1.25        1\n",
      "2.12        1\n",
      "0.59        1\n",
      "0.56        1\n",
      "0.83        1\n",
      "0.73        1\n",
      "0.57        1\n",
      "0.91        1\n",
      "0.10        1\n",
      "7.69        1\n",
      "2.92        1\n",
      "1.27        1\n",
      "5.55        1\n",
      "1.42        1\n",
      "2.29        1\n",
      "6.94        1\n",
      "9.09        1\n",
      "1.01        1\n",
      "1.13        1\n",
      "1.38        1\n",
      "1.11        1\n",
      "5.12        1\n",
      "0.62        1\n",
      "2.27        1\n",
      "1.80        1\n",
      "2.50        1\n",
      "1.56        1\n",
      "2.63        1\n",
      "11.11       1\n",
      "0.06        1\n",
      "1.61        1\n",
      "1.96        1\n",
      "2.76        1\n",
      "6.15        1\n",
      "3.70        1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "word_freq_labs\n",
      "0.00    3912\n",
      "0.24       9\n",
      "0.68       7\n",
      "0.27       7\n",
      "0.17       7\n",
      "0.18       7\n",
      "0.58       6\n",
      "0.34       6\n",
      "0.33       6\n",
      "0.15       6\n",
      "0.25       6\n",
      "0.39       6\n",
      "0.52       6\n",
      "4.76       6\n",
      "0.42       6\n",
      "0.86       6\n",
      "0.11       6\n",
      "0.32       5\n",
      "0.63       5\n",
      "0.28       5\n",
      "1.31       5\n",
      "0.44       5\n",
      "0.66       5\n",
      "0.06       5\n",
      "4.34       5\n",
      "0.10       5\n",
      "0.40       5\n",
      "0.74       5\n",
      "0.46       4\n",
      "1.26       4\n",
      "2.32       4\n",
      "0.09       4\n",
      "0.99       4\n",
      "0.82       4\n",
      "4.16       4\n",
      "0.50       4\n",
      "0.55       4\n",
      "0.51       4\n",
      "0.73       4\n",
      "0.62       4\n",
      "0.54       4\n",
      "0.61       4\n",
      "0.26       4\n",
      "0.23       4\n",
      "0.89       4\n",
      "0.91       4\n",
      "0.12       4\n",
      "0.47       3\n",
      "0.64       3\n",
      "0.20       3\n",
      "1.01       3\n",
      "0.65       3\n",
      "0.67       3\n",
      "0.36       3\n",
      "0.13       3\n",
      "0.56       3\n",
      "1.17       3\n",
      "0.88       3\n",
      "1.23       3\n",
      "0.57       3\n",
      "0.84       3\n",
      "0.19       3\n",
      "1.58       3\n",
      "0.80       3\n",
      "2.00       3\n",
      "0.16       3\n",
      "0.14       3\n",
      "3.57       3\n",
      "2.04       3\n",
      "1.06       3\n",
      "1.96       3\n",
      "0.97       3\n",
      "0.90       3\n",
      "2.77       3\n",
      "1.29       2\n",
      "0.78       2\n",
      "0.08       2\n",
      "0.70       2\n",
      "1.00       2\n",
      "0.07       2\n",
      "0.72       2\n",
      "1.42       2\n",
      "1.14       2\n",
      "0.49       2\n",
      "0.22       2\n",
      "1.20       2\n",
      "0.21       2\n",
      "1.28       2\n",
      "0.37       2\n",
      "0.31       2\n",
      "1.44       2\n",
      "0.29       2\n",
      "0.59       2\n",
      "2.17       2\n",
      "0.87       2\n",
      "1.19       2\n",
      "4.00       2\n",
      "1.08       2\n",
      "1.52       2\n",
      "0.05       2\n",
      "3.44       2\n",
      "1.61       2\n",
      "0.35       2\n",
      "1.16       2\n",
      "0.93       2\n",
      "1.72       2\n",
      "1.07       1\n",
      "0.69       1\n",
      "3.03       1\n",
      "1.39       1\n",
      "1.09       1\n",
      "2.05       1\n",
      "5.88       1\n",
      "2.98       1\n",
      "1.78       1\n",
      "1.13       1\n",
      "1.47       1\n",
      "1.80       1\n",
      "1.15       1\n",
      "0.43       1\n",
      "3.70       1\n",
      "0.83       1\n",
      "0.41       1\n",
      "0.85       1\n",
      "3.63       1\n",
      "3.48       1\n",
      "0.60       1\n",
      "1.22       1\n",
      "1.92       1\n",
      "3.46       1\n",
      "3.33       1\n",
      "3.84       1\n",
      "1.41       1\n",
      "2.22       1\n",
      "1.75       1\n",
      "2.56       1\n",
      "0.01       1\n",
      "3.22       1\n",
      "1.65       1\n",
      "1.84       1\n",
      "1.38       1\n",
      "0.96       1\n",
      "1.81       1\n",
      "1.85       1\n",
      "1.11       1\n",
      "1.33       1\n",
      "1.02       1\n",
      "4.54       1\n",
      "1.66       1\n",
      "0.48       1\n",
      "1.73       1\n",
      "0.30       1\n",
      "2.70       1\n",
      "3.38       1\n",
      "2.24       1\n",
      "1.03       1\n",
      "2.29       1\n",
      "3.73       1\n",
      "0.53       1\n",
      "2.63       1\n",
      "1.43       1\n",
      "1.56       1\n",
      "3.12       1\n",
      "2.79       1\n",
      "2.11       1\n",
      "1.70       1\n",
      "1.12       1\n",
      "1.53       1\n",
      "0.92       1\n",
      "2.19       1\n",
      "2.45       1\n",
      "0.77       1\n",
      "0.38       1\n",
      "0.75       1\n",
      "0.81       1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "word_freq_telnet\n",
      "0.00     4081\n",
      "0.70        8\n",
      "0.26        6\n",
      "0.24        6\n",
      "0.22        5\n",
      "4.76        5\n",
      "0.15        5\n",
      "0.39        5\n",
      "0.27        5\n",
      "0.34        5\n",
      "0.58        5\n",
      "0.16        4\n",
      "0.42        4\n",
      "0.55        4\n",
      "0.23        4\n",
      "0.50        4\n",
      "0.68        4\n",
      "0.18        4\n",
      "0.54        4\n",
      "0.86        4\n",
      "0.59        4\n",
      "0.32        4\n",
      "0.33        4\n",
      "0.76        3\n",
      "0.09        3\n",
      "0.63        3\n",
      "1.26        3\n",
      "0.61        3\n",
      "0.87        3\n",
      "0.73        3\n",
      "4.34        3\n",
      "3.57        3\n",
      "0.80        3\n",
      "0.90        3\n",
      "0.51        3\n",
      "0.17        3\n",
      "4.16        3\n",
      "0.62        3\n",
      "0.49        3\n",
      "0.35        3\n",
      "0.20        3\n",
      "0.66        3\n",
      "1.31        3\n",
      "0.19        3\n",
      "2.04        3\n",
      "1.28        2\n",
      "0.37        2\n",
      "1.14        2\n",
      "0.65        2\n",
      "0.13        2\n",
      "0.45        2\n",
      "0.44        2\n",
      "0.77        2\n",
      "0.28        2\n",
      "2.63        2\n",
      "0.64        2\n",
      "1.16        2\n",
      "1.72        2\n",
      "1.01        2\n",
      "4.54        2\n",
      "0.29        2\n",
      "0.46        2\n",
      "1.29        2\n",
      "1.20        2\n",
      "2.32        2\n",
      "0.74        2\n",
      "0.91        2\n",
      "0.93        2\n",
      "2.00        2\n",
      "2.77        2\n",
      "1.44        2\n",
      "0.30        2\n",
      "1.08        2\n",
      "0.88        1\n",
      "0.85        1\n",
      "0.56        1\n",
      "0.36        1\n",
      "2.22        1\n",
      "3.12        1\n",
      "3.03        1\n",
      "0.25        1\n",
      "1.56        1\n",
      "0.97        1\n",
      "4.00        1\n",
      "3.84        1\n",
      "1.78        1\n",
      "0.47        1\n",
      "12.50       1\n",
      "1.13        1\n",
      "0.43        1\n",
      "1.49        1\n",
      "0.78        1\n",
      "0.14        1\n",
      "1.06        1\n",
      "2.56        1\n",
      "2.27        1\n",
      "0.10        1\n",
      "1.19        1\n",
      "0.40        1\n",
      "1.66        1\n",
      "1.07        1\n",
      "1.33        1\n",
      "1.11        1\n",
      "0.92        1\n",
      "1.85        1\n",
      "2.70        1\n",
      "0.60        1\n",
      "0.21        1\n",
      "0.72        1\n",
      "0.52        1\n",
      "2.71        1\n",
      "0.99        1\n",
      "0.96        1\n",
      "3.26        1\n",
      "1.38        1\n",
      "1.23        1\n",
      "1.36        1\n",
      "1.92        1\n",
      "0.82        1\n",
      "0.53        1\n",
      "0.75        1\n",
      "0.38        1\n",
      "1.58        1\n",
      "0.12        1\n",
      "0.48        1\n",
      "1.42        1\n",
      "0.79        1\n",
      "0.67        1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "word_freq_857\n",
      "0.00    4176\n",
      "4.76       6\n",
      "0.58       5\n",
      "0.15       4\n",
      "0.68       4\n",
      "0.63       4\n",
      "0.35       4\n",
      "0.55       4\n",
      "0.24       4\n",
      "0.76       4\n",
      "0.86       3\n",
      "0.33       3\n",
      "0.73       3\n",
      "0.87       3\n",
      "0.61       3\n",
      "4.34       3\n",
      "1.01       3\n",
      "0.54       3\n",
      "0.17       3\n",
      "4.16       3\n",
      "0.66       3\n",
      "0.28       3\n",
      "0.51       3\n",
      "0.27       3\n",
      "0.65       2\n",
      "0.26       2\n",
      "1.20       2\n",
      "1.28       2\n",
      "0.37       2\n",
      "0.47       2\n",
      "0.62       2\n",
      "0.44       2\n",
      "0.59       2\n",
      "0.85       2\n",
      "2.04       2\n",
      "0.09       2\n",
      "0.22       2\n",
      "0.31       2\n",
      "0.52       2\n",
      "0.42       2\n",
      "1.31       2\n",
      "0.34       2\n",
      "0.46       2\n",
      "1.08       2\n",
      "0.64       2\n",
      "0.60       2\n",
      "2.32       2\n",
      "0.50       2\n",
      "0.32       2\n",
      "0.19       2\n",
      "0.39       2\n",
      "1.07       1\n",
      "1.63       1\n",
      "1.33       1\n",
      "0.78       1\n",
      "0.70       1\n",
      "0.90       1\n",
      "3.03       1\n",
      "0.97       1\n",
      "0.74       1\n",
      "2.56       1\n",
      "2.00       1\n",
      "4.70       1\n",
      "2.14       1\n",
      "4.00       1\n",
      "0.25       1\n",
      "0.88       1\n",
      "1.44       1\n",
      "0.23       1\n",
      "0.80       1\n",
      "0.77       1\n",
      "1.00       1\n",
      "0.91       1\n",
      "1.72       1\n",
      "0.41       1\n",
      "4.54       1\n",
      "1.11       1\n",
      "3.57       1\n",
      "0.16       1\n",
      "1.38       1\n",
      "1.85       1\n",
      "0.72       1\n",
      "0.99       1\n",
      "0.48       1\n",
      "0.10       1\n",
      "0.45       1\n",
      "0.82       1\n",
      "0.53       1\n",
      "0.75       1\n",
      "0.38       1\n",
      "0.93       1\n",
      "3.17       1\n",
      "2.77       1\n",
      "1.42       1\n",
      "0.13       1\n",
      "0.49       1\n",
      "3.12       1\n",
      "0.29       1\n",
      "1.56       1\n",
      "2.63       1\n",
      "0.67       1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "word_freq_data\n",
      "0.00     3969\n",
      "0.34       12\n",
      "0.14       10\n",
      "0.08        8\n",
      "0.33        8\n",
      "0.23        7\n",
      "0.26        7\n",
      "0.47        7\n",
      "0.27        6\n",
      "0.25        6\n",
      "0.06        5\n",
      "0.37        5\n",
      "0.15        5\n",
      "0.90        5\n",
      "0.45        5\n",
      "0.05        5\n",
      "0.61        4\n",
      "0.21        4\n",
      "0.11        4\n",
      "0.30        4\n",
      "1.40        4\n",
      "0.46        4\n",
      "0.35        4\n",
      "0.16        4\n",
      "0.17        4\n",
      "2.00        4\n",
      "0.10        4\n",
      "0.59        4\n",
      "0.76        4\n",
      "0.74        4\n",
      "1.03        4\n",
      "0.42        3\n",
      "0.57        3\n",
      "1.76        3\n",
      "1.06        3\n",
      "1.85        3\n",
      "1.19        3\n",
      "0.80        3\n",
      "0.07        3\n",
      "0.69        3\n",
      "0.29        3\n",
      "0.20        3\n",
      "0.44        3\n",
      "0.24        3\n",
      "0.52        3\n",
      "0.55        3\n",
      "0.28        3\n",
      "0.49        3\n",
      "0.36        3\n",
      "0.03        3\n",
      "1.15        2\n",
      "3.57        2\n",
      "2.86        2\n",
      "1.66        2\n",
      "0.41        2\n",
      "1.33        2\n",
      "0.39        2\n",
      "1.37        2\n",
      "0.38        2\n",
      "2.85        2\n",
      "1.30        2\n",
      "1.26        2\n",
      "0.22        2\n",
      "0.56        2\n",
      "1.16        2\n",
      "1.47        2\n",
      "0.79        2\n",
      "1.34        2\n",
      "2.35        2\n",
      "0.13        2\n",
      "1.57        2\n",
      "3.30        2\n",
      "4.16        2\n",
      "0.53        2\n",
      "1.58        2\n",
      "0.19        2\n",
      "1.36        2\n",
      "1.88        2\n",
      "0.32        2\n",
      "0.70        2\n",
      "1.25        2\n",
      "0.12        2\n",
      "0.75        2\n",
      "0.65        2\n",
      "1.63        2\n",
      "2.12        2\n",
      "2.13        2\n",
      "2.56        2\n",
      "0.09        2\n",
      "1.01        2\n",
      "1.67        1\n",
      "5.34        1\n",
      "0.95        1\n",
      "5.33        1\n",
      "6.25        1\n",
      "2.10        1\n",
      "5.35        1\n",
      "1.89        1\n",
      "1.60        1\n",
      "1.78        1\n",
      "2.50        1\n",
      "0.04        1\n",
      "1.13        1\n",
      "3.70        1\n",
      "7.40        1\n",
      "0.98        1\n",
      "7.31        1\n",
      "0.64        1\n",
      "1.97        1\n",
      "4.65        1\n",
      "3.84        1\n",
      "4.08        1\n",
      "1.38        1\n",
      "1.79        1\n",
      "3.77        1\n",
      "6.00        1\n",
      "1.44        1\n",
      "1.20        1\n",
      "1.50        1\n",
      "1.81        1\n",
      "1.11        1\n",
      "0.81        1\n",
      "2.83        1\n",
      "0.87        1\n",
      "1.61        1\n",
      "4.74        1\n",
      "18.18       1\n",
      "5.72        1\n",
      "0.40        1\n",
      "1.93        1\n",
      "0.77        1\n",
      "3.40        1\n",
      "2.70        1\n",
      "1.12        1\n",
      "2.08        1\n",
      "2.43        1\n",
      "1.94        1\n",
      "0.51        1\n",
      "0.93        1\n",
      "2.30        1\n",
      "0.50        1\n",
      "4.25        1\n",
      "0.71        1\n",
      "3.06        1\n",
      "2.80        1\n",
      "0.72        1\n",
      "2.38        1\n",
      "1.04        1\n",
      "0.85        1\n",
      "3.73        1\n",
      "2.04        1\n",
      "1.17        1\n",
      "0.67        1\n",
      "3.44        1\n",
      "6.22        1\n",
      "1.21        1\n",
      "2.48        1\n",
      "2.17        1\n",
      "2.06        1\n",
      "1.43        1\n",
      "0.78        1\n",
      "0.02        1\n",
      "0.18        1\n",
      "0.48        1\n",
      "0.84        1\n",
      "0.83        1\n",
      "8.33        1\n",
      "2.15        1\n",
      "0.31        1\n",
      "2.32        1\n",
      "4.76        1\n",
      "0.63        1\n",
      "1.70        1\n",
      "0.73        1\n",
      "0.62        1\n",
      "1.05        1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "word_freq_415\n",
      "0.00    4178\n",
      "0.58       7\n",
      "4.76       6\n",
      "0.63       5\n",
      "0.17       5\n",
      "0.68       5\n",
      "0.39       5\n",
      "0.55       4\n",
      "0.15       4\n",
      "0.24       4\n",
      "1.01       3\n",
      "0.19       3\n",
      "0.61       3\n",
      "0.87       3\n",
      "0.73       3\n",
      "0.35       3\n",
      "0.64       3\n",
      "4.34       3\n",
      "0.66       3\n",
      "0.28       3\n",
      "0.86       3\n",
      "0.33       3\n",
      "0.27       3\n",
      "0.51       3\n",
      "0.76       3\n",
      "0.42       2\n",
      "0.26       2\n",
      "0.44       2\n",
      "1.20       2\n",
      "0.54       2\n",
      "1.28       2\n",
      "0.29       2\n",
      "0.59       2\n",
      "4.16       2\n",
      "1.72       2\n",
      "0.20       2\n",
      "0.65       2\n",
      "0.62       2\n",
      "0.32       2\n",
      "0.09       2\n",
      "0.85       2\n",
      "0.13       2\n",
      "1.08       2\n",
      "0.22       2\n",
      "2.32       2\n",
      "0.38       2\n",
      "0.07       2\n",
      "0.43       2\n",
      "2.04       2\n",
      "0.52       2\n",
      "0.90       2\n",
      "1.31       2\n",
      "0.34       2\n",
      "0.93       2\n",
      "0.46       2\n",
      "0.80       2\n",
      "1.38       2\n",
      "0.60       2\n",
      "0.50       2\n",
      "0.25       1\n",
      "2.14       1\n",
      "2.00       1\n",
      "0.77       1\n",
      "1.33       1\n",
      "4.70       1\n",
      "1.63       1\n",
      "0.70       1\n",
      "1.07       1\n",
      "0.23       1\n",
      "2.22       1\n",
      "3.03       1\n",
      "0.97       1\n",
      "4.00       1\n",
      "3.84       1\n",
      "1.44       1\n",
      "0.88       1\n",
      "2.56       1\n",
      "0.47       1\n",
      "1.00       1\n",
      "0.78       1\n",
      "0.11       1\n",
      "0.37       1\n",
      "0.41       1\n",
      "0.12       1\n",
      "1.35       1\n",
      "0.14       1\n",
      "4.54       1\n",
      "1.11       1\n",
      "3.57       1\n",
      "0.16       1\n",
      "1.85       1\n",
      "0.72       1\n",
      "0.99       1\n",
      "0.48       1\n",
      "2.27       1\n",
      "0.45       1\n",
      "0.82       1\n",
      "0.53       1\n",
      "0.75       1\n",
      "0.30       1\n",
      "3.17       1\n",
      "0.91       1\n",
      "2.77       1\n",
      "1.42       1\n",
      "0.49       1\n",
      "3.12       1\n",
      "1.56       1\n",
      "2.63       1\n",
      "0.67       1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "word_freq_85\n",
      "0.00     3912\n",
      "0.10       13\n",
      "0.24       11\n",
      "0.33       10\n",
      "0.58        9\n",
      "0.50        8\n",
      "0.34        7\n",
      "0.29        7\n",
      "0.22        7\n",
      "0.26        7\n",
      "0.44        6\n",
      "4.76        6\n",
      "0.39        6\n",
      "0.19        6\n",
      "0.31        6\n",
      "0.08        6\n",
      "0.66        5\n",
      "0.15        5\n",
      "0.68        5\n",
      "2.04        5\n",
      "1.72        5\n",
      "0.28        5\n",
      "0.54        5\n",
      "0.67        5\n",
      "0.49        5\n",
      "0.52        4\n",
      "0.86        4\n",
      "0.27        4\n",
      "0.17        4\n",
      "1.26        4\n",
      "0.13        4\n",
      "0.25        4\n",
      "0.60        4\n",
      "2.32        4\n",
      "3.57        4\n",
      "0.80        4\n",
      "0.43        4\n",
      "0.42        4\n",
      "0.59        4\n",
      "0.23        4\n",
      "0.51        4\n",
      "0.36        4\n",
      "0.45        4\n",
      "0.74        3\n",
      "0.88        3\n",
      "1.01        3\n",
      "1.75        3\n",
      "0.46        3\n",
      "0.65        3\n",
      "0.61        3\n",
      "1.31        3\n",
      "1.58        3\n",
      "1.17        3\n",
      "0.64        3\n",
      "0.57        3\n",
      "0.56        3\n",
      "1.28        3\n",
      "1.47        3\n",
      "0.63        3\n",
      "4.34        3\n",
      "0.37        3\n",
      "1.20        3\n",
      "0.06        3\n",
      "0.35        3\n",
      "0.20        3\n",
      "1.08        3\n",
      "0.21        3\n",
      "0.76        3\n",
      "1.19        3\n",
      "0.32        3\n",
      "0.55        3\n",
      "2.00        3\n",
      "0.48        3\n",
      "1.49        2\n",
      "0.07        2\n",
      "0.30        2\n",
      "1.09        2\n",
      "0.03        2\n",
      "1.78        2\n",
      "3.03        2\n",
      "1.02        2\n",
      "0.14        2\n",
      "0.75        2\n",
      "0.89        2\n",
      "0.18        2\n",
      "2.15        2\n",
      "0.79        2\n",
      "1.40        2\n",
      "1.44        2\n",
      "0.09        2\n",
      "0.85        2\n",
      "1.11        2\n",
      "2.22        2\n",
      "2.63        2\n",
      "0.62        2\n",
      "0.12        2\n",
      "0.78        2\n",
      "0.40        2\n",
      "0.90        2\n",
      "1.94        2\n",
      "4.16        2\n",
      "0.91        2\n",
      "0.41        2\n",
      "0.73        2\n",
      "0.99        2\n",
      "0.96        2\n",
      "3.84        2\n",
      "1.85        2\n",
      "0.93        2\n",
      "0.87        1\n",
      "1.14        1\n",
      "20.00       1\n",
      "1.56        1\n",
      "3.12        1\n",
      "1.87        1\n",
      "2.85        1\n",
      "0.77        1\n",
      "1.29        1\n",
      "2.43        1\n",
      "4.11        1\n",
      "1.81        1\n",
      "1.36        1\n",
      "1.50        1\n",
      "1.06        1\n",
      "4.00        1\n",
      "2.69        1\n",
      "0.97        1\n",
      "1.13        1\n",
      "0.11        1\n",
      "2.12        1\n",
      "5.88        1\n",
      "3.70        1\n",
      "0.16        1\n",
      "1.41        1\n",
      "0.71        1\n",
      "2.56        1\n",
      "1.51        1\n",
      "1.03        1\n",
      "1.22        1\n",
      "0.47        1\n",
      "3.40        1\n",
      "1.38        1\n",
      "1.88        1\n",
      "4.54        1\n",
      "0.81        1\n",
      "0.72        1\n",
      "0.98        1\n",
      "4.44        1\n",
      "3.33        1\n",
      "1.69        1\n",
      "1.33        1\n",
      "0.92        1\n",
      "0.70        1\n",
      "2.29        1\n",
      "2.38        1\n",
      "1.92        1\n",
      "1.66        1\n",
      "1.23        1\n",
      "0.01        1\n",
      "2.27        1\n",
      "2.17        1\n",
      "1.16        1\n",
      "1.42        1\n",
      "2.77        1\n",
      "1.91        1\n",
      "0.04        1\n",
      "1.55        1\n",
      "0.38        1\n",
      "0.84        1\n",
      "2.20        1\n",
      "0.53        1\n",
      "3.21        1\n",
      "0.82        1\n",
      "1.35        1\n",
      "2.02        1\n",
      "0.69        1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "word_freq_technology\n",
      "0.00    3777\n",
      "0.09      14\n",
      "0.08      12\n",
      "0.13      10\n",
      "0.42      10\n",
      "0.16      10\n",
      "0.43      10\n",
      "0.58      10\n",
      "0.86       9\n",
      "0.34       9\n",
      "0.15       9\n",
      "0.19       9\n",
      "0.31       9\n",
      "0.24       9\n",
      "0.35       9\n",
      "0.11       8\n",
      "0.37       8\n",
      "0.20       8\n",
      "0.25       8\n",
      "0.12       7\n",
      "0.32       7\n",
      "0.10       7\n",
      "0.39       7\n",
      "0.52       7\n",
      "0.27       7\n",
      "0.22       7\n",
      "0.74       6\n",
      "0.49       6\n",
      "0.54       6\n",
      "0.62       6\n",
      "0.26       6\n",
      "4.76       6\n",
      "0.68       6\n",
      "0.05       6\n",
      "1.16       5\n",
      "0.53       5\n",
      "0.87       5\n",
      "0.73       5\n",
      "0.51       5\n",
      "0.66       5\n",
      "0.78       5\n",
      "0.38       5\n",
      "0.23       5\n",
      "1.28       5\n",
      "0.44       5\n",
      "0.41       5\n",
      "0.28       5\n",
      "0.47       4\n",
      "1.58       4\n",
      "0.07       4\n",
      "0.61       4\n",
      "0.50       4\n",
      "0.91       4\n",
      "0.21       4\n",
      "2.04       4\n",
      "0.18       4\n",
      "0.63       4\n",
      "0.90       4\n",
      "0.57       4\n",
      "1.03       4\n",
      "0.98       4\n",
      "0.85       4\n",
      "0.30       4\n",
      "0.64       4\n",
      "0.72       4\n",
      "0.46       3\n",
      "0.88       3\n",
      "0.04       3\n",
      "0.29       3\n",
      "1.31       3\n",
      "0.59       3\n",
      "0.17       3\n",
      "1.21       3\n",
      "0.55       3\n",
      "0.45       3\n",
      "1.26       3\n",
      "1.05       3\n",
      "0.77       3\n",
      "0.02       3\n",
      "4.16       3\n",
      "1.33       3\n",
      "1.56       3\n",
      "0.60       3\n",
      "0.33       3\n",
      "1.02       3\n",
      "1.36       3\n",
      "2.00       3\n",
      "1.19       3\n",
      "4.34       3\n",
      "0.76       3\n",
      "0.80       3\n",
      "3.57       3\n",
      "1.20       2\n",
      "1.23       2\n",
      "0.65       2\n",
      "0.56       2\n",
      "0.01       2\n",
      "1.24       2\n",
      "0.75       2\n",
      "1.49       2\n",
      "2.56       2\n",
      "0.82       2\n",
      "0.89       2\n",
      "1.08       2\n",
      "0.96       2\n",
      "1.15       2\n",
      "0.97       2\n",
      "1.44       2\n",
      "2.77       2\n",
      "1.38       2\n",
      "1.01       2\n",
      "1.09       2\n",
      "1.42       2\n",
      "1.11       2\n",
      "0.93       2\n",
      "0.14       2\n",
      "1.00       1\n",
      "2.55       1\n",
      "2.08       1\n",
      "0.06       1\n",
      "3.84       1\n",
      "2.27       1\n",
      "4.00       1\n",
      "7.69       1\n",
      "1.29       1\n",
      "1.04       1\n",
      "1.14       1\n",
      "2.32       1\n",
      "1.06       1\n",
      "0.40       1\n",
      "2.22       1\n",
      "1.07       1\n",
      "2.54       1\n",
      "0.81       1\n",
      "0.67       1\n",
      "1.39       1\n",
      "3.03       1\n",
      "1.72       1\n",
      "1.78       1\n",
      "0.71       1\n",
      "1.66       1\n",
      "0.70       1\n",
      "1.80       1\n",
      "0.69       1\n",
      "1.85       1\n",
      "1.63       1\n",
      "0.84       1\n",
      "1.17       1\n",
      "2.85       1\n",
      "4.54       1\n",
      "0.03       1\n",
      "3.12       1\n",
      "1.35       1\n",
      "0.99       1\n",
      "1.18       1\n",
      "1.62       1\n",
      "2.63       1\n",
      "1.97       1\n",
      "1.13       1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "word_freq_1999\n",
      "0.00    3563\n",
      "0.08      15\n",
      "0.24      13\n",
      "0.19      13\n",
      "0.23      13\n",
      "0.29      13\n",
      "0.64      12\n",
      "0.10      12\n",
      "0.31      12\n",
      "0.41      11\n",
      "0.68      11\n",
      "0.26      11\n",
      "0.28      11\n",
      "0.12      10\n",
      "0.22      10\n",
      "0.18      10\n",
      "0.15      10\n",
      "0.30      10\n",
      "0.25       9\n",
      "0.58       9\n",
      "0.74       9\n",
      "0.32       9\n",
      "0.55       9\n",
      "0.35       8\n",
      "0.21       8\n",
      "0.81       8\n",
      "0.45       8\n",
      "0.80       8\n",
      "0.67       8\n",
      "0.13       8\n",
      "0.89       8\n",
      "0.27       7\n",
      "0.86       7\n",
      "0.61       7\n",
      "0.88       7\n",
      "0.47       7\n",
      "0.49       7\n",
      "0.34       7\n",
      "0.50       7\n",
      "0.38       7\n",
      "0.39       6\n",
      "0.97       6\n",
      "0.93       6\n",
      "0.42       6\n",
      "0.17       6\n",
      "0.59       6\n",
      "1.28       6\n",
      "0.85       6\n",
      "0.54       6\n",
      "0.14       6\n",
      "0.07       6\n",
      "0.95       6\n",
      "0.33       6\n",
      "0.16       6\n",
      "1.78       5\n",
      "0.48       5\n",
      "0.87       5\n",
      "1.31       5\n",
      "1.01       5\n",
      "0.20       5\n",
      "0.09       5\n",
      "1.47       5\n",
      "1.21       5\n",
      "0.44       5\n",
      "1.08       5\n",
      "1.36       5\n",
      "0.71       5\n",
      "0.06       5\n",
      "0.36       5\n",
      "0.37       5\n",
      "0.56       5\n",
      "1.38       5\n",
      "0.40       5\n",
      "1.66       4\n",
      "0.92       4\n",
      "0.53       4\n",
      "1.92       4\n",
      "3.33       4\n",
      "1.25       4\n",
      "1.72       4\n",
      "0.90       4\n",
      "0.75       4\n",
      "0.72       4\n",
      "1.11       4\n",
      "0.73       4\n",
      "0.91       4\n",
      "0.11       4\n",
      "0.96       4\n",
      "1.06       4\n",
      "1.19       3\n",
      "0.57       3\n",
      "0.63       3\n",
      "0.46       3\n",
      "1.61       3\n",
      "1.05       3\n",
      "4.34       3\n",
      "1.00       3\n",
      "0.66       3\n",
      "1.04       3\n",
      "1.49       3\n",
      "1.40       3\n",
      "0.51       3\n",
      "1.34       3\n",
      "0.43       3\n",
      "1.56       3\n",
      "0.79       3\n",
      "0.62       3\n",
      "1.44       3\n",
      "1.96       3\n",
      "0.52       3\n",
      "0.65       3\n",
      "1.10       2\n",
      "0.05       2\n",
      "0.78       2\n",
      "2.22       2\n",
      "1.27       2\n",
      "1.53       2\n",
      "0.70       2\n",
      "1.12       2\n",
      "0.94       2\n",
      "2.08       2\n",
      "0.99       2\n",
      "0.84       2\n",
      "1.63       2\n",
      "4.54       2\n",
      "2.56       2\n",
      "0.83       2\n",
      "2.12       2\n",
      "0.60       2\n",
      "1.02       2\n",
      "1.99       2\n",
      "2.43       2\n",
      "1.20       2\n",
      "0.82       2\n",
      "1.35       2\n",
      "1.24       2\n",
      "1.17       2\n",
      "1.23       2\n",
      "3.03       2\n",
      "1.16       2\n",
      "1.42       2\n",
      "2.32       2\n",
      "1.07       2\n",
      "1.33       2\n",
      "2.83       1\n",
      "1.94       1\n",
      "1.14       1\n",
      "1.45       1\n",
      "3.57       1\n",
      "1.46       1\n",
      "6.89       1\n",
      "2.85       1\n",
      "3.70       1\n",
      "1.60       1\n",
      "1.81       1\n",
      "0.76       1\n",
      "1.03       1\n",
      "2.25       1\n",
      "1.22       1\n",
      "1.29       1\n",
      "1.80       1\n",
      "1.65       1\n",
      "1.13       1\n",
      "1.70       1\n",
      "1.51       1\n",
      "1.52       1\n",
      "3.84       1\n",
      "0.69       1\n",
      "1.85       1\n",
      "1.88       1\n",
      "2.46       1\n",
      "1.48       1\n",
      "5.05       1\n",
      "1.09       1\n",
      "1.84       1\n",
      "1.75       1\n",
      "2.94       1\n",
      "2.00       1\n",
      "1.58       1\n",
      "2.16       1\n",
      "1.32       1\n",
      "1.87       1\n",
      "1.69       1\n",
      "1.74       1\n",
      "3.94       1\n",
      "2.17       1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "word_freq_parts\n",
      "0.00    4301\n",
      "0.02       6\n",
      "0.29       6\n",
      "0.11       5\n",
      "0.07       4\n",
      "0.12       3\n",
      "0.10       3\n",
      "0.03       3\n",
      "0.55       2\n",
      "0.06       2\n",
      "0.14       2\n",
      "0.09       2\n",
      "0.08       2\n",
      "0.25       2\n",
      "0.19       2\n",
      "1.52       1\n",
      "0.54       1\n",
      "2.85       1\n",
      "0.40       1\n",
      "7.40       1\n",
      "1.22       1\n",
      "1.44       1\n",
      "0.90       1\n",
      "1.11       1\n",
      "1.57       1\n",
      "8.33       1\n",
      "3.44       1\n",
      "4.00       1\n",
      "6.45       1\n",
      "0.04       1\n",
      "0.80       1\n",
      "0.37       1\n",
      "0.93       1\n",
      "0.05       1\n",
      "0.36       1\n",
      "1.56       1\n",
      "0.42       1\n",
      "0.50       1\n",
      "0.41       1\n",
      "0.24       1\n",
      "0.28       1\n",
      "0.43       1\n",
      "0.45       1\n",
      "1.02       1\n",
      "0.72       1\n",
      "0.46       1\n",
      "0.81       1\n",
      "0.01       1\n",
      "0.16       1\n",
      "0.23       1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "word_freq_pm\n",
      "0.00     3997\n",
      "0.10       10\n",
      "0.64        8\n",
      "0.09        7\n",
      "0.19        7\n",
      "0.11        6\n",
      "0.58        6\n",
      "0.66        6\n",
      "0.31        6\n",
      "0.28        5\n",
      "0.33        5\n",
      "0.53        5\n",
      "0.16        5\n",
      "0.48        5\n",
      "0.52        5\n",
      "1.21        5\n",
      "0.32        5\n",
      "0.68        5\n",
      "0.27        5\n",
      "0.35        4\n",
      "0.87        4\n",
      "0.88        4\n",
      "0.62        4\n",
      "0.34        4\n",
      "0.50        4\n",
      "0.47        4\n",
      "0.23        4\n",
      "0.20        4\n",
      "0.55        3\n",
      "0.91        3\n",
      "0.29        3\n",
      "0.37        3\n",
      "1.60        3\n",
      "0.76        3\n",
      "1.58        3\n",
      "1.72        3\n",
      "0.84        3\n",
      "0.67        3\n",
      "0.36        3\n",
      "1.69        3\n",
      "1.01        3\n",
      "0.42        3\n",
      "1.88        3\n",
      "1.25        3\n",
      "0.72        3\n",
      "0.73        3\n",
      "0.74        3\n",
      "0.51        3\n",
      "0.04        3\n",
      "0.21        3\n",
      "0.85        3\n",
      "3.03        3\n",
      "1.17        3\n",
      "0.63        2\n",
      "1.47        2\n",
      "1.49        2\n",
      "0.69        2\n",
      "1.36        2\n",
      "0.38        2\n",
      "4.54        2\n",
      "0.80        2\n",
      "2.27        2\n",
      "1.16        2\n",
      "0.81        2\n",
      "0.49        2\n",
      "0.13        2\n",
      "1.05        2\n",
      "0.22        2\n",
      "0.46        2\n",
      "1.19        2\n",
      "1.07        2\n",
      "0.59        2\n",
      "0.78        2\n",
      "0.45        2\n",
      "0.70        2\n",
      "1.42        2\n",
      "0.02        2\n",
      "1.38        2\n",
      "1.96        2\n",
      "0.15        2\n",
      "0.01        2\n",
      "0.17        2\n",
      "0.26        2\n",
      "0.93        2\n",
      "4.00        2\n",
      "1.29        2\n",
      "0.65        2\n",
      "0.30        2\n",
      "0.54        2\n",
      "2.56        2\n",
      "0.08        2\n",
      "0.24        2\n",
      "0.18        2\n",
      "0.57        1\n",
      "1.35        1\n",
      "1.92        1\n",
      "1.94        1\n",
      "1.73        1\n",
      "0.60        1\n",
      "4.16        1\n",
      "0.95        1\n",
      "1.08        1\n",
      "0.43        1\n",
      "2.38        1\n",
      "2.40        1\n",
      "0.86        1\n",
      "1.06        1\n",
      "0.99        1\n",
      "1.78        1\n",
      "0.44        1\n",
      "2.22        1\n",
      "9.75        1\n",
      "2.94        1\n",
      "2.63        1\n",
      "0.25        1\n",
      "1.33        1\n",
      "1.02        1\n",
      "1.85        1\n",
      "8.69        1\n",
      "0.07        1\n",
      "4.87        1\n",
      "11.11       1\n",
      "0.71        1\n",
      "1.23        1\n",
      "0.89        1\n",
      "0.92        1\n",
      "7.14        1\n",
      "1.56        1\n",
      "1.11        1\n",
      "0.75        1\n",
      "1.31        1\n",
      "3.22        1\n",
      "0.96        1\n",
      "0.90        1\n",
      "0.79        1\n",
      "3.70        1\n",
      "1.30        1\n",
      "1.12        1\n",
      "2.02        1\n",
      "1.48        1\n",
      "1.75        1\n",
      "1.39        1\n",
      "3.53        1\n",
      "1.51        1\n",
      "2.64        1\n",
      "2.89        1\n",
      "1.22        1\n",
      "3.75        1\n",
      "1.40        1\n",
      "0.12        1\n",
      "0.56        1\n",
      "0.14        1\n",
      "4.34        1\n",
      "0.40        1\n",
      "2.12        1\n",
      "1.04        1\n",
      "2.08        1\n",
      "1.13        1\n",
      "1.86        1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "word_freq_direct\n",
      "0.00    3956\n",
      "0.08      24\n",
      "0.16      13\n",
      "0.11      12\n",
      "0.17      12\n",
      "0.12      10\n",
      "0.46      10\n",
      "0.09      10\n",
      "0.15      10\n",
      "0.58       8\n",
      "0.50       8\n",
      "2.11       8\n",
      "0.10       8\n",
      "0.24       7\n",
      "0.51       7\n",
      "0.06       7\n",
      "0.27       7\n",
      "0.19       7\n",
      "0.03       6\n",
      "0.14       6\n",
      "0.04       6\n",
      "0.65       6\n",
      "0.34       6\n",
      "0.26       6\n",
      "0.28       5\n",
      "4.76       5\n",
      "0.02       5\n",
      "0.68       5\n",
      "0.39       5\n",
      "0.44       5\n",
      "4.16       5\n",
      "0.32       4\n",
      "0.35       4\n",
      "0.37       4\n",
      "0.55       4\n",
      "0.52       4\n",
      "0.33       4\n",
      "0.66       4\n",
      "0.05       4\n",
      "0.07       4\n",
      "0.20       4\n",
      "0.63       4\n",
      "0.48       4\n",
      "0.87       3\n",
      "0.73       3\n",
      "0.22       3\n",
      "0.38       3\n",
      "0.43       3\n",
      "0.54       3\n",
      "0.86       3\n",
      "0.45       3\n",
      "0.49       3\n",
      "0.42       3\n",
      "0.47       3\n",
      "0.93       3\n",
      "0.74       3\n",
      "0.64       3\n",
      "0.29       3\n",
      "2.32       2\n",
      "0.80       2\n",
      "0.76       2\n",
      "0.36       2\n",
      "1.31       2\n",
      "0.01       2\n",
      "1.20       2\n",
      "0.92       2\n",
      "1.59       2\n",
      "0.21       2\n",
      "1.08       2\n",
      "0.59       2\n",
      "2.04       2\n",
      "0.13       2\n",
      "1.72       2\n",
      "0.61       2\n",
      "2.22       2\n",
      "1.01       2\n",
      "0.25       2\n",
      "0.31       2\n",
      "0.53       2\n",
      "1.36       2\n",
      "4.34       2\n",
      "0.62       2\n",
      "0.91       2\n",
      "2.12       1\n",
      "0.56       1\n",
      "0.78       1\n",
      "3.03       1\n",
      "2.00       1\n",
      "2.56       1\n",
      "1.17       1\n",
      "3.84       1\n",
      "0.77       1\n",
      "0.85       1\n",
      "4.00       1\n",
      "0.90       1\n",
      "0.23       1\n",
      "1.44       1\n",
      "0.88       1\n",
      "1.56       1\n",
      "2.63       1\n",
      "1.00       1\n",
      "3.12       1\n",
      "3.57       1\n",
      "0.96       1\n",
      "1.07       1\n",
      "0.97       1\n",
      "0.89       1\n",
      "1.19       1\n",
      "0.40       1\n",
      "1.62       1\n",
      "4.54       1\n",
      "1.11       1\n",
      "1.85       1\n",
      "1.42       1\n",
      "0.60       1\n",
      "0.72       1\n",
      "0.99       1\n",
      "2.27       1\n",
      "0.82       1\n",
      "1.28       1\n",
      "0.75       1\n",
      "1.58       1\n",
      "2.77       1\n",
      "0.67       1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "word_freq_cs\n",
      "0.00    4237\n",
      "0.31       5\n",
      "7.14       4\n",
      "0.10       3\n",
      "1.44       3\n",
      "4.75       3\n",
      "0.34       3\n",
      "0.25       3\n",
      "0.37       2\n",
      "2.56       2\n",
      "0.61       2\n",
      "0.46       2\n",
      "2.00       2\n",
      "1.35       2\n",
      "0.16       2\n",
      "1.01       2\n",
      "0.36       2\n",
      "0.06       2\n",
      "0.86       2\n",
      "0.68       2\n",
      "0.62       2\n",
      "0.65       2\n",
      "0.19       2\n",
      "1.58       2\n",
      "0.51       2\n",
      "0.13       2\n",
      "1.16       2\n",
      "0.08       2\n",
      "0.02       1\n",
      "2.81       1\n",
      "0.84       1\n",
      "1.69       1\n",
      "2.83       1\n",
      "0.93       1\n",
      "3.26       1\n",
      "0.54       1\n",
      "0.07       1\n",
      "0.69       1\n",
      "0.32       1\n",
      "0.75       1\n",
      "0.98       1\n",
      "0.38       1\n",
      "1.26       1\n",
      "0.52       1\n",
      "2.15       1\n",
      "1.06       1\n",
      "0.92       1\n",
      "0.44       1\n",
      "0.42       1\n",
      "1.02       1\n",
      "0.21       1\n",
      "1.92       1\n",
      "1.88       1\n",
      "0.53       1\n",
      "4.28       1\n",
      "1.17       1\n",
      "0.81       1\n",
      "1.20       1\n",
      "0.60       1\n",
      "2.32       1\n",
      "0.23       1\n",
      "1.28       1\n",
      "1.66       1\n",
      "1.80       1\n",
      "0.80       1\n",
      "1.70       1\n",
      "1.94       1\n",
      "0.29       1\n",
      "0.94       1\n",
      "0.76       1\n",
      "1.38       1\n",
      "0.26       1\n",
      "0.33       1\n",
      "2.31       1\n",
      "3.25       1\n",
      "1.29       1\n",
      "0.59       1\n",
      "1.24       1\n",
      "1.62       1\n",
      "0.18       1\n",
      "3.12       1\n",
      "1.56       1\n",
      "0.17       1\n",
      "1.40       1\n",
      "0.28       1\n",
      "0.39       1\n",
      "0.71       1\n",
      "1.30       1\n",
      "2.26       1\n",
      "2.22       1\n",
      "5.88       1\n",
      "2.80       1\n",
      "3.22       1\n",
      "5.00       1\n",
      "0.56       1\n",
      "2.50       1\n",
      "0.35       1\n",
      "0.89       1\n",
      "0.20       1\n",
      "2.11       1\n",
      "0.03       1\n",
      "3.07       1\n",
      "4.76       1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "word_freq_meeting\n",
      "0.00     4049\n",
      "0.11        8\n",
      "0.06        6\n",
      "0.08        6\n",
      "0.90        5\n",
      "3.84        5\n",
      "0.28        5\n",
      "0.80        5\n",
      "0.71        5\n",
      "0.03        5\n",
      "0.02        4\n",
      "0.52        4\n",
      "0.76        4\n",
      "0.25        4\n",
      "3.70        4\n",
      "1.21        4\n",
      "0.07        4\n",
      "0.93        3\n",
      "0.60        3\n",
      "0.01        3\n",
      "0.04        3\n",
      "1.38        3\n",
      "5.00        3\n",
      "2.85        3\n",
      "0.45        3\n",
      "1.02        3\n",
      "0.41        3\n",
      "2.12        3\n",
      "0.12        3\n",
      "2.32        3\n",
      "0.37        3\n",
      "5.26        2\n",
      "1.04        2\n",
      "4.00        2\n",
      "2.15        2\n",
      "0.61        2\n",
      "2.70        2\n",
      "0.77        2\n",
      "0.87        2\n",
      "0.78        2\n",
      "0.22        2\n",
      "1.23        2\n",
      "3.57        2\n",
      "1.96        2\n",
      "0.33        2\n",
      "0.88        2\n",
      "11.11       2\n",
      "4.76        2\n",
      "0.27        2\n",
      "14.28       2\n",
      "0.46        2\n",
      "0.19        2\n",
      "0.13        2\n",
      "0.38        2\n",
      "2.35        2\n",
      "0.50        2\n",
      "1.69        2\n",
      "0.75        2\n",
      "1.78        2\n",
      "7.69        2\n",
      "2.22        2\n",
      "1.34        2\n",
      "0.89        2\n",
      "2.43        2\n",
      "0.54        2\n",
      "0.97        2\n",
      "2.23        2\n",
      "3.22        2\n",
      "0.92        2\n",
      "9.09        2\n",
      "1.81        2\n",
      "1.75        2\n",
      "0.96        2\n",
      "0.91        2\n",
      "1.60        2\n",
      "1.85        2\n",
      "0.73        2\n",
      "4.08        2\n",
      "0.32        2\n",
      "0.18        2\n",
      "0.34        2\n",
      "0.23        2\n",
      "0.39        2\n",
      "1.25        2\n",
      "4.54        2\n",
      "0.85        2\n",
      "0.53        2\n",
      "1.17        1\n",
      "0.43        1\n",
      "1.47        1\n",
      "0.55        1\n",
      "6.34        1\n",
      "3.63        1\n",
      "0.70        1\n",
      "1.27        1\n",
      "2.17        1\n",
      "0.84        1\n",
      "1.16        1\n",
      "0.68        1\n",
      "5.55        1\n",
      "7.40        1\n",
      "2.81        1\n",
      "3.12        1\n",
      "1.00        1\n",
      "5.40        1\n",
      "1.72        1\n",
      "0.16        1\n",
      "2.58        1\n",
      "7.89        1\n",
      "0.48        1\n",
      "0.83        1\n",
      "0.44        1\n",
      "1.49        1\n",
      "0.58        1\n",
      "8.33        1\n",
      "6.45        1\n",
      "0.95        1\n",
      "0.94        1\n",
      "2.10        1\n",
      "0.47        1\n",
      "0.51        1\n",
      "0.09        1\n",
      "1.24        1\n",
      "0.59        1\n",
      "0.69        1\n",
      "2.95        1\n",
      "1.19        1\n",
      "1.20        1\n",
      "3.09        1\n",
      "4.83        1\n",
      "2.69        1\n",
      "6.94        1\n",
      "0.57        1\n",
      "6.06        1\n",
      "1.88        1\n",
      "2.40        1\n",
      "1.09        1\n",
      "3.44        1\n",
      "2.02        1\n",
      "1.44        1\n",
      "7.14        1\n",
      "1.86        1\n",
      "0.24        1\n",
      "0.66        1\n",
      "1.05        1\n",
      "0.40        1\n",
      "1.10        1\n",
      "1.62        1\n",
      "5.12        1\n",
      "1.90        1\n",
      "0.67        1\n",
      "2.89        1\n",
      "0.35        1\n",
      "2.94        1\n",
      "1.31        1\n",
      "2.64        1\n",
      "1.42        1\n",
      "1.80        1\n",
      "4.44        1\n",
      "0.82        1\n",
      "0.49        1\n",
      "1.13        1\n",
      "3.27        1\n",
      "3.33        1\n",
      "4.91        1\n",
      "1.43        1\n",
      "0.64        1\n",
      "3.92        1\n",
      "3.40        1\n",
      "1.33        1\n",
      "2.63        1\n",
      "0.14        1\n",
      "2.50        1\n",
      "1.26        1\n",
      "0.20        1\n",
      "1.06        1\n",
      "6.15        1\n",
      "4.16        1\n",
      "3.03        1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "word_freq_original\n",
      "0.00    4024\n",
      "0.20      18\n",
      "0.17      15\n",
      "0.06      13\n",
      "0.24       8\n",
      "0.68       7\n",
      "0.02       7\n",
      "0.18       7\n",
      "0.11       7\n",
      "0.19       6\n",
      "0.33       6\n",
      "0.31       6\n",
      "0.08       6\n",
      "0.09       6\n",
      "0.13       5\n",
      "0.07       5\n",
      "0.04       5\n",
      "0.64       5\n",
      "0.38       5\n",
      "0.03       4\n",
      "0.35       4\n",
      "0.50       4\n",
      "0.14       4\n",
      "0.26       4\n",
      "0.34       4\n",
      "0.30       4\n",
      "0.58       4\n",
      "0.85       4\n",
      "0.76       4\n",
      "0.87       4\n",
      "0.52       4\n",
      "0.42       3\n",
      "0.66       3\n",
      "0.72       3\n",
      "0.43       3\n",
      "0.73       3\n",
      "0.32       3\n",
      "0.22       3\n",
      "0.12       3\n",
      "1.01       3\n",
      "0.39       3\n",
      "0.37       3\n",
      "0.56       3\n",
      "0.55       3\n",
      "0.16       3\n",
      "0.54       3\n",
      "0.48       3\n",
      "0.05       3\n",
      "0.27       3\n",
      "0.41       3\n",
      "0.70       2\n",
      "1.60       2\n",
      "1.72       2\n",
      "1.56       2\n",
      "0.63       2\n",
      "0.28       2\n",
      "1.25       2\n",
      "0.81       2\n",
      "0.61       2\n",
      "0.74       2\n",
      "0.89       2\n",
      "0.01       2\n",
      "0.65       2\n",
      "0.10       2\n",
      "0.86       2\n",
      "1.05       2\n",
      "0.49       2\n",
      "0.62       2\n",
      "0.53       2\n",
      "0.47       2\n",
      "1.35       2\n",
      "0.88       2\n",
      "0.67       2\n",
      "0.23       2\n",
      "1.31       2\n",
      "0.93       2\n",
      "0.46       2\n",
      "0.36       2\n",
      "1.28       2\n",
      "1.44       2\n",
      "1.38       2\n",
      "0.98       2\n",
      "1.36       2\n",
      "3.57       2\n",
      "0.29       2\n",
      "0.45       2\n",
      "1.20       1\n",
      "0.79       1\n",
      "1.16       1\n",
      "0.25       1\n",
      "0.71       1\n",
      "0.40       1\n",
      "1.73       1\n",
      "0.21       1\n",
      "1.80       1\n",
      "0.84       1\n",
      "1.94       1\n",
      "1.88       1\n",
      "1.10       1\n",
      "1.92       1\n",
      "0.97       1\n",
      "0.94       1\n",
      "0.60       1\n",
      "0.44       1\n",
      "1.04       1\n",
      "0.59       1\n",
      "1.21       1\n",
      "1.11       1\n",
      "1.06       1\n",
      "1.07       1\n",
      "1.17       1\n",
      "0.99       1\n",
      "1.08       1\n",
      "1.02       1\n",
      "3.03       1\n",
      "0.95       1\n",
      "0.78       1\n",
      "0.92       1\n",
      "0.80       1\n",
      "2.63       1\n",
      "3.44       1\n",
      "0.75       1\n",
      "1.84       1\n",
      "1.75       1\n",
      "0.15       1\n",
      "1.40       1\n",
      "0.91       1\n",
      "1.78       1\n",
      "1.42       1\n",
      "1.49       1\n",
      "1.23       1\n",
      "1.69       1\n",
      "3.33       1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "word_freq_project\n",
      "0.00     4051\n",
      "0.08       13\n",
      "0.06       12\n",
      "0.05       10\n",
      "0.28        9\n",
      "0.33        8\n",
      "0.16        8\n",
      "0.02        7\n",
      "0.10        7\n",
      "0.80        6\n",
      "0.26        5\n",
      "0.54        5\n",
      "0.14        4\n",
      "0.03        4\n",
      "0.58        4\n",
      "0.09        4\n",
      "0.32        3\n",
      "0.29        3\n",
      "4.54        3\n",
      "0.86        3\n",
      "0.78        3\n",
      "0.65        3\n",
      "0.84        3\n",
      "1.26        3\n",
      "0.13        3\n",
      "0.23        3\n",
      "0.55        3\n",
      "1.96        3\n",
      "0.22        3\n",
      "0.64        3\n",
      "0.44        3\n",
      "0.36        3\n",
      "0.62        2\n",
      "0.40        2\n",
      "3.57        2\n",
      "0.31        2\n",
      "0.17        2\n",
      "2.32        2\n",
      "1.28        2\n",
      "1.49        2\n",
      "0.68        2\n",
      "1.45        2\n",
      "0.81        2\n",
      "0.52        2\n",
      "0.51        2\n",
      "0.12        2\n",
      "0.67        2\n",
      "0.15        2\n",
      "0.37        2\n",
      "0.27        2\n",
      "2.46        2\n",
      "1.05        2\n",
      "0.04        2\n",
      "0.30        2\n",
      "0.25        2\n",
      "3.22        2\n",
      "0.11        2\n",
      "5.00        2\n",
      "0.72        2\n",
      "2.63        2\n",
      "0.50        2\n",
      "0.63        2\n",
      "1.39        2\n",
      "0.41        2\n",
      "0.24        2\n",
      "0.85        2\n",
      "0.38        1\n",
      "0.34        1\n",
      "4.76        1\n",
      "0.53        1\n",
      "2.78        1\n",
      "0.43        1\n",
      "1.21        1\n",
      "0.21        1\n",
      "1.08        1\n",
      "0.59        1\n",
      "1.07        1\n",
      "2.02        1\n",
      "0.90        1\n",
      "1.37        1\n",
      "20.00       1\n",
      "1.80        1\n",
      "1.23        1\n",
      "0.56        1\n",
      "1.09        1\n",
      "0.45        1\n",
      "16.66       1\n",
      "0.97        1\n",
      "4.16        1\n",
      "0.46        1\n",
      "1.66        1\n",
      "3.12        1\n",
      "2.77        1\n",
      "0.87        1\n",
      "2.04        1\n",
      "1.20        1\n",
      "0.66        1\n",
      "3.04        1\n",
      "0.47        1\n",
      "0.89        1\n",
      "1.90        1\n",
      "1.29        1\n",
      "1.22        1\n",
      "0.61        1\n",
      "2.70        1\n",
      "0.60        1\n",
      "3.09        1\n",
      "3.17        1\n",
      "0.48        1\n",
      "0.35        1\n",
      "3.84        1\n",
      "2.31        1\n",
      "3.30        1\n",
      "1.73        1\n",
      "0.18        1\n",
      "4.57        1\n",
      "4.40        1\n",
      "0.01        1\n",
      "10.00       1\n",
      "8.10        1\n",
      "1.41        1\n",
      "3.33        1\n",
      "0.20        1\n",
      "1.44        1\n",
      "0.42        1\n",
      "1.35        1\n",
      "1.51        1\n",
      "1.60        1\n",
      "0.49        1\n",
      "1.16        1\n",
      "0.96        1\n",
      "3.40        1\n",
      "0.75        1\n",
      "2.56        1\n",
      "1.58        1\n",
      "3.19        1\n",
      "0.39        1\n",
      "1.14        1\n",
      "2.29        1\n",
      "0.07        1\n",
      "1.55        1\n",
      "6.25        1\n",
      "1.56        1\n",
      "1.76        1\n",
      "1.03        1\n",
      "1.88        1\n",
      "0.57        1\n",
      "4.04        1\n",
      "2.10        1\n",
      "1.72        1\n",
      "0.99        1\n",
      "6.34        1\n",
      "1.10        1\n",
      "1.83        1\n",
      "2.38        1\n",
      "1.25        1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "word_freq_re\n",
      "0.00     3129\n",
      "0.08       30\n",
      "0.10       20\n",
      "0.06       19\n",
      "0.33       18\n",
      "0.27       17\n",
      "0.12       17\n",
      "0.05       16\n",
      "0.09       16\n",
      "0.64       16\n",
      "0.41       15\n",
      "0.02       15\n",
      "0.34       14\n",
      "0.55       14\n",
      "0.03       14\n",
      "0.32       14\n",
      "0.07       14\n",
      "0.48       14\n",
      "0.35       13\n",
      "0.39       13\n",
      "0.54       13\n",
      "0.53       12\n",
      "0.28       12\n",
      "0.44       12\n",
      "0.58       12\n",
      "0.22       11\n",
      "0.65       11\n",
      "0.31       11\n",
      "0.68       10\n",
      "1.17       10\n",
      "0.17       10\n",
      "0.29        9\n",
      "0.37        9\n",
      "0.20        9\n",
      "0.15        9\n",
      "0.38        9\n",
      "0.49        9\n",
      "0.62        9\n",
      "0.24        9\n",
      "1.03        9\n",
      "0.61        9\n",
      "0.67        9\n",
      "0.45        9\n",
      "0.30        9\n",
      "0.14        9\n",
      "0.47        9\n",
      "1.23        8\n",
      "0.87        8\n",
      "0.11        8\n",
      "0.56        8\n",
      "0.66        8\n",
      "0.25        8\n",
      "3.33        8\n",
      "0.18        8\n",
      "1.08        8\n",
      "0.51        8\n",
      "0.84        8\n",
      "0.23        8\n",
      "1.29        8\n",
      "0.80        8\n",
      "1.36        8\n",
      "0.57        8\n",
      "1.26        8\n",
      "1.28        8\n",
      "0.86        7\n",
      "0.74        7\n",
      "2.56        7\n",
      "0.76        7\n",
      "0.26        7\n",
      "1.16        7\n",
      "0.70        7\n",
      "1.06        7\n",
      "2.70        7\n",
      "0.93        7\n",
      "0.46        7\n",
      "0.16        7\n",
      "0.40        7\n",
      "1.44        7\n",
      "0.50        7\n",
      "0.90        6\n",
      "0.71        6\n",
      "1.63        6\n",
      "0.42        6\n",
      "1.01        6\n",
      "0.85        6\n",
      "0.81        6\n",
      "0.13        6\n",
      "1.21        6\n",
      "2.85        6\n",
      "4.16        6\n",
      "1.12        6\n",
      "1.25        6\n",
      "3.03        6\n",
      "1.35        6\n",
      "0.60        5\n",
      "2.22        5\n",
      "0.78        5\n",
      "0.19        5\n",
      "1.20        5\n",
      "2.12        5\n",
      "0.63        5\n",
      "8.33        5\n",
      "0.94        5\n",
      "4.76        5\n",
      "1.11        5\n",
      "1.09        5\n",
      "0.99        5\n",
      "0.59        5\n",
      "1.61        5\n",
      "1.31        5\n",
      "0.95        5\n",
      "7.69        5\n",
      "2.50        4\n",
      "1.69        4\n",
      "1.38        4\n",
      "0.75        4\n",
      "1.04        4\n",
      "0.52        4\n",
      "1.19        4\n",
      "0.89        4\n",
      "0.43        4\n",
      "0.73        4\n",
      "1.58        4\n",
      "1.14        4\n",
      "2.32        4\n",
      "1.05        4\n",
      "7.14        4\n",
      "1.75        4\n",
      "3.57        3\n",
      "6.25        3\n",
      "0.88        3\n",
      "1.72        3\n",
      "1.02        3\n",
      "1.42        3\n",
      "1.92        3\n",
      "0.91        3\n",
      "3.44        3\n",
      "2.94        3\n",
      "0.97        3\n",
      "0.82        3\n",
      "1.00        3\n",
      "3.70        3\n",
      "0.72        3\n",
      "0.79        3\n",
      "1.56        3\n",
      "1.34        3\n",
      "0.04        3\n",
      "0.36        3\n",
      "5.55        3\n",
      "1.13        3\n",
      "1.88        2\n",
      "2.04        2\n",
      "5.26        2\n",
      "2.77        2\n",
      "2.63        2\n",
      "0.01        2\n",
      "1.40        2\n",
      "0.77        2\n",
      "2.08        2\n",
      "3.84        2\n",
      "1.49        2\n",
      "1.55        2\n",
      "1.07        2\n",
      "0.96        2\n",
      "1.73        2\n",
      "1.41        2\n",
      "2.35        2\n",
      "2.00        2\n",
      "2.15        2\n",
      "2.27        2\n",
      "2.01        2\n",
      "0.92        2\n",
      "0.69        2\n",
      "1.78        2\n",
      "1.53        2\n",
      "1.60        2\n",
      "0.83        2\n",
      "5.00        2\n",
      "16.66       2\n",
      "1.85        2\n",
      "3.22        2\n",
      "6.66        2\n",
      "1.96        2\n",
      "1.52        1\n",
      "1.18        1\n",
      "1.84        1\n",
      "2.65        1\n",
      "4.44        1\n",
      "2.17        1\n",
      "1.27        1\n",
      "1.47        1\n",
      "1.51        1\n",
      "9.09        1\n",
      "2.24        1\n",
      "2.88        1\n",
      "2.29        1\n",
      "1.10        1\n",
      "21.42       1\n",
      "20.00       1\n",
      "1.22        1\n",
      "1.24        1\n",
      "3.12        1\n",
      "2.53        1\n",
      "1.66        1\n",
      "2.43        1\n",
      "2.38        1\n",
      "1.43        1\n",
      "3.92        1\n",
      "1.33        1\n",
      "1.37        1\n",
      "1.15        1\n",
      "1.65        1\n",
      "1.87        1\n",
      "2.89        1\n",
      "4.34        1\n",
      "4.00        1\n",
      "1.81        1\n",
      "2.02        1\n",
      "10.52       1\n",
      "1.62        1\n",
      "0.21        1\n",
      "2.54        1\n",
      "14.28       1\n",
      "0.98        1\n",
      "1.94        1\n",
      "2.46        1\n",
      "6.45        1\n",
      "11.11       1\n",
      "1.97        1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "word_freq_edu\n",
      "0.00     3881\n",
      "0.08       18\n",
      "0.10       13\n",
      "0.09       10\n",
      "0.27        9\n",
      "0.34        8\n",
      "0.16        8\n",
      "0.33        7\n",
      "0.80        6\n",
      "0.28        6\n",
      "1.20        5\n",
      "1.58        5\n",
      "2.32        5\n",
      "0.44        5\n",
      "0.51        5\n",
      "0.25        5\n",
      "1.02        4\n",
      "0.39        4\n",
      "7.14        4\n",
      "0.20        4\n",
      "0.89        4\n",
      "0.61        4\n",
      "0.23        4\n",
      "0.78        4\n",
      "5.00        4\n",
      "0.29        4\n",
      "0.48        4\n",
      "1.85        4\n",
      "0.36        4\n",
      "1.47        4\n",
      "0.46        4\n",
      "0.37        4\n",
      "0.97        3\n",
      "0.68        3\n",
      "1.03        3\n",
      "0.26        3\n",
      "1.61        3\n",
      "0.54        3\n",
      "1.44        3\n",
      "0.40        3\n",
      "0.91        3\n",
      "5.74        3\n",
      "1.19        3\n",
      "1.56        3\n",
      "1.01        3\n",
      "0.06        3\n",
      "0.19        3\n",
      "0.92        3\n",
      "2.00        3\n",
      "1.92        3\n",
      "0.49        3\n",
      "0.11        3\n",
      "0.62        3\n",
      "1.94        3\n",
      "1.91        3\n",
      "0.24        3\n",
      "0.14        3\n",
      "1.40        3\n",
      "5.88        3\n",
      "2.22        3\n",
      "0.38        3\n",
      "0.12        3\n",
      "0.86        3\n",
      "0.50        3\n",
      "9.09        3\n",
      "2.85        3\n",
      "1.69        3\n",
      "0.22        3\n",
      "1.16        3\n",
      "7.69        3\n",
      "1.28        2\n",
      "4.76        2\n",
      "0.43        2\n",
      "1.76        2\n",
      "1.13        2\n",
      "1.36        2\n",
      "1.82        2\n",
      "2.89        2\n",
      "1.09        2\n",
      "1.31        2\n",
      "0.59        2\n",
      "2.17        2\n",
      "3.33        2\n",
      "3.03        2\n",
      "3.57        2\n",
      "2.12        2\n",
      "1.06        2\n",
      "1.38        2\n",
      "0.64        2\n",
      "3.84        2\n",
      "2.45        2\n",
      "0.58        2\n",
      "10.00       2\n",
      "1.49        2\n",
      "0.17        2\n",
      "0.56        2\n",
      "1.75        2\n",
      "1.24        2\n",
      "0.99        2\n",
      "0.98        2\n",
      "3.07        2\n",
      "0.84        2\n",
      "0.81        2\n",
      "2.50        2\n",
      "0.57        2\n",
      "0.04        2\n",
      "0.94        2\n",
      "1.48        2\n",
      "0.52        2\n",
      "0.31        2\n",
      "0.15        2\n",
      "0.21        2\n",
      "2.56        2\n",
      "0.47        2\n",
      "0.03        1\n",
      "1.43        1\n",
      "4.47        1\n",
      "2.77        1\n",
      "2.97        1\n",
      "0.76        1\n",
      "1.50        1\n",
      "0.13        1\n",
      "2.91        1\n",
      "22.05       1\n",
      "2.01        1\n",
      "1.52        1\n",
      "3.10        1\n",
      "0.63        1\n",
      "3.44        1\n",
      "1.25        1\n",
      "1.39        1\n",
      "0.30        1\n",
      "0.32        1\n",
      "0.02        1\n",
      "1.42        1\n",
      "0.42        1\n",
      "9.52        1\n",
      "1.34        1\n",
      "4.33        1\n",
      "1.08        1\n",
      "15.35       1\n",
      "16.70       1\n",
      "7.60        1\n",
      "5.05        1\n",
      "2.58        1\n",
      "6.25        1\n",
      "13.37       1\n",
      "0.93        1\n",
      "4.83        1\n",
      "6.00        1\n",
      "3.29        1\n",
      "8.49        1\n",
      "1.17        1\n",
      "5.76        1\n",
      "0.95        1\n",
      "6.66        1\n",
      "0.72        1\n",
      "4.34        1\n",
      "3.12        1\n",
      "1.21        1\n",
      "0.70        1\n",
      "0.07        1\n",
      "0.88        1\n",
      "0.45        1\n",
      "2.73        1\n",
      "0.83        1\n",
      "4.00        1\n",
      "0.90        1\n",
      "0.77        1\n",
      "1.07        1\n",
      "2.40        1\n",
      "1.81        1\n",
      "1.23        1\n",
      "2.60        1\n",
      "3.00        1\n",
      "3.52        1\n",
      "1.33        1\n",
      "3.92        1\n",
      "1.62        1\n",
      "2.63        1\n",
      "1.98        1\n",
      "1.12        1\n",
      "0.41        1\n",
      "2.53        1\n",
      "1.30        1\n",
      "0.74        1\n",
      "0.18        1\n",
      "1.72        1\n",
      "2.11        1\n",
      "1.35        1\n",
      "0.53        1\n",
      "1.15        1\n",
      "5.55        1\n",
      "2.69        1\n",
      "1.41        1\n",
      "0.67        1\n",
      "0.71        1\n",
      "2.29        1\n",
      "2.68        1\n",
      "0.75        1\n",
      "2.24        1\n",
      "1.87        1\n",
      "1.26        1\n",
      "0.55        1\n",
      "2.65        1\n",
      "4.50        1\n",
      "3.68        1\n",
      "2.04        1\n",
      "4.08        1\n",
      "5.12        1\n",
      "3.42        1\n",
      "1.80        1\n",
      "3.04        1\n",
      "7.88        1\n",
      "0.69        1\n",
      "2.08        1\n",
      "2.43        1\n",
      "0.60        1\n",
      "1.00        1\n",
      "4.16        1\n",
      "3.70        1\n",
      "0.65        1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "word_freq_table\n",
      "0.00    4294\n",
      "0.04       6\n",
      "0.02       4\n",
      "0.05       4\n",
      "0.19       3\n",
      "0.09       3\n",
      "0.03       3\n",
      "0.06       2\n",
      "0.01       2\n",
      "0.16       2\n",
      "0.27       2\n",
      "0.61       2\n",
      "0.34       2\n",
      "0.88       1\n",
      "0.93       1\n",
      "1.51       1\n",
      "0.46       1\n",
      "2.12       1\n",
      "0.73       1\n",
      "0.12       1\n",
      "0.81       1\n",
      "0.72       1\n",
      "0.51       1\n",
      "0.14       1\n",
      "0.25       1\n",
      "2.17       1\n",
      "1.60       1\n",
      "0.39       1\n",
      "0.28       1\n",
      "0.86       1\n",
      "0.74       1\n",
      "0.18       1\n",
      "0.65       1\n",
      "1.02       1\n",
      "0.37       1\n",
      "0.11       1\n",
      "0.80       1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "word_freq_conference\n",
      "0.00     4169\n",
      "0.13        9\n",
      "0.20        7\n",
      "0.24        7\n",
      "0.10        6\n",
      "0.19        6\n",
      "0.28        5\n",
      "0.14        5\n",
      "0.15        5\n",
      "0.11        4\n",
      "0.33        4\n",
      "0.44        3\n",
      "0.35        3\n",
      "0.08        3\n",
      "0.34        3\n",
      "0.04        3\n",
      "0.02        3\n",
      "0.09        3\n",
      "0.05        3\n",
      "0.41        3\n",
      "0.39        2\n",
      "0.51        2\n",
      "0.12        2\n",
      "0.68        2\n",
      "0.53        2\n",
      "0.25        2\n",
      "0.77        2\n",
      "0.49        2\n",
      "0.54        2\n",
      "3.33        2\n",
      "0.22        2\n",
      "1.49        2\n",
      "0.71        2\n",
      "0.52        2\n",
      "0.74        2\n",
      "2.56        2\n",
      "0.07        2\n",
      "0.17        2\n",
      "0.48        2\n",
      "0.30        2\n",
      "1.16        2\n",
      "2.22        2\n",
      "0.89        2\n",
      "1.00        2\n",
      "0.18        2\n",
      "0.26        2\n",
      "1.35        1\n",
      "8.33        1\n",
      "1.58        1\n",
      "1.86        1\n",
      "1.27        1\n",
      "1.72        1\n",
      "1.07        1\n",
      "5.00        1\n",
      "0.91        1\n",
      "0.21        1\n",
      "2.43        1\n",
      "0.62        1\n",
      "0.43        1\n",
      "0.06        1\n",
      "0.03        1\n",
      "10.00       1\n",
      "2.00        1\n",
      "1.69        1\n",
      "1.10        1\n",
      "0.90        1\n",
      "0.76        1\n",
      "0.37        1\n",
      "2.81        1\n",
      "0.36        1\n",
      "1.32        1\n",
      "0.86        1\n",
      "0.73        1\n",
      "0.16        1\n",
      "0.78        1\n",
      "0.58        1\n",
      "0.98        1\n",
      "1.42        1\n",
      "0.92        1\n",
      "0.84        1\n",
      "1.66        1\n",
      "0.93        1\n",
      "0.97        1\n",
      "0.60        1\n",
      "3.70        1\n",
      "0.23        1\n",
      "0.94        1\n",
      "0.64        1\n",
      "0.72        1\n",
      "0.87        1\n",
      "1.17        1\n",
      "1.12        1\n",
      "1.38        1\n",
      "0.27        1\n",
      "2.45        1\n",
      "2.50        1\n",
      "4.76        1\n",
      "0.55        1\n",
      "0.29        1\n",
      "1.74        1\n",
      "0.88        1\n",
      "0.32        1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "char_freq_%3B\n",
      "0.000    3622\n",
      "0.010      20\n",
      "0.019      16\n",
      "0.027      15\n",
      "0.011      12\n",
      "0.015      11\n",
      "0.014      10\n",
      "0.012       9\n",
      "0.016       8\n",
      "0.017       7\n",
      "0.018       7\n",
      "0.044       7\n",
      "0.028       7\n",
      "0.052       7\n",
      "0.098       6\n",
      "0.080       6\n",
      "0.030       6\n",
      "0.056       6\n",
      "0.063       6\n",
      "0.067       6\n",
      "0.073       6\n",
      "0.034       5\n",
      "0.072       5\n",
      "0.008       5\n",
      "0.036       5\n",
      "0.094       5\n",
      "0.096       5\n",
      "0.037       5\n",
      "0.006       5\n",
      "0.026       5\n",
      "0.038       5\n",
      "0.325       5\n",
      "0.022       5\n",
      "0.185       5\n",
      "0.079       5\n",
      "0.075       5\n",
      "0.163       4\n",
      "0.182       4\n",
      "0.084       4\n",
      "0.142       4\n",
      "0.128       4\n",
      "0.031       4\n",
      "0.114       4\n",
      "0.029       4\n",
      "0.023       4\n",
      "0.048       4\n",
      "0.123       4\n",
      "0.020       4\n",
      "0.149       4\n",
      "0.058       4\n",
      "0.135       4\n",
      "0.061       4\n",
      "0.050       4\n",
      "0.024       4\n",
      "0.127       3\n",
      "0.041       3\n",
      "0.144       3\n",
      "0.222       3\n",
      "0.033       3\n",
      "0.264       3\n",
      "0.317       3\n",
      "0.765       3\n",
      "0.121       3\n",
      "0.054       3\n",
      "0.301       3\n",
      "0.145       3\n",
      "0.104       3\n",
      "0.091       3\n",
      "0.116       3\n",
      "0.126       3\n",
      "0.055       3\n",
      "0.070       3\n",
      "0.088       3\n",
      "0.223       3\n",
      "0.675       3\n",
      "0.131       3\n",
      "0.139       3\n",
      "0.111       3\n",
      "0.164       3\n",
      "0.039       3\n",
      "0.120       3\n",
      "0.109       3\n",
      "0.047       3\n",
      "0.117       3\n",
      "0.013       3\n",
      "0.112       3\n",
      "0.082       3\n",
      "0.069       3\n",
      "0.009       3\n",
      "0.071       3\n",
      "0.115       3\n",
      "0.305       3\n",
      "0.125       3\n",
      "0.064       3\n",
      "0.170       3\n",
      "0.100       3\n",
      "0.021       3\n",
      "0.040       3\n",
      "0.046       3\n",
      "0.066       3\n",
      "0.179       3\n",
      "0.097       3\n",
      "0.134       2\n",
      "0.188       2\n",
      "0.140       2\n",
      "0.151       2\n",
      "0.053       2\n",
      "0.043       2\n",
      "0.283       2\n",
      "0.007       2\n",
      "0.049       2\n",
      "0.078       2\n",
      "0.171       2\n",
      "0.101       2\n",
      "0.093       2\n",
      "0.087       2\n",
      "0.119       2\n",
      "0.005       2\n",
      "0.198       2\n",
      "0.221       2\n",
      "0.147       2\n",
      "0.042       2\n",
      "0.068       2\n",
      "0.124       2\n",
      "0.373       2\n",
      "0.226       2\n",
      "0.203       2\n",
      "0.133       2\n",
      "0.183       2\n",
      "0.051       2\n",
      "0.343       2\n",
      "0.253       2\n",
      "0.172       2\n",
      "0.089       2\n",
      "0.200       2\n",
      "0.309       2\n",
      "0.166       2\n",
      "0.238       2\n",
      "0.122       2\n",
      "0.332       2\n",
      "0.148       2\n",
      "0.207       2\n",
      "0.300       2\n",
      "0.336       2\n",
      "0.102       2\n",
      "0.110       2\n",
      "0.186       2\n",
      "0.766       2\n",
      "0.095       2\n",
      "0.210       2\n",
      "0.159       2\n",
      "0.306       2\n",
      "0.035       2\n",
      "0.199       2\n",
      "0.714       2\n",
      "0.173       2\n",
      "0.156       2\n",
      "0.180       2\n",
      "0.187       2\n",
      "0.108       2\n",
      "0.032       2\n",
      "0.218       2\n",
      "0.153       2\n",
      "0.280       2\n",
      "0.299       2\n",
      "0.431       2\n",
      "0.025       2\n",
      "0.215       2\n",
      "0.065       2\n",
      "0.045       2\n",
      "0.394       1\n",
      "0.196       1\n",
      "0.205       1\n",
      "0.358       1\n",
      "0.753       1\n",
      "0.436       1\n",
      "0.374       1\n",
      "0.209       1\n",
      "0.224       1\n",
      "0.157       1\n",
      "0.404       1\n",
      "0.353       1\n",
      "0.289       1\n",
      "0.086       1\n",
      "3.885       1\n",
      "3.024       1\n",
      "0.359       1\n",
      "0.106       1\n",
      "0.197       1\n",
      "0.103       1\n",
      "0.090       1\n",
      "3.125       1\n",
      "0.191       1\n",
      "0.165       1\n",
      "0.267       1\n",
      "0.174       1\n",
      "0.189       1\n",
      "0.168       1\n",
      "0.247       1\n",
      "0.107       1\n",
      "1.001       1\n",
      "0.327       1\n",
      "0.434       1\n",
      "0.263       1\n",
      "0.865       1\n",
      "0.136       1\n",
      "0.466       1\n",
      "0.895       1\n",
      "0.457       1\n",
      "0.074       1\n",
      "0.184       1\n",
      "0.217       1\n",
      "0.232       1\n",
      "0.636       1\n",
      "0.169       1\n",
      "0.246       1\n",
      "0.634       1\n",
      "4.121       1\n",
      "4.385       1\n",
      "3.972       1\n",
      "4.367       1\n",
      "0.543       1\n",
      "4.096       1\n",
      "3.672       1\n",
      "3.838       1\n",
      "0.083       1\n",
      "0.567       1\n",
      "0.208       1\n",
      "0.105       1\n",
      "4.187       1\n",
      "4.149       1\n",
      "0.279       1\n",
      "0.561       1\n",
      "0.323       1\n",
      "0.252       1\n",
      "0.261       1\n",
      "0.258       1\n",
      "1.024       1\n",
      "0.249       1\n",
      "0.077       1\n",
      "0.496       1\n",
      "0.195       1\n",
      "0.557       1\n",
      "0.303       1\n",
      "0.216       1\n",
      "0.085       1\n",
      "0.092       1\n",
      "1.411       1\n",
      "0.287       1\n",
      "0.190       1\n",
      "0.245       1\n",
      "0.709       1\n",
      "0.778       1\n",
      "0.503       1\n",
      "0.767       1\n",
      "0.768       1\n",
      "0.673       1\n",
      "0.472       1\n",
      "0.333       1\n",
      "0.233       1\n",
      "0.780       1\n",
      "0.462       1\n",
      "1.117       1\n",
      "0.407       1\n",
      "0.212       1\n",
      "0.470       1\n",
      "0.469       1\n",
      "0.158       1\n",
      "0.363       1\n",
      "0.416       1\n",
      "0.318       1\n",
      "0.193       1\n",
      "0.349       1\n",
      "0.161       1\n",
      "0.175       1\n",
      "0.176       1\n",
      "0.118       1\n",
      "0.213       1\n",
      "0.442       1\n",
      "0.143       1\n",
      "0.355       1\n",
      "0.271       1\n",
      "0.335       1\n",
      "0.076       1\n",
      "0.361       1\n",
      "1.353       1\n",
      "0.451       1\n",
      "0.471       1\n",
      "0.425       1\n",
      "0.081       1\n",
      "2.053       1\n",
      "1.408       1\n",
      "1.204       1\n",
      "0.388       1\n",
      "0.645       1\n",
      "1.352       1\n",
      "0.211       1\n",
      "0.004       1\n",
      "0.227       1\n",
      "0.578       1\n",
      "0.344       1\n",
      "0.376       1\n",
      "0.607       1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "char_freq_%28\n",
      "0.000    1782\n",
      "0.052      19\n",
      "0.047      18\n",
      "0.085      18\n",
      "0.037      18\n",
      "         ... \n",
      "0.419       1\n",
      "4.271       1\n",
      "0.524       1\n",
      "0.619       1\n",
      "0.718       1\n",
      "Name: count, Length: 628, dtype: int64\n",
      "\n",
      "char_freq_%5B\n",
      "0.000    3848\n",
      "0.066      13\n",
      "0.031      10\n",
      "0.053       9\n",
      "0.028       8\n",
      "0.047       8\n",
      "0.061       8\n",
      "0.194       7\n",
      "0.030       7\n",
      "0.016       6\n",
      "0.059       6\n",
      "0.264       6\n",
      "0.068       6\n",
      "0.032       6\n",
      "0.058       5\n",
      "0.091       5\n",
      "0.049       5\n",
      "0.029       5\n",
      "0.075       5\n",
      "0.065       5\n",
      "0.052       5\n",
      "0.027       5\n",
      "0.073       5\n",
      "0.168       5\n",
      "0.084       4\n",
      "0.033       4\n",
      "0.015       4\n",
      "0.209       4\n",
      "0.034       4\n",
      "0.119       4\n",
      "0.048       4\n",
      "0.046       4\n",
      "0.045       4\n",
      "0.109       4\n",
      "0.041       4\n",
      "0.062       4\n",
      "0.064       4\n",
      "0.036       4\n",
      "0.074       4\n",
      "0.159       4\n",
      "0.040       4\n",
      "0.055       3\n",
      "0.044       3\n",
      "0.013       3\n",
      "0.072       3\n",
      "0.042       3\n",
      "0.090       3\n",
      "0.035       3\n",
      "0.019       3\n",
      "0.050       3\n",
      "0.284       3\n",
      "0.108       3\n",
      "0.060       3\n",
      "0.067       3\n",
      "0.085       3\n",
      "0.094       3\n",
      "0.092       3\n",
      "0.186       3\n",
      "0.093       3\n",
      "0.137       3\n",
      "0.095       3\n",
      "0.265       3\n",
      "0.181       3\n",
      "0.043       3\n",
      "0.063       3\n",
      "0.139       3\n",
      "0.256       3\n",
      "0.202       3\n",
      "0.107       2\n",
      "0.102       2\n",
      "0.023       2\n",
      "0.149       2\n",
      "0.205       2\n",
      "0.121       2\n",
      "2.777       2\n",
      "0.105       2\n",
      "0.110       2\n",
      "0.152       2\n",
      "0.037       2\n",
      "0.116       2\n",
      "0.111       2\n",
      "0.227       2\n",
      "0.088       2\n",
      "0.057       2\n",
      "0.039       2\n",
      "0.114       2\n",
      "0.005       2\n",
      "0.051       2\n",
      "0.131       2\n",
      "0.180       2\n",
      "0.272       2\n",
      "0.124       2\n",
      "0.135       2\n",
      "0.253       2\n",
      "0.118       2\n",
      "0.018       2\n",
      "0.123       2\n",
      "0.122       2\n",
      "0.056       2\n",
      "0.003       2\n",
      "0.145       2\n",
      "0.136       2\n",
      "0.080       2\n",
      "0.054       2\n",
      "0.079       2\n",
      "0.002       2\n",
      "0.134       2\n",
      "0.100       2\n",
      "0.007       2\n",
      "0.038       2\n",
      "0.190       2\n",
      "0.166       2\n",
      "0.330       2\n",
      "0.021       2\n",
      "0.010       2\n",
      "0.260       2\n",
      "0.133       2\n",
      "0.104       2\n",
      "0.097       1\n",
      "0.098       1\n",
      "0.849       1\n",
      "0.126       1\n",
      "0.353       1\n",
      "0.335       1\n",
      "0.008       1\n",
      "0.115       1\n",
      "0.262       1\n",
      "0.125       1\n",
      "0.081       1\n",
      "0.679       1\n",
      "1.111       1\n",
      "0.570       1\n",
      "0.150       1\n",
      "0.120       1\n",
      "0.374       1\n",
      "0.343       1\n",
      "0.144       1\n",
      "0.597       1\n",
      "0.113       1\n",
      "1.634       1\n",
      "0.306       1\n",
      "0.751       1\n",
      "0.148       1\n",
      "0.294       1\n",
      "0.295       1\n",
      "1.449       1\n",
      "0.017       1\n",
      "0.395       1\n",
      "0.022       1\n",
      "0.290       1\n",
      "1.176       1\n",
      "0.216       1\n",
      "0.101       1\n",
      "0.358       1\n",
      "0.143       1\n",
      "4.081       1\n",
      "0.146       1\n",
      "0.163       1\n",
      "0.069       1\n",
      "0.128       1\n",
      "0.014       1\n",
      "0.171       1\n",
      "0.341       1\n",
      "0.020       1\n",
      "0.303       1\n",
      "0.141       1\n",
      "0.086       1\n",
      "0.439       1\n",
      "0.156       1\n",
      "0.220       1\n",
      "0.224       1\n",
      "0.269       1\n",
      "0.193       1\n",
      "0.082       1\n",
      "0.645       1\n",
      "0.324       1\n",
      "0.255       1\n",
      "0.525       1\n",
      "0.621       1\n",
      "0.331       1\n",
      "0.201       1\n",
      "0.071       1\n",
      "0.087       1\n",
      "0.447       1\n",
      "0.197       1\n",
      "0.132       1\n",
      "0.161       1\n",
      "0.076       1\n",
      "0.347       1\n",
      "0.414       1\n",
      "0.185       1\n",
      "0.203       1\n",
      "0.297       1\n",
      "0.298       1\n",
      "0.170       1\n",
      "0.012       1\n",
      "0.153       1\n",
      "0.142       1\n",
      "0.215       1\n",
      "0.167       1\n",
      "0.666       1\n",
      "0.078       1\n",
      "0.158       1\n",
      "0.140       1\n",
      "0.430       1\n",
      "0.689       1\n",
      "0.680       1\n",
      "0.188       1\n",
      "0.006       1\n",
      "0.130       1\n",
      "0.242       1\n",
      "0.129       1\n",
      "0.314       1\n",
      "0.182       1\n",
      "0.204       1\n",
      "0.222       1\n",
      "0.312       1\n",
      "0.026       1\n",
      "0.138       1\n",
      "1.098       1\n",
      "0.406       1\n",
      "Name: count, dtype: int64\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "char_freq_%21\n",
      "0.000    2226\n",
      "0.010      12\n",
      "0.149      11\n",
      "0.045      10\n",
      "0.016      10\n",
      "         ... \n",
      "0.582       1\n",
      "1.680       1\n",
      "2.143       1\n",
      "1.663       1\n",
      "1.052       1\n",
      "Name: count, Length: 939, dtype: int64\n",
      "\n",
      "char_freq_%24\n",
      "0.000    3052\n",
      "0.118      16\n",
      "0.061      13\n",
      "0.158      12\n",
      "0.014      11\n",
      "0.031      11\n",
      "0.062      10\n",
      "0.056       9\n",
      "0.157       9\n",
      "0.107       9\n",
      "0.016       9\n",
      "0.022       9\n",
      "0.105       9\n",
      "0.063       9\n",
      "0.024       8\n",
      "0.141       8\n",
      "0.021       8\n",
      "0.160       8\n",
      "0.168       8\n",
      "0.191       8\n",
      "0.165       8\n",
      "0.159       7\n",
      "0.059       7\n",
      "0.032       7\n",
      "0.013       7\n",
      "0.041       7\n",
      "0.054       7\n",
      "0.212       7\n",
      "0.114       7\n",
      "0.121       7\n",
      "0.065       7\n",
      "0.103       7\n",
      "0.370       7\n",
      "0.053       7\n",
      "0.046       7\n",
      "0.167       7\n",
      "0.230       7\n",
      "0.182       7\n",
      "0.132       7\n",
      "0.037       7\n",
      "0.048       7\n",
      "0.223       7\n",
      "0.036       7\n",
      "0.124       6\n",
      "0.043       6\n",
      "0.029       6\n",
      "0.127       6\n",
      "0.023       6\n",
      "0.161       6\n",
      "0.211       6\n",
      "0.027       6\n",
      "0.169       6\n",
      "0.017       6\n",
      "0.015       6\n",
      "0.224       6\n",
      "0.162       6\n",
      "0.109       6\n",
      "0.030       6\n",
      "0.163       6\n",
      "0.171       6\n",
      "0.254       6\n",
      "0.128       6\n",
      "0.210       6\n",
      "0.080       5\n",
      "0.180       5\n",
      "0.166       5\n",
      "0.094       5\n",
      "0.197       5\n",
      "0.175       5\n",
      "0.101       5\n",
      "0.050       5\n",
      "0.079       5\n",
      "0.040       5\n",
      "0.111       5\n",
      "0.233       5\n",
      "0.170       5\n",
      "0.055       5\n",
      "0.156       5\n",
      "0.045       5\n",
      "0.196       5\n",
      "0.147       5\n",
      "0.085       5\n",
      "0.071       5\n",
      "0.033       5\n",
      "0.186       5\n",
      "0.075       5\n",
      "0.069       5\n",
      "0.184       5\n",
      "0.150       5\n",
      "0.117       5\n",
      "0.034       4\n",
      "0.189       4\n",
      "0.199       4\n",
      "0.173       4\n",
      "0.265       4\n",
      "0.058       4\n",
      "0.044       4\n",
      "0.218       4\n",
      "0.261       4\n",
      "0.133       4\n",
      "0.174       4\n",
      "0.110       4\n",
      "0.066       4\n",
      "0.019       4\n",
      "0.397       4\n",
      "0.149       4\n",
      "0.271       4\n",
      "0.011       4\n",
      "0.051       4\n",
      "0.134       4\n",
      "0.116       4\n",
      "0.229       4\n",
      "0.232       4\n",
      "0.135       4\n",
      "0.267       4\n",
      "0.112       4\n",
      "0.345       4\n",
      "0.086       4\n",
      "0.106       4\n",
      "0.082       4\n",
      "0.093       4\n",
      "0.338       4\n",
      "0.005       4\n",
      "0.347       4\n",
      "0.221       4\n",
      "0.129       4\n",
      "0.291       4\n",
      "0.067       4\n",
      "0.057       4\n",
      "0.207       4\n",
      "0.213       3\n",
      "0.088       3\n",
      "0.008       3\n",
      "0.467       3\n",
      "0.341       3\n",
      "0.188       3\n",
      "0.222       3\n",
      "0.038       3\n",
      "0.138       3\n",
      "0.028       3\n",
      "0.177       3\n",
      "0.192       3\n",
      "0.042       3\n",
      "0.064       3\n",
      "0.047       3\n",
      "0.206       3\n",
      "0.336       3\n",
      "0.208       3\n",
      "0.176       3\n",
      "0.151       3\n",
      "0.142       3\n",
      "0.084       3\n",
      "0.496       3\n",
      "0.108       3\n",
      "0.146       3\n",
      "0.816       3\n",
      "0.145       3\n",
      "0.090       3\n",
      "0.259       3\n",
      "0.305       3\n",
      "0.039       3\n",
      "0.097       3\n",
      "0.242       3\n",
      "0.193       3\n",
      "0.154       3\n",
      "0.253       3\n",
      "0.099       3\n",
      "0.087       3\n",
      "0.049       3\n",
      "0.279       3\n",
      "0.239       3\n",
      "0.120       3\n",
      "0.052       3\n",
      "0.183       3\n",
      "0.549       3\n",
      "0.068       3\n",
      "0.136       3\n",
      "0.300       3\n",
      "0.215       3\n",
      "0.009       3\n",
      "0.541       3\n",
      "0.201       3\n",
      "0.312       3\n",
      "0.665       2\n",
      "0.125       2\n",
      "0.007       2\n",
      "0.381       2\n",
      "0.248       2\n",
      "0.077       2\n",
      "0.390       2\n",
      "0.026       2\n",
      "0.396       2\n",
      "0.217       2\n",
      "0.078       2\n",
      "0.060       2\n",
      "0.238       2\n",
      "0.012       2\n",
      "0.260       2\n",
      "0.402       2\n",
      "5.300       2\n",
      "0.255       2\n",
      "0.349       2\n",
      "0.020       2\n",
      "0.340       2\n",
      "0.716       2\n",
      "0.256       2\n",
      "0.131       2\n",
      "0.290       2\n",
      "0.231       2\n",
      "1.310       2\n",
      "0.164       2\n",
      "0.205       2\n",
      "0.979       2\n",
      "0.868       2\n",
      "0.123       2\n",
      "0.523       2\n",
      "0.478       2\n",
      "0.475       2\n",
      "0.155       2\n",
      "0.006       2\n",
      "0.350       2\n",
      "0.104       2\n",
      "0.524       2\n",
      "0.266       2\n",
      "0.025       2\n",
      "0.228       2\n",
      "0.018       2\n",
      "0.095       2\n",
      "0.073       2\n",
      "0.342       2\n",
      "0.313       2\n",
      "0.388       2\n",
      "1.281       2\n",
      "0.236       2\n",
      "0.505       2\n",
      "0.353       2\n",
      "0.333       2\n",
      "0.500       2\n",
      "0.410       2\n",
      "0.234       2\n",
      "0.626       2\n",
      "0.214       2\n",
      "0.252       2\n",
      "0.181       2\n",
      "0.198       2\n",
      "0.258       2\n",
      "0.185       2\n",
      "0.202       2\n",
      "0.420       2\n",
      "0.113       2\n",
      "0.235       2\n",
      "0.126       2\n",
      "0.216       2\n",
      "0.331       2\n",
      "0.225       2\n",
      "0.431       2\n",
      "0.383       2\n",
      "0.389       2\n",
      "0.251       2\n",
      "0.273       2\n",
      "0.412       2\n",
      "0.322       2\n",
      "0.072       2\n",
      "0.076       2\n",
      "0.269       2\n",
      "0.294       2\n",
      "0.152       2\n",
      "0.092       2\n",
      "0.070       2\n",
      "0.310       2\n",
      "0.203       2\n",
      "0.403       2\n",
      "0.263       2\n",
      "0.302       2\n",
      "0.784       2\n",
      "0.278       2\n",
      "0.083       2\n",
      "0.289       2\n",
      "0.130       2\n",
      "0.707       2\n",
      "0.306       2\n",
      "0.416       1\n",
      "1.023       1\n",
      "0.361       1\n",
      "0.787       1\n",
      "0.143       1\n",
      "6.003       1\n",
      "0.315       1\n",
      "0.437       1\n",
      "0.240       1\n",
      "0.179       1\n",
      "0.178       1\n",
      "0.316       1\n",
      "0.592       1\n",
      "0.354       1\n",
      "0.352       1\n",
      "0.481       1\n",
      "0.330       1\n",
      "0.515       1\n",
      "0.241       1\n",
      "1.050       1\n",
      "0.301       1\n",
      "0.799       1\n",
      "0.194       1\n",
      "1.417       1\n",
      "0.295       1\n",
      "0.321       1\n",
      "0.406       1\n",
      "0.486       1\n",
      "0.885       1\n",
      "0.434       1\n",
      "0.997       1\n",
      "3.260       1\n",
      "0.140       1\n",
      "0.144       1\n",
      "1.611       1\n",
      "1.219       1\n",
      "0.752       1\n",
      "0.598       1\n",
      "0.297       1\n",
      "0.698       1\n",
      "0.139       1\n",
      "0.010       1\n",
      "0.596       1\n",
      "0.332       1\n",
      "2.038       1\n",
      "0.601       1\n",
      "0.003       1\n",
      "0.756       1\n",
      "0.244       1\n",
      "0.091       1\n",
      "0.377       1\n",
      "0.004       1\n",
      "0.630       1\n",
      "0.219       1\n",
      "0.081       1\n",
      "0.427       1\n",
      "0.719       1\n",
      "0.724       1\n",
      "0.651       1\n",
      "0.246       1\n",
      "0.857       1\n",
      "0.327       1\n",
      "0.102       1\n",
      "0.285       1\n",
      "0.172       1\n",
      "0.903       1\n",
      "0.809       1\n",
      "0.277       1\n",
      "0.100       1\n",
      "0.365       1\n",
      "0.351       1\n",
      "1.308       1\n",
      "0.720       1\n",
      "0.862       1\n",
      "0.609       1\n",
      "0.794       1\n",
      "0.378       1\n",
      "0.391       1\n",
      "0.119       1\n",
      "0.527       1\n",
      "0.823       1\n",
      "1.284       1\n",
      "0.364       1\n",
      "0.531       1\n",
      "0.421       1\n",
      "0.243       1\n",
      "0.250       1\n",
      "0.465       1\n",
      "0.529       1\n",
      "1.785       1\n",
      "0.303       1\n",
      "1.309       1\n",
      "0.430       1\n",
      "0.536       1\n",
      "0.928       1\n",
      "0.429       1\n",
      "0.532       1\n",
      "0.764       1\n",
      "0.195       1\n",
      "0.790       1\n",
      "0.480       1\n",
      "0.317       1\n",
      "0.632       1\n",
      "0.763       1\n",
      "1.212       1\n",
      "2.330       1\n",
      "0.740       1\n",
      "0.519       1\n",
      "4.017       1\n",
      "0.473       1\n",
      "1.961       1\n",
      "0.424       1\n",
      "1.223       1\n",
      "1.237       1\n",
      "0.662       1\n",
      "0.466       1\n",
      "0.493       1\n",
      "0.367       1\n",
      "0.552       1\n",
      "0.148       1\n",
      "0.187       1\n",
      "0.249       1\n",
      "0.612       1\n",
      "0.204       1\n",
      "0.761       1\n",
      "0.573       1\n",
      "0.408       1\n",
      "0.610       1\n",
      "1.457       1\n",
      "0.433       1\n",
      "0.035       1\n",
      "1.305       1\n",
      "0.672       1\n",
      "0.894       1\n",
      "0.472       1\n",
      "0.358       1\n",
      "0.089       1\n",
      "0.528       1\n",
      "0.543       1\n",
      "0.439       1\n",
      "0.888       1\n",
      "0.309       1\n",
      "0.247       1\n",
      "0.585       1\n",
      "0.674       1\n",
      "0.452       1\n",
      "0.673       1\n",
      "0.288       1\n",
      "0.830       1\n",
      "0.411       1\n",
      "0.535       1\n",
      "0.828       1\n",
      "0.432       1\n",
      "0.932       1\n",
      "0.299       1\n",
      "0.483       1\n",
      "0.509       1\n",
      "0.634       1\n",
      "0.829       1\n",
      "0.209       1\n",
      "0.793       1\n",
      "0.137       1\n",
      "1.330       1\n",
      "0.597       1\n",
      "0.122       1\n",
      "0.681       1\n",
      "0.858       1\n",
      "0.780       1\n",
      "0.692       1\n",
      "0.663       1\n",
      "0.734       1\n",
      "1.357       1\n",
      "0.754       1\n",
      "0.464       1\n",
      "0.501       1\n",
      "0.369       1\n",
      "0.613       1\n",
      "0.459       1\n",
      "0.800       1\n",
      "0.318       1\n",
      "0.721       1\n",
      "0.729       1\n",
      "0.753       1\n",
      "0.548       1\n",
      "1.334       1\n",
      "0.670       1\n",
      "1.121       1\n",
      "0.264       1\n",
      "0.957       1\n",
      "0.339       1\n",
      "0.074       1\n",
      "3.305       1\n",
      "3.125       1\n",
      "0.380       1\n",
      "0.847       1\n",
      "0.510       1\n",
      "0.200       1\n",
      "0.438       1\n",
      "0.245       1\n",
      "1.313       1\n",
      "0.471       1\n",
      "1.311       1\n",
      "0.153       1\n",
      "0.896       1\n",
      "0.683       1\n",
      "0.326       1\n",
      "0.606       1\n",
      "0.360       1\n",
      "0.304       1\n",
      "0.745       1\n",
      "1.492       1\n",
      "0.514       1\n",
      "0.479       1\n",
      "0.943       1\n",
      "0.460       1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "char_freq_%23\n",
      "0.000     3637\n",
      "0.015       15\n",
      "0.013       12\n",
      "0.054       12\n",
      "0.026       11\n",
      "0.033       11\n",
      "0.031       11\n",
      "0.052       10\n",
      "0.030        9\n",
      "0.012        9\n",
      "0.081        8\n",
      "0.025        8\n",
      "0.064        7\n",
      "0.018        7\n",
      "0.009        7\n",
      "0.110        7\n",
      "0.065        7\n",
      "0.022        7\n",
      "0.102        7\n",
      "0.113        6\n",
      "0.095        6\n",
      "0.053        6\n",
      "0.072        6\n",
      "0.062        6\n",
      "0.046        6\n",
      "0.049        6\n",
      "0.084        6\n",
      "0.041        6\n",
      "0.011        5\n",
      "0.182        5\n",
      "0.008        5\n",
      "0.017        5\n",
      "0.032        5\n",
      "0.020        5\n",
      "0.050        5\n",
      "0.028        5\n",
      "0.096        5\n",
      "0.010        5\n",
      "0.124        5\n",
      "0.159        5\n",
      "0.137        5\n",
      "0.014        5\n",
      "0.128        4\n",
      "0.059        4\n",
      "0.029        4\n",
      "0.047        4\n",
      "0.055        4\n",
      "0.040        4\n",
      "0.058        4\n",
      "0.067        4\n",
      "0.066        4\n",
      "0.023        4\n",
      "0.109        4\n",
      "0.080        4\n",
      "0.092        4\n",
      "0.074        4\n",
      "0.090        4\n",
      "0.075        3\n",
      "0.082        3\n",
      "0.097        3\n",
      "0.216        3\n",
      "0.089        3\n",
      "0.439        3\n",
      "0.039        3\n",
      "0.002        3\n",
      "0.083        3\n",
      "0.144        3\n",
      "0.036        3\n",
      "0.122        3\n",
      "0.167        3\n",
      "0.038        3\n",
      "0.016        3\n",
      "0.183        3\n",
      "0.235        3\n",
      "0.132        3\n",
      "0.153        3\n",
      "0.079        3\n",
      "0.027        3\n",
      "0.268        3\n",
      "0.133        3\n",
      "0.077        3\n",
      "0.232        3\n",
      "0.078        3\n",
      "0.056        3\n",
      "0.123        3\n",
      "0.112        2\n",
      "0.294        2\n",
      "0.194        2\n",
      "0.237        2\n",
      "0.021        2\n",
      "0.051        2\n",
      "0.371        2\n",
      "0.151        2\n",
      "0.086        2\n",
      "0.070        2\n",
      "0.154        2\n",
      "0.250        2\n",
      "0.203        2\n",
      "0.211        2\n",
      "0.136        2\n",
      "0.034        2\n",
      "0.007        2\n",
      "6.896        2\n",
      "0.335        2\n",
      "0.094        2\n",
      "0.024        2\n",
      "0.126        2\n",
      "0.125        2\n",
      "0.185        2\n",
      "0.162        2\n",
      "0.255        2\n",
      "0.103        2\n",
      "0.071        2\n",
      "0.019        2\n",
      "0.165        2\n",
      "0.114        2\n",
      "0.134        2\n",
      "0.107        2\n",
      "0.147        2\n",
      "0.202        2\n",
      "0.088        2\n",
      "0.116        2\n",
      "0.503        2\n",
      "0.337        2\n",
      "0.199        2\n",
      "0.111        2\n",
      "0.099        2\n",
      "0.003        2\n",
      "0.043        2\n",
      "0.143        2\n",
      "0.044        2\n",
      "0.166        2\n",
      "0.140        2\n",
      "0.045        2\n",
      "0.105        2\n",
      "0.204        1\n",
      "1.157        1\n",
      "0.473        1\n",
      "1.998        1\n",
      "0.751        1\n",
      "0.178        1\n",
      "0.454        1\n",
      "0.645        1\n",
      "0.164        1\n",
      "1.570        1\n",
      "0.676        1\n",
      "0.279        1\n",
      "1.410        1\n",
      "0.190        1\n",
      "0.763        1\n",
      "0.639        1\n",
      "0.138        1\n",
      "0.156        1\n",
      "0.480        1\n",
      "0.555        1\n",
      "0.230        1\n",
      "0.602        1\n",
      "0.063        1\n",
      "1.043        1\n",
      "7.407        1\n",
      "0.365        1\n",
      "0.042        1\n",
      "0.290        1\n",
      "0.127        1\n",
      "0.129        1\n",
      "1.403        1\n",
      "0.507        1\n",
      "0.504        1\n",
      "0.592        1\n",
      "0.776        1\n",
      "0.120        1\n",
      "0.562        1\n",
      "0.482        1\n",
      "0.425        1\n",
      "0.280        1\n",
      "0.441        1\n",
      "0.106        1\n",
      "0.057        1\n",
      "0.409        1\n",
      "0.231        1\n",
      "0.307        1\n",
      "0.135        1\n",
      "0.396        1\n",
      "0.657        1\n",
      "0.342        1\n",
      "0.341        1\n",
      "0.087        1\n",
      "0.130        1\n",
      "0.161        1\n",
      "0.076        1\n",
      "0.286        1\n",
      "0.104        1\n",
      "0.395        1\n",
      "0.215        1\n",
      "0.416        1\n",
      "0.168        1\n",
      "0.005        1\n",
      "0.004        1\n",
      "0.925        1\n",
      "0.037        1\n",
      "0.006        1\n",
      "0.384        1\n",
      "1.503        1\n",
      "0.108        1\n",
      "0.198        1\n",
      "0.266        1\n",
      "0.048        1\n",
      "0.253        1\n",
      "0.348        1\n",
      "0.326        1\n",
      "1.118        1\n",
      "0.035        1\n",
      "0.836        1\n",
      "1.047        1\n",
      "0.150        1\n",
      "3.423        1\n",
      "0.115        1\n",
      "0.394        1\n",
      "1.625        1\n",
      "0.539        1\n",
      "1.985        1\n",
      "0.293        1\n",
      "13.129       1\n",
      "0.119        1\n",
      "0.201        1\n",
      "1.724        1\n",
      "1.882        1\n",
      "0.149        1\n",
      "0.459        1\n",
      "0.145        1\n",
      "0.889        1\n",
      "0.450        1\n",
      "0.686        1\n",
      "0.466        1\n",
      "0.061        1\n",
      "0.069        1\n",
      "0.171        1\n",
      "0.248        1\n",
      "0.291        1\n",
      "0.229        1\n",
      "0.484        1\n",
      "0.435        1\n",
      "0.460        1\n",
      "0.141        1\n",
      "1.026        1\n",
      "1.002        1\n",
      "1.084        1\n",
      "0.340        1\n",
      "1.017        1\n",
      "0.260        1\n",
      "0.210        1\n",
      "0.478        1\n",
      "0.285        1\n",
      "3.879        1\n",
      "0.432        1\n",
      "0.437        1\n",
      "1.068        1\n",
      "0.350        1\n",
      "0.381        1\n",
      "0.228        1\n",
      "0.187        1\n",
      "0.217        1\n",
      "0.928        1\n",
      "0.329        1\n",
      "0.330        1\n",
      "0.517        1\n",
      "2.290        1\n",
      "0.177        1\n",
      "1.051        1\n",
      "0.349        1\n",
      "0.304        1\n",
      "1.560        1\n",
      "0.270        1\n",
      "0.142        1\n",
      "0.518        1\n",
      "0.998        1\n",
      "0.226        1\n",
      "0.446        1\n",
      "0.412        1\n",
      "0.465        1\n",
      "0.630        1\n",
      "4.008        1\n",
      "19.829       1\n",
      "1.342        1\n",
      "0.191        1\n",
      "0.236        1\n",
      "0.969        1\n",
      "0.073        1\n",
      "1.151        1\n",
      "1.468        1\n",
      "0.148        1\n",
      "0.651        1\n",
      "1.233        1\n",
      "0.169        1\n",
      "0.479        1\n",
      "1.584        1\n",
      "0.233        1\n",
      "1.083        1\n",
      "0.170        1\n",
      "0.157        1\n",
      "2.517        1\n",
      "0.152        1\n",
      "0.306        1\n",
      "0.091        1\n",
      "0.100        1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "capital_run_length_average\n",
      "1.000     335\n",
      "2.000      76\n",
      "1.800      52\n",
      "1.500      35\n",
      "1.666      34\n",
      "         ... \n",
      "20.432      1\n",
      "6.718       1\n",
      "5.666       1\n",
      "5.955       1\n",
      "1.147       1\n",
      "Name: count, Length: 2085, dtype: int64\n",
      "\n",
      "capital_run_length_longest\n",
      "1.0       330\n",
      "5.0       236\n",
      "11.0      216\n",
      "12.0      206\n",
      "4.0       206\n",
      "3.0       161\n",
      "7.0       128\n",
      "13.0      128\n",
      "15.0      123\n",
      "10.0      122\n",
      "6.0       112\n",
      "8.0       106\n",
      "2.0        91\n",
      "9.0        75\n",
      "17.0       74\n",
      "19.0       69\n",
      "22.0       66\n",
      "28.0       61\n",
      "16.0       61\n",
      "18.0       56\n",
      "14.0       55\n",
      "21.0       55\n",
      "25.0       51\n",
      "47.0       48\n",
      "24.0       42\n",
      "20.0       41\n",
      "29.0       37\n",
      "54.0       35\n",
      "23.0       34\n",
      "26.0       32\n",
      "32.0       32\n",
      "51.0       30\n",
      "34.0       30\n",
      "55.0       29\n",
      "43.0       29\n",
      "38.0       27\n",
      "669.0      27\n",
      "60.0       25\n",
      "30.0       25\n",
      "45.0       22\n",
      "31.0       22\n",
      "46.0       21\n",
      "33.0       21\n",
      "66.0       20\n",
      "70.0       20\n",
      "41.0       20\n",
      "48.0       19\n",
      "42.0       19\n",
      "63.0       19\n",
      "61.0       19\n",
      "27.0       19\n",
      "69.0       17\n",
      "49.0       17\n",
      "37.0       16\n",
      "140.0      16\n",
      "75.0       16\n",
      "36.0       15\n",
      "35.0       15\n",
      "52.0       15\n",
      "121.0      14\n",
      "78.0       13\n",
      "40.0       13\n",
      "107.0      13\n",
      "39.0       13\n",
      "58.0       12\n",
      "64.0       12\n",
      "44.0       12\n",
      "76.0       12\n",
      "56.0       12\n",
      "71.0       12\n",
      "84.0       11\n",
      "97.0       11\n",
      "68.0       11\n",
      "73.0       10\n",
      "148.0      10\n",
      "494.0      10\n",
      "193.0       9\n",
      "53.0        9\n",
      "57.0        9\n",
      "132.0       9\n",
      "116.0       9\n",
      "59.0        8\n",
      "114.0       8\n",
      "525.0       8\n",
      "74.0        8\n",
      "65.0        8\n",
      "82.0        8\n",
      "117.0       8\n",
      "87.0        8\n",
      "181.0       7\n",
      "62.0        7\n",
      "200.0       7\n",
      "104.0       7\n",
      "67.0        6\n",
      "95.0        6\n",
      "79.0        6\n",
      "131.0       6\n",
      "81.0        6\n",
      "147.0       6\n",
      "144.0       6\n",
      "149.0       6\n",
      "80.0        6\n",
      "119.0       6\n",
      "139.0       5\n",
      "85.0        5\n",
      "127.0       5\n",
      "72.0        5\n",
      "50.0        5\n",
      "126.0       4\n",
      "91.0        4\n",
      "636.0       4\n",
      "235.0       4\n",
      "123.0       4\n",
      "94.0        4\n",
      "102.0       4\n",
      "96.0        4\n",
      "157.0       4\n",
      "583.0       4\n",
      "101.0       3\n",
      "1177.0      3\n",
      "83.0        3\n",
      "283.0       3\n",
      "110.0       3\n",
      "128.0       3\n",
      "92.0        3\n",
      "103.0       3\n",
      "77.0        3\n",
      "489.0       3\n",
      "113.0       3\n",
      "154.0       3\n",
      "138.0       3\n",
      "199.0       3\n",
      "99.0        3\n",
      "137.0       3\n",
      "393.0       3\n",
      "295.0       3\n",
      "696.0       2\n",
      "136.0       2\n",
      "89.0        2\n",
      "634.0       2\n",
      "143.0       2\n",
      "124.0       2\n",
      "1325.0      2\n",
      "152.0       2\n",
      "272.0       2\n",
      "182.0       2\n",
      "217.0       2\n",
      "142.0       2\n",
      "326.0       2\n",
      "292.0       2\n",
      "100.0       2\n",
      "195.0       2\n",
      "685.0       2\n",
      "1146.0      2\n",
      "281.0       2\n",
      "332.0       2\n",
      "185.0       2\n",
      "134.0       2\n",
      "192.0       2\n",
      "708.0       2\n",
      "226.0       2\n",
      "86.0        2\n",
      "122.0       2\n",
      "108.0       2\n",
      "581.0       2\n",
      "129.0       2\n",
      "595.0       2\n",
      "130.0       2\n",
      "739.0       2\n",
      "90.0        2\n",
      "158.0       2\n",
      "159.0       2\n",
      "1171.0      2\n",
      "164.0       2\n",
      "153.0       2\n",
      "232.0       2\n",
      "1038.0      2\n",
      "445.0       2\n",
      "259.0       2\n",
      "394.0       2\n",
      "363.0       2\n",
      "763.0       2\n",
      "183.0       2\n",
      "350.0       2\n",
      "289.0       1\n",
      "887.0       1\n",
      "335.0       1\n",
      "247.0       1\n",
      "111.0       1\n",
      "276.0       1\n",
      "304.0       1\n",
      "735.0       1\n",
      "430.0       1\n",
      "1013.0      1\n",
      "278.0       1\n",
      "163.0       1\n",
      "300.0       1\n",
      "543.0       1\n",
      "213.0       1\n",
      "186.0       1\n",
      "9989.0      1\n",
      "93.0        1\n",
      "178.0       1\n",
      "115.0       1\n",
      "485.0       1\n",
      "98.0        1\n",
      "351.0       1\n",
      "343.0       1\n",
      "214.0       1\n",
      "118.0       1\n",
      "287.0       1\n",
      "161.0       1\n",
      "245.0       1\n",
      "1488.0      1\n",
      "280.0       1\n",
      "160.0       1\n",
      "251.0       1\n",
      "252.0       1\n",
      "196.0       1\n",
      "305.0       1\n",
      "683.0       1\n",
      "392.0       1\n",
      "264.0       1\n",
      "175.0       1\n",
      "223.0       1\n",
      "260.0       1\n",
      "1333.0      1\n",
      "1505.0      1\n",
      "772.0       1\n",
      "689.0       1\n",
      "404.0       1\n",
      "412.0       1\n",
      "135.0       1\n",
      "299.0       1\n",
      "279.0       1\n",
      "209.0       1\n",
      "266.0       1\n",
      "274.0       1\n",
      "447.0       1\n",
      "190.0       1\n",
      "151.0       1\n",
      "515.0       1\n",
      "268.0       1\n",
      "286.0       1\n",
      "296.0       1\n",
      "146.0       1\n",
      "691.0       1\n",
      "180.0       1\n",
      "168.0       1\n",
      "105.0       1\n",
      "418.0       1\n",
      "2042.0      1\n",
      "845.0       1\n",
      "311.0       1\n",
      "2204.0      1\n",
      "842.0       1\n",
      "339.0       1\n",
      "798.0       1\n",
      "694.0       1\n",
      "169.0       1\n",
      "706.0       1\n",
      "611.0       1\n",
      "155.0       1\n",
      "133.0       1\n",
      "1170.0      1\n",
      "338.0       1\n",
      "208.0       1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "capital_run_length_total\n",
      "5.0       109\n",
      "9.0        65\n",
      "7.0        49\n",
      "6.0        48\n",
      "4.0        44\n",
      "         ... \n",
      "725.0       1\n",
      "998.0       1\n",
      "3213.0      1\n",
      "526.0       1\n",
      "1789.0      1\n",
      "Name: count, Length: 894, dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for column in data.columns:\n",
    "    print(data[column].value_counts())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a9ef62",
   "metadata": {},
   "source": [
    "Kolumny opisujące **word_freq_*** oraz **capital_run_*** uzupełnimy medianą, a resztę - średnią. Do wyboru kolumn w transformatorze wykorzystam **DataFrameSelector** z notebooka **Z09_E_titanic**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "321f5dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# A class to select numerical or categorical columns \n",
    "# since Scikit-Learn doesn't handle DataFrames yet\n",
    "class DataFrameSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, attribute_names):\n",
    "        self.attribute_names = attribute_names\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X[self.attribute_names]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cac9f73",
   "metadata": {},
   "source": [
    "Zanim przejdziemy do tworzenia pipeline'a, usuńmy dwie kolumny - **word_freq_george** oraz **word_freq_650**. Zgodnie z opisem na kaggle, *George* jest imieniem jednego z pracowników, a *650* numerem kierunkowym - więc jeśli chcemy stworzyć w miarę ogólny filter spamu, to powinniśmy się pozbyć tych kolumn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1442188e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(columns=['word_freq_george', 'word_freq_650'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5adfd58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "median_columns = []\n",
    "avg_columns = []\n",
    "for column in data.columns:\n",
    "    if 'word_freq_' in column or 'capital_run_' in column:\n",
    "        median_columns.append(column)\n",
    "    else:\n",
    "        avg_columns.append(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "da754561",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['word_freq_make',\n",
       " 'word_freq_address',\n",
       " 'word_freq_all',\n",
       " 'word_freq_3d',\n",
       " 'word_freq_our',\n",
       " 'word_freq_over',\n",
       " 'word_freq_remove',\n",
       " 'word_freq_internet',\n",
       " 'word_freq_order',\n",
       " 'word_freq_mail',\n",
       " 'word_freq_receive',\n",
       " 'word_freq_will',\n",
       " 'word_freq_people',\n",
       " 'word_freq_report',\n",
       " 'word_freq_addresses',\n",
       " 'word_freq_free',\n",
       " 'word_freq_business',\n",
       " 'word_freq_email',\n",
       " 'word_freq_you',\n",
       " 'word_freq_credit',\n",
       " 'word_freq_your',\n",
       " 'word_freq_font',\n",
       " 'word_freq_000',\n",
       " 'word_freq_money',\n",
       " 'word_freq_hp',\n",
       " 'word_freq_hpl',\n",
       " 'word_freq_lab',\n",
       " 'word_freq_labs',\n",
       " 'word_freq_telnet',\n",
       " 'word_freq_857',\n",
       " 'word_freq_data',\n",
       " 'word_freq_415',\n",
       " 'word_freq_85',\n",
       " 'word_freq_technology',\n",
       " 'word_freq_1999',\n",
       " 'word_freq_parts',\n",
       " 'word_freq_pm',\n",
       " 'word_freq_direct',\n",
       " 'word_freq_cs',\n",
       " 'word_freq_meeting',\n",
       " 'word_freq_original',\n",
       " 'word_freq_project',\n",
       " 'word_freq_re',\n",
       " 'word_freq_edu',\n",
       " 'word_freq_table',\n",
       " 'word_freq_conference',\n",
       " 'capital_run_length_average',\n",
       " 'capital_run_length_longest',\n",
       " 'capital_run_length_total']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "median_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "345f53ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['char_freq_%3B',\n",
       " 'char_freq_%28',\n",
       " 'char_freq_%5B',\n",
       " 'char_freq_%21',\n",
       " 'char_freq_%24',\n",
       " 'char_freq_%23']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "22129c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import FeatureUnion\n",
    "\n",
    "median_pipeline = Pipeline([\n",
    "    ('selector', DataFrameSelector(median_columns)),\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "])\n",
    "\n",
    "avg_pipeline = Pipeline([\n",
    "    ('selector', DataFrameSelector(avg_columns)),\n",
    "    ('imputer', SimpleImputer(strategy='mean'))\n",
    "])\n",
    "\n",
    "fill_pipeline = FeatureUnion(\n",
    "    transformer_list = [\n",
    "        ('median', median_pipeline),\n",
    "        ('average', avg_pipeline),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2600274f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_filled = fill_pipeline.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "421ccfcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00000000e+00, 6.40000000e-01, 6.40000000e-01, 0.00000000e+00,\n",
       "       3.20000000e-01, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 6.40000000e-01,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 3.20000000e-01,\n",
       "       0.00000000e+00, 1.29000000e+00, 1.93000000e+00, 0.00000000e+00,\n",
       "       9.60000000e-01, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 3.75600000e+00, 6.10000000e+01,\n",
       "       2.78000000e+02, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       7.78000000e-01, 0.00000000e+00, 4.45260369e-02])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_filled[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73bc08c",
   "metadata": {},
   "source": [
    "Spójrzmy jeszcze na **PCA**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9117f94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model = PCA()\n",
    "\n",
    "data_filled = StandardScaler().fit_transform(data_filled)\n",
    "pca_features = model.fit_transform(data_filled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3ec3ecc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "features = range(model.n_components_)\n",
    "plt.figure(figsize=(20,6))\n",
    "plt.bar(features, model.explained_variance_ratio_)\n",
    "plt.xlabel('PCA feature')\n",
    "plt.ylabel('variance')\n",
    "plt.xticks(features)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5066bd85",
   "metadata": {},
   "source": [
    "Zredukujmy dane do 11 wymiarów."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "addf20ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pipeline = Pipeline([\n",
    "    ('fill', fill_pipeline),\n",
    "    ('scale', StandardScaler()),\n",
    "    #('pca', PCA(11)),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "661f5de6",
   "metadata": {},
   "source": [
    "Podzielmy na **train** i **test**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "490ce7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, stratify=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f212652",
   "metadata": {},
   "source": [
    "## Pierwszy model - SVM rbf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "701a25fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n",
      "[CV 1/5; 1/72] START classifier__C=0.001, classifier__gamma=0.001, pca=PCA(n_components=11)\n",
      "[CV 1/5; 1/72] END classifier__C=0.001, classifier__gamma=0.001, pca=PCA(n_components=11);, score=(train=0.606, test=0.606) total time=   0.4s\n",
      "[CV 2/5; 1/72] START classifier__C=0.001, classifier__gamma=0.001, pca=PCA(n_components=11)\n",
      "[CV 2/5; 1/72] END classifier__C=0.001, classifier__gamma=0.001, pca=PCA(n_components=11);, score=(train=0.606, test=0.606) total time=   0.4s\n",
      "[CV 3/5; 1/72] START classifier__C=0.001, classifier__gamma=0.001, pca=PCA(n_components=11)\n",
      "[CV 3/5; 1/72] END classifier__C=0.001, classifier__gamma=0.001, pca=PCA(n_components=11);, score=(train=0.606, test=0.606) total time=   0.4s\n",
      "[CV 4/5; 1/72] START classifier__C=0.001, classifier__gamma=0.001, pca=PCA(n_components=11)\n",
      "[CV 4/5; 1/72] END classifier__C=0.001, classifier__gamma=0.001, pca=PCA(n_components=11);, score=(train=0.606, test=0.606) total time=   0.4s\n",
      "[CV 5/5; 1/72] START classifier__C=0.001, classifier__gamma=0.001, pca=PCA(n_components=11)\n",
      "[CV 5/5; 1/72] END classifier__C=0.001, classifier__gamma=0.001, pca=PCA(n_components=11);, score=(train=0.606, test=0.606) total time=   0.4s\n",
      "[CV 1/5; 2/72] START classifier__C=0.001, classifier__gamma=0.001, pca=None.....\n",
      "[CV 1/5; 2/72] END classifier__C=0.001, classifier__gamma=0.001, pca=None;, score=(train=0.606, test=0.606) total time=   0.5s\n",
      "[CV 2/5; 2/72] START classifier__C=0.001, classifier__gamma=0.001, pca=None.....\n",
      "[CV 2/5; 2/72] END classifier__C=0.001, classifier__gamma=0.001, pca=None;, score=(train=0.606, test=0.606) total time=   0.5s\n",
      "[CV 3/5; 2/72] START classifier__C=0.001, classifier__gamma=0.001, pca=None.....\n",
      "[CV 3/5; 2/72] END classifier__C=0.001, classifier__gamma=0.001, pca=None;, score=(train=0.606, test=0.606) total time=   0.5s\n",
      "[CV 4/5; 2/72] START classifier__C=0.001, classifier__gamma=0.001, pca=None.....\n",
      "[CV 4/5; 2/72] END classifier__C=0.001, classifier__gamma=0.001, pca=None;, score=(train=0.606, test=0.606) total time=   0.5s\n",
      "[CV 5/5; 2/72] START classifier__C=0.001, classifier__gamma=0.001, pca=None.....\n",
      "[CV 5/5; 2/72] END classifier__C=0.001, classifier__gamma=0.001, pca=None;, score=(train=0.606, test=0.606) total time=   0.5s\n",
      "[CV 1/5; 3/72] START classifier__C=0.001, classifier__gamma=0.01, pca=PCA(n_components=11)\n",
      "[CV 1/5; 3/72] END classifier__C=0.001, classifier__gamma=0.01, pca=PCA(n_components=11);, score=(train=0.606, test=0.606) total time=   0.4s\n",
      "[CV 2/5; 3/72] START classifier__C=0.001, classifier__gamma=0.01, pca=PCA(n_components=11)\n",
      "[CV 2/5; 3/72] END classifier__C=0.001, classifier__gamma=0.01, pca=PCA(n_components=11);, score=(train=0.606, test=0.606) total time=   0.4s\n",
      "[CV 3/5; 3/72] START classifier__C=0.001, classifier__gamma=0.01, pca=PCA(n_components=11)\n",
      "[CV 3/5; 3/72] END classifier__C=0.001, classifier__gamma=0.01, pca=PCA(n_components=11);, score=(train=0.606, test=0.606) total time=   0.4s\n",
      "[CV 4/5; 3/72] START classifier__C=0.001, classifier__gamma=0.01, pca=PCA(n_components=11)\n",
      "[CV 4/5; 3/72] END classifier__C=0.001, classifier__gamma=0.01, pca=PCA(n_components=11);, score=(train=0.606, test=0.606) total time=   0.4s\n",
      "[CV 5/5; 3/72] START classifier__C=0.001, classifier__gamma=0.01, pca=PCA(n_components=11)\n",
      "[CV 5/5; 3/72] END classifier__C=0.001, classifier__gamma=0.01, pca=PCA(n_components=11);, score=(train=0.606, test=0.606) total time=   0.4s\n",
      "[CV 1/5; 4/72] START classifier__C=0.001, classifier__gamma=0.01, pca=None......\n",
      "[CV 1/5; 4/72] END classifier__C=0.001, classifier__gamma=0.01, pca=None;, score=(train=0.606, test=0.606) total time=   0.5s\n",
      "[CV 2/5; 4/72] START classifier__C=0.001, classifier__gamma=0.01, pca=None......\n",
      "[CV 2/5; 4/72] END classifier__C=0.001, classifier__gamma=0.01, pca=None;, score=(train=0.606, test=0.606) total time=   0.5s\n",
      "[CV 3/5; 4/72] START classifier__C=0.001, classifier__gamma=0.01, pca=None......\n",
      "[CV 3/5; 4/72] END classifier__C=0.001, classifier__gamma=0.01, pca=None;, score=(train=0.606, test=0.606) total time=   0.5s\n",
      "[CV 4/5; 4/72] START classifier__C=0.001, classifier__gamma=0.01, pca=None......\n",
      "[CV 4/5; 4/72] END classifier__C=0.001, classifier__gamma=0.01, pca=None;, score=(train=0.606, test=0.606) total time=   0.5s\n",
      "[CV 5/5; 4/72] START classifier__C=0.001, classifier__gamma=0.01, pca=None......\n",
      "[CV 5/5; 4/72] END classifier__C=0.001, classifier__gamma=0.01, pca=None;, score=(train=0.606, test=0.606) total time=   0.5s\n",
      "[CV 1/5; 5/72] START classifier__C=0.001, classifier__gamma=0.1, pca=PCA(n_components=11)\n",
      "[CV 1/5; 5/72] END classifier__C=0.001, classifier__gamma=0.1, pca=PCA(n_components=11);, score=(train=0.606, test=0.606) total time=   0.4s\n",
      "[CV 2/5; 5/72] START classifier__C=0.001, classifier__gamma=0.1, pca=PCA(n_components=11)\n",
      "[CV 2/5; 5/72] END classifier__C=0.001, classifier__gamma=0.1, pca=PCA(n_components=11);, score=(train=0.606, test=0.606) total time=   0.4s\n",
      "[CV 3/5; 5/72] START classifier__C=0.001, classifier__gamma=0.1, pca=PCA(n_components=11)\n",
      "[CV 3/5; 5/72] END classifier__C=0.001, classifier__gamma=0.1, pca=PCA(n_components=11);, score=(train=0.606, test=0.606) total time=   0.4s\n",
      "[CV 4/5; 5/72] START classifier__C=0.001, classifier__gamma=0.1, pca=PCA(n_components=11)\n",
      "[CV 4/5; 5/72] END classifier__C=0.001, classifier__gamma=0.1, pca=PCA(n_components=11);, score=(train=0.606, test=0.606) total time=   0.4s\n",
      "[CV 5/5; 5/72] START classifier__C=0.001, classifier__gamma=0.1, pca=PCA(n_components=11)\n",
      "[CV 5/5; 5/72] END classifier__C=0.001, classifier__gamma=0.1, pca=PCA(n_components=11);, score=(train=0.606, test=0.606) total time=   0.4s\n",
      "[CV 1/5; 6/72] START classifier__C=0.001, classifier__gamma=0.1, pca=None.......\n",
      "[CV 1/5; 6/72] END classifier__C=0.001, classifier__gamma=0.1, pca=None;, score=(train=0.606, test=0.606) total time=   0.5s\n",
      "[CV 2/5; 6/72] START classifier__C=0.001, classifier__gamma=0.1, pca=None.......\n",
      "[CV 2/5; 6/72] END classifier__C=0.001, classifier__gamma=0.1, pca=None;, score=(train=0.606, test=0.606) total time=   0.5s\n",
      "[CV 3/5; 6/72] START classifier__C=0.001, classifier__gamma=0.1, pca=None.......\n",
      "[CV 3/5; 6/72] END classifier__C=0.001, classifier__gamma=0.1, pca=None;, score=(train=0.606, test=0.606) total time=   0.5s\n",
      "[CV 4/5; 6/72] START classifier__C=0.001, classifier__gamma=0.1, pca=None.......\n",
      "[CV 4/5; 6/72] END classifier__C=0.001, classifier__gamma=0.1, pca=None;, score=(train=0.606, test=0.606) total time=   0.5s\n",
      "[CV 5/5; 6/72] START classifier__C=0.001, classifier__gamma=0.1, pca=None.......\n",
      "[CV 5/5; 6/72] END classifier__C=0.001, classifier__gamma=0.1, pca=None;, score=(train=0.606, test=0.606) total time=   0.5s\n",
      "[CV 1/5; 7/72] START classifier__C=0.001, classifier__gamma=1.0, pca=PCA(n_components=11)\n",
      "[CV 1/5; 7/72] END classifier__C=0.001, classifier__gamma=1.0, pca=PCA(n_components=11);, score=(train=0.606, test=0.606) total time=   0.4s\n",
      "[CV 2/5; 7/72] START classifier__C=0.001, classifier__gamma=1.0, pca=PCA(n_components=11)\n",
      "[CV 2/5; 7/72] END classifier__C=0.001, classifier__gamma=1.0, pca=PCA(n_components=11);, score=(train=0.606, test=0.606) total time=   0.4s\n",
      "[CV 3/5; 7/72] START classifier__C=0.001, classifier__gamma=1.0, pca=PCA(n_components=11)\n",
      "[CV 3/5; 7/72] END classifier__C=0.001, classifier__gamma=1.0, pca=PCA(n_components=11);, score=(train=0.606, test=0.606) total time=   0.4s\n",
      "[CV 4/5; 7/72] START classifier__C=0.001, classifier__gamma=1.0, pca=PCA(n_components=11)\n",
      "[CV 4/5; 7/72] END classifier__C=0.001, classifier__gamma=1.0, pca=PCA(n_components=11);, score=(train=0.606, test=0.606) total time=   0.4s\n",
      "[CV 5/5; 7/72] START classifier__C=0.001, classifier__gamma=1.0, pca=PCA(n_components=11)\n",
      "[CV 5/5; 7/72] END classifier__C=0.001, classifier__gamma=1.0, pca=PCA(n_components=11);, score=(train=0.606, test=0.606) total time=   0.4s\n",
      "[CV 1/5; 8/72] START classifier__C=0.001, classifier__gamma=1.0, pca=None.......\n",
      "[CV 1/5; 8/72] END classifier__C=0.001, classifier__gamma=1.0, pca=None;, score=(train=0.606, test=0.606) total time=   0.5s\n",
      "[CV 2/5; 8/72] START classifier__C=0.001, classifier__gamma=1.0, pca=None.......\n",
      "[CV 2/5; 8/72] END classifier__C=0.001, classifier__gamma=1.0, pca=None;, score=(train=0.606, test=0.606) total time=   0.5s\n",
      "[CV 3/5; 8/72] START classifier__C=0.001, classifier__gamma=1.0, pca=None.......\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 8/72] END classifier__C=0.001, classifier__gamma=1.0, pca=None;, score=(train=0.606, test=0.606) total time=   0.5s\n",
      "[CV 4/5; 8/72] START classifier__C=0.001, classifier__gamma=1.0, pca=None.......\n",
      "[CV 4/5; 8/72] END classifier__C=0.001, classifier__gamma=1.0, pca=None;, score=(train=0.606, test=0.606) total time=   0.5s\n",
      "[CV 5/5; 8/72] START classifier__C=0.001, classifier__gamma=1.0, pca=None.......\n",
      "[CV 5/5; 8/72] END classifier__C=0.001, classifier__gamma=1.0, pca=None;, score=(train=0.606, test=0.606) total time=   0.5s\n",
      "[CV 1/5; 9/72] START classifier__C=0.001, classifier__gamma=10.0, pca=PCA(n_components=11)\n",
      "[CV 1/5; 9/72] END classifier__C=0.001, classifier__gamma=10.0, pca=PCA(n_components=11);, score=(train=0.606, test=0.606) total time=   0.4s\n",
      "[CV 2/5; 9/72] START classifier__C=0.001, classifier__gamma=10.0, pca=PCA(n_components=11)\n",
      "[CV 2/5; 9/72] END classifier__C=0.001, classifier__gamma=10.0, pca=PCA(n_components=11);, score=(train=0.606, test=0.606) total time=   0.4s\n",
      "[CV 3/5; 9/72] START classifier__C=0.001, classifier__gamma=10.0, pca=PCA(n_components=11)\n",
      "[CV 3/5; 9/72] END classifier__C=0.001, classifier__gamma=10.0, pca=PCA(n_components=11);, score=(train=0.606, test=0.606) total time=   0.4s\n",
      "[CV 4/5; 9/72] START classifier__C=0.001, classifier__gamma=10.0, pca=PCA(n_components=11)\n",
      "[CV 4/5; 9/72] END classifier__C=0.001, classifier__gamma=10.0, pca=PCA(n_components=11);, score=(train=0.606, test=0.606) total time=   0.4s\n",
      "[CV 5/5; 9/72] START classifier__C=0.001, classifier__gamma=10.0, pca=PCA(n_components=11)\n",
      "[CV 5/5; 9/72] END classifier__C=0.001, classifier__gamma=10.0, pca=PCA(n_components=11);, score=(train=0.606, test=0.606) total time=   0.4s\n",
      "[CV 1/5; 10/72] START classifier__C=0.001, classifier__gamma=10.0, pca=None.....\n",
      "[CV 1/5; 10/72] END classifier__C=0.001, classifier__gamma=10.0, pca=None;, score=(train=0.606, test=0.606) total time=   0.7s\n",
      "[CV 2/5; 10/72] START classifier__C=0.001, classifier__gamma=10.0, pca=None.....\n",
      "[CV 2/5; 10/72] END classifier__C=0.001, classifier__gamma=10.0, pca=None;, score=(train=0.606, test=0.606) total time=   0.7s\n",
      "[CV 3/5; 10/72] START classifier__C=0.001, classifier__gamma=10.0, pca=None.....\n",
      "[CV 3/5; 10/72] END classifier__C=0.001, classifier__gamma=10.0, pca=None;, score=(train=0.606, test=0.606) total time=   0.7s\n",
      "[CV 4/5; 10/72] START classifier__C=0.001, classifier__gamma=10.0, pca=None.....\n",
      "[CV 4/5; 10/72] END classifier__C=0.001, classifier__gamma=10.0, pca=None;, score=(train=0.606, test=0.606) total time=   0.7s\n",
      "[CV 5/5; 10/72] START classifier__C=0.001, classifier__gamma=10.0, pca=None.....\n",
      "[CV 5/5; 10/72] END classifier__C=0.001, classifier__gamma=10.0, pca=None;, score=(train=0.606, test=0.606) total time=   0.7s\n",
      "[CV 1/5; 11/72] START classifier__C=0.001, classifier__gamma=100.0, pca=PCA(n_components=11)\n",
      "[CV 1/5; 11/72] END classifier__C=0.001, classifier__gamma=100.0, pca=PCA(n_components=11);, score=(train=0.606, test=0.606) total time=   0.7s\n",
      "[CV 2/5; 11/72] START classifier__C=0.001, classifier__gamma=100.0, pca=PCA(n_components=11)\n",
      "[CV 2/5; 11/72] END classifier__C=0.001, classifier__gamma=100.0, pca=PCA(n_components=11);, score=(train=0.606, test=0.606) total time=   0.6s\n",
      "[CV 3/5; 11/72] START classifier__C=0.001, classifier__gamma=100.0, pca=PCA(n_components=11)\n",
      "[CV 3/5; 11/72] END classifier__C=0.001, classifier__gamma=100.0, pca=PCA(n_components=11);, score=(train=0.606, test=0.606) total time=   0.6s\n",
      "[CV 4/5; 11/72] START classifier__C=0.001, classifier__gamma=100.0, pca=PCA(n_components=11)\n",
      "[CV 4/5; 11/72] END classifier__C=0.001, classifier__gamma=100.0, pca=PCA(n_components=11);, score=(train=0.606, test=0.606) total time=   0.6s\n",
      "[CV 5/5; 11/72] START classifier__C=0.001, classifier__gamma=100.0, pca=PCA(n_components=11)\n",
      "[CV 5/5; 11/72] END classifier__C=0.001, classifier__gamma=100.0, pca=PCA(n_components=11);, score=(train=0.606, test=0.606) total time=   0.7s\n",
      "[CV 1/5; 12/72] START classifier__C=0.001, classifier__gamma=100.0, pca=None....\n",
      "[CV 1/5; 12/72] END classifier__C=0.001, classifier__gamma=100.0, pca=None;, score=(train=0.606, test=0.606) total time=   0.9s\n",
      "[CV 2/5; 12/72] START classifier__C=0.001, classifier__gamma=100.0, pca=None....\n",
      "[CV 2/5; 12/72] END classifier__C=0.001, classifier__gamma=100.0, pca=None;, score=(train=0.606, test=0.606) total time=   0.9s\n",
      "[CV 3/5; 12/72] START classifier__C=0.001, classifier__gamma=100.0, pca=None....\n",
      "[CV 3/5; 12/72] END classifier__C=0.001, classifier__gamma=100.0, pca=None;, score=(train=0.606, test=0.606) total time=   0.9s\n",
      "[CV 4/5; 12/72] START classifier__C=0.001, classifier__gamma=100.0, pca=None....\n",
      "[CV 4/5; 12/72] END classifier__C=0.001, classifier__gamma=100.0, pca=None;, score=(train=0.606, test=0.606) total time=   0.9s\n",
      "[CV 5/5; 12/72] START classifier__C=0.001, classifier__gamma=100.0, pca=None....\n",
      "[CV 5/5; 12/72] END classifier__C=0.001, classifier__gamma=100.0, pca=None;, score=(train=0.606, test=0.606) total time=   0.9s\n",
      "[CV 1/5; 13/72] START classifier__C=0.01, classifier__gamma=0.001, pca=PCA(n_components=11)\n",
      "[CV 1/5; 13/72] END classifier__C=0.01, classifier__gamma=0.001, pca=PCA(n_components=11);, score=(train=0.606, test=0.606) total time=   0.4s\n",
      "[CV 2/5; 13/72] START classifier__C=0.01, classifier__gamma=0.001, pca=PCA(n_components=11)\n",
      "[CV 2/5; 13/72] END classifier__C=0.01, classifier__gamma=0.001, pca=PCA(n_components=11);, score=(train=0.606, test=0.606) total time=   0.4s\n",
      "[CV 3/5; 13/72] START classifier__C=0.01, classifier__gamma=0.001, pca=PCA(n_components=11)\n",
      "[CV 3/5; 13/72] END classifier__C=0.01, classifier__gamma=0.001, pca=PCA(n_components=11);, score=(train=0.606, test=0.606) total time=   0.4s\n",
      "[CV 4/5; 13/72] START classifier__C=0.01, classifier__gamma=0.001, pca=PCA(n_components=11)\n",
      "[CV 4/5; 13/72] END classifier__C=0.01, classifier__gamma=0.001, pca=PCA(n_components=11);, score=(train=0.606, test=0.606) total time=   0.4s\n",
      "[CV 5/5; 13/72] START classifier__C=0.01, classifier__gamma=0.001, pca=PCA(n_components=11)\n",
      "[CV 5/5; 13/72] END classifier__C=0.01, classifier__gamma=0.001, pca=PCA(n_components=11);, score=(train=0.606, test=0.606) total time=   0.4s\n",
      "[CV 1/5; 14/72] START classifier__C=0.01, classifier__gamma=0.001, pca=None.....\n",
      "[CV 1/5; 14/72] END classifier__C=0.01, classifier__gamma=0.001, pca=None;, score=(train=0.606, test=0.606) total time=   0.5s\n",
      "[CV 2/5; 14/72] START classifier__C=0.01, classifier__gamma=0.001, pca=None.....\n",
      "[CV 2/5; 14/72] END classifier__C=0.01, classifier__gamma=0.001, pca=None;, score=(train=0.606, test=0.606) total time=   0.5s\n",
      "[CV 3/5; 14/72] START classifier__C=0.01, classifier__gamma=0.001, pca=None.....\n",
      "[CV 3/5; 14/72] END classifier__C=0.01, classifier__gamma=0.001, pca=None;, score=(train=0.606, test=0.606) total time=   0.5s\n",
      "[CV 4/5; 14/72] START classifier__C=0.01, classifier__gamma=0.001, pca=None.....\n",
      "[CV 4/5; 14/72] END classifier__C=0.01, classifier__gamma=0.001, pca=None;, score=(train=0.606, test=0.606) total time=   0.5s\n",
      "[CV 5/5; 14/72] START classifier__C=0.01, classifier__gamma=0.001, pca=None.....\n",
      "[CV 5/5; 14/72] END classifier__C=0.01, classifier__gamma=0.001, pca=None;, score=(train=0.606, test=0.606) total time=   0.5s\n",
      "[CV 1/5; 15/72] START classifier__C=0.01, classifier__gamma=0.01, pca=PCA(n_components=11)\n",
      "[CV 1/5; 15/72] END classifier__C=0.01, classifier__gamma=0.01, pca=PCA(n_components=11);, score=(train=0.760, test=0.757) total time=   0.4s\n",
      "[CV 2/5; 15/72] START classifier__C=0.01, classifier__gamma=0.01, pca=PCA(n_components=11)\n",
      "[CV 2/5; 15/72] END classifier__C=0.01, classifier__gamma=0.01, pca=PCA(n_components=11);, score=(train=0.757, test=0.772) total time=   0.4s\n",
      "[CV 3/5; 15/72] START classifier__C=0.01, classifier__gamma=0.01, pca=PCA(n_components=11)\n",
      "[CV 3/5; 15/72] END classifier__C=0.01, classifier__gamma=0.01, pca=PCA(n_components=11);, score=(train=0.766, test=0.749) total time=   0.4s\n",
      "[CV 4/5; 15/72] START classifier__C=0.01, classifier__gamma=0.01, pca=PCA(n_components=11)\n",
      "[CV 4/5; 15/72] END classifier__C=0.01, classifier__gamma=0.01, pca=PCA(n_components=11);, score=(train=0.770, test=0.769) total time=   0.4s\n",
      "[CV 5/5; 15/72] START classifier__C=0.01, classifier__gamma=0.01, pca=PCA(n_components=11)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 15/72] END classifier__C=0.01, classifier__gamma=0.01, pca=PCA(n_components=11);, score=(train=0.762, test=0.758) total time=   0.4s\n",
      "[CV 1/5; 16/72] START classifier__C=0.01, classifier__gamma=0.01, pca=None......\n",
      "[CV 1/5; 16/72] END classifier__C=0.01, classifier__gamma=0.01, pca=None;, score=(train=0.634, test=0.628) total time=   0.5s\n",
      "[CV 2/5; 16/72] START classifier__C=0.01, classifier__gamma=0.01, pca=None......\n",
      "[CV 2/5; 16/72] END classifier__C=0.01, classifier__gamma=0.01, pca=None;, score=(train=0.627, test=0.630) total time=   0.6s\n",
      "[CV 3/5; 16/72] START classifier__C=0.01, classifier__gamma=0.01, pca=None......\n",
      "[CV 3/5; 16/72] END classifier__C=0.01, classifier__gamma=0.01, pca=None;, score=(train=0.633, test=0.628) total time=   0.5s\n",
      "[CV 4/5; 16/72] START classifier__C=0.01, classifier__gamma=0.01, pca=None......\n",
      "[CV 4/5; 16/72] END classifier__C=0.01, classifier__gamma=0.01, pca=None;, score=(train=0.643, test=0.635) total time=   0.5s\n",
      "[CV 5/5; 16/72] START classifier__C=0.01, classifier__gamma=0.01, pca=None......\n",
      "[CV 5/5; 16/72] END classifier__C=0.01, classifier__gamma=0.01, pca=None;, score=(train=0.626, test=0.644) total time=   0.5s\n",
      "[CV 1/5; 17/72] START classifier__C=0.01, classifier__gamma=0.1, pca=PCA(n_components=11)\n",
      "[CV 1/5; 17/72] END classifier__C=0.01, classifier__gamma=0.1, pca=PCA(n_components=11);, score=(train=0.839, test=0.838) total time=   0.4s\n",
      "[CV 2/5; 17/72] START classifier__C=0.01, classifier__gamma=0.1, pca=PCA(n_components=11)\n",
      "[CV 2/5; 17/72] END classifier__C=0.01, classifier__gamma=0.1, pca=PCA(n_components=11);, score=(train=0.832, test=0.841) total time=   0.4s\n",
      "[CV 3/5; 17/72] START classifier__C=0.01, classifier__gamma=0.1, pca=PCA(n_components=11)\n",
      "[CV 3/5; 17/72] END classifier__C=0.01, classifier__gamma=0.1, pca=PCA(n_components=11);, score=(train=0.833, test=0.825) total time=   0.4s\n",
      "[CV 4/5; 17/72] START classifier__C=0.01, classifier__gamma=0.1, pca=PCA(n_components=11)\n",
      "[CV 4/5; 17/72] END classifier__C=0.01, classifier__gamma=0.1, pca=PCA(n_components=11);, score=(train=0.841, test=0.834) total time=   0.3s\n",
      "[CV 5/5; 17/72] START classifier__C=0.01, classifier__gamma=0.1, pca=PCA(n_components=11)\n",
      "[CV 5/5; 17/72] END classifier__C=0.01, classifier__gamma=0.1, pca=PCA(n_components=11);, score=(train=0.828, test=0.825) total time=   0.3s\n",
      "[CV 1/5; 18/72] START classifier__C=0.01, classifier__gamma=0.1, pca=None.......\n",
      "[CV 1/5; 18/72] END classifier__C=0.01, classifier__gamma=0.1, pca=None;, score=(train=0.606, test=0.606) total time=   0.5s\n",
      "[CV 2/5; 18/72] START classifier__C=0.01, classifier__gamma=0.1, pca=None.......\n",
      "[CV 2/5; 18/72] END classifier__C=0.01, classifier__gamma=0.1, pca=None;, score=(train=0.606, test=0.606) total time=   0.5s\n",
      "[CV 3/5; 18/72] START classifier__C=0.01, classifier__gamma=0.1, pca=None.......\n",
      "[CV 3/5; 18/72] END classifier__C=0.01, classifier__gamma=0.1, pca=None;, score=(train=0.606, test=0.606) total time=   0.5s\n",
      "[CV 4/5; 18/72] START classifier__C=0.01, classifier__gamma=0.1, pca=None.......\n",
      "[CV 4/5; 18/72] END classifier__C=0.01, classifier__gamma=0.1, pca=None;, score=(train=0.606, test=0.606) total time=   0.5s\n",
      "[CV 5/5; 18/72] START classifier__C=0.01, classifier__gamma=0.1, pca=None.......\n",
      "[CV 5/5; 18/72] END classifier__C=0.01, classifier__gamma=0.1, pca=None;, score=(train=0.606, test=0.606) total time=   0.5s\n",
      "[CV 1/5; 19/72] START classifier__C=0.01, classifier__gamma=1.0, pca=PCA(n_components=11)\n",
      "[CV 1/5; 19/72] END classifier__C=0.01, classifier__gamma=1.0, pca=PCA(n_components=11);, score=(train=0.606, test=0.606) total time=   0.4s\n",
      "[CV 2/5; 19/72] START classifier__C=0.01, classifier__gamma=1.0, pca=PCA(n_components=11)\n",
      "[CV 2/5; 19/72] END classifier__C=0.01, classifier__gamma=1.0, pca=PCA(n_components=11);, score=(train=0.606, test=0.606) total time=   0.4s\n",
      "[CV 3/5; 19/72] START classifier__C=0.01, classifier__gamma=1.0, pca=PCA(n_components=11)\n",
      "[CV 3/5; 19/72] END classifier__C=0.01, classifier__gamma=1.0, pca=PCA(n_components=11);, score=(train=0.606, test=0.606) total time=   0.4s\n",
      "[CV 4/5; 19/72] START classifier__C=0.01, classifier__gamma=1.0, pca=PCA(n_components=11)\n",
      "[CV 4/5; 19/72] END classifier__C=0.01, classifier__gamma=1.0, pca=PCA(n_components=11);, score=(train=0.606, test=0.606) total time=   0.4s\n",
      "[CV 5/5; 19/72] START classifier__C=0.01, classifier__gamma=1.0, pca=PCA(n_components=11)\n",
      "[CV 5/5; 19/72] END classifier__C=0.01, classifier__gamma=1.0, pca=PCA(n_components=11);, score=(train=0.606, test=0.606) total time=   0.4s\n",
      "[CV 1/5; 20/72] START classifier__C=0.01, classifier__gamma=1.0, pca=None.......\n",
      "[CV 1/5; 20/72] END classifier__C=0.01, classifier__gamma=1.0, pca=None;, score=(train=0.606, test=0.606) total time=   0.6s\n",
      "[CV 2/5; 20/72] START classifier__C=0.01, classifier__gamma=1.0, pca=None.......\n",
      "[CV 2/5; 20/72] END classifier__C=0.01, classifier__gamma=1.0, pca=None;, score=(train=0.606, test=0.606) total time=   0.6s\n",
      "[CV 3/5; 20/72] START classifier__C=0.01, classifier__gamma=1.0, pca=None.......\n",
      "[CV 3/5; 20/72] END classifier__C=0.01, classifier__gamma=1.0, pca=None;, score=(train=0.606, test=0.606) total time=   0.7s\n",
      "[CV 4/5; 20/72] START classifier__C=0.01, classifier__gamma=1.0, pca=None.......\n",
      "[CV 4/5; 20/72] END classifier__C=0.01, classifier__gamma=1.0, pca=None;, score=(train=0.606, test=0.606) total time=   0.7s\n",
      "[CV 5/5; 20/72] START classifier__C=0.01, classifier__gamma=1.0, pca=None.......\n",
      "[CV 5/5; 20/72] END classifier__C=0.01, classifier__gamma=1.0, pca=None;, score=(train=0.606, test=0.606) total time=   0.6s\n",
      "[CV 1/5; 21/72] START classifier__C=0.01, classifier__gamma=10.0, pca=PCA(n_components=11)\n",
      "[CV 1/5; 21/72] END classifier__C=0.01, classifier__gamma=10.0, pca=PCA(n_components=11);, score=(train=0.606, test=0.606) total time=   0.5s\n",
      "[CV 2/5; 21/72] START classifier__C=0.01, classifier__gamma=10.0, pca=PCA(n_components=11)\n",
      "[CV 2/5; 21/72] END classifier__C=0.01, classifier__gamma=10.0, pca=PCA(n_components=11);, score=(train=0.606, test=0.606) total time=   0.5s\n",
      "[CV 3/5; 21/72] START classifier__C=0.01, classifier__gamma=10.0, pca=PCA(n_components=11)\n",
      "[CV 3/5; 21/72] END classifier__C=0.01, classifier__gamma=10.0, pca=PCA(n_components=11);, score=(train=0.606, test=0.606) total time=   0.5s\n",
      "[CV 4/5; 21/72] START classifier__C=0.01, classifier__gamma=10.0, pca=PCA(n_components=11)\n",
      "[CV 4/5; 21/72] END classifier__C=0.01, classifier__gamma=10.0, pca=PCA(n_components=11);, score=(train=0.606, test=0.606) total time=   0.5s\n",
      "[CV 5/5; 21/72] START classifier__C=0.01, classifier__gamma=10.0, pca=PCA(n_components=11)\n",
      "[CV 5/5; 21/72] END classifier__C=0.01, classifier__gamma=10.0, pca=PCA(n_components=11);, score=(train=0.606, test=0.606) total time=   0.5s\n",
      "[CV 1/5; 22/72] START classifier__C=0.01, classifier__gamma=10.0, pca=None......\n",
      "[CV 1/5; 22/72] END classifier__C=0.01, classifier__gamma=10.0, pca=None;, score=(train=0.606, test=0.606) total time=   0.8s\n",
      "[CV 2/5; 22/72] START classifier__C=0.01, classifier__gamma=10.0, pca=None......\n",
      "[CV 2/5; 22/72] END classifier__C=0.01, classifier__gamma=10.0, pca=None;, score=(train=0.606, test=0.606) total time=   0.8s\n",
      "[CV 3/5; 22/72] START classifier__C=0.01, classifier__gamma=10.0, pca=None......\n",
      "[CV 3/5; 22/72] END classifier__C=0.01, classifier__gamma=10.0, pca=None;, score=(train=0.606, test=0.606) total time=   0.8s\n",
      "[CV 4/5; 22/72] START classifier__C=0.01, classifier__gamma=10.0, pca=None......\n",
      "[CV 4/5; 22/72] END classifier__C=0.01, classifier__gamma=10.0, pca=None;, score=(train=0.606, test=0.606) total time=   0.8s\n",
      "[CV 5/5; 22/72] START classifier__C=0.01, classifier__gamma=10.0, pca=None......\n",
      "[CV 5/5; 22/72] END classifier__C=0.01, classifier__gamma=10.0, pca=None;, score=(train=0.606, test=0.606) total time=   0.9s\n",
      "[CV 1/5; 23/72] START classifier__C=0.01, classifier__gamma=100.0, pca=PCA(n_components=11)\n",
      "[CV 1/5; 23/72] END classifier__C=0.01, classifier__gamma=100.0, pca=PCA(n_components=11);, score=(train=0.606, test=0.606) total time=   0.8s\n",
      "[CV 2/5; 23/72] START classifier__C=0.01, classifier__gamma=100.0, pca=PCA(n_components=11)\n",
      "[CV 2/5; 23/72] END classifier__C=0.01, classifier__gamma=100.0, pca=PCA(n_components=11);, score=(train=0.606, test=0.606) total time=   0.7s\n",
      "[CV 3/5; 23/72] START classifier__C=0.01, classifier__gamma=100.0, pca=PCA(n_components=11)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 23/72] END classifier__C=0.01, classifier__gamma=100.0, pca=PCA(n_components=11);, score=(train=0.606, test=0.606) total time=   0.7s\n",
      "[CV 4/5; 23/72] START classifier__C=0.01, classifier__gamma=100.0, pca=PCA(n_components=11)\n",
      "[CV 4/5; 23/72] END classifier__C=0.01, classifier__gamma=100.0, pca=PCA(n_components=11);, score=(train=0.606, test=0.606) total time=   0.7s\n",
      "[CV 5/5; 23/72] START classifier__C=0.01, classifier__gamma=100.0, pca=PCA(n_components=11)\n",
      "[CV 5/5; 23/72] END classifier__C=0.01, classifier__gamma=100.0, pca=PCA(n_components=11);, score=(train=0.606, test=0.606) total time=   0.7s\n",
      "[CV 1/5; 24/72] START classifier__C=0.01, classifier__gamma=100.0, pca=None.....\n",
      "[CV 1/5; 24/72] END classifier__C=0.01, classifier__gamma=100.0, pca=None;, score=(train=0.606, test=0.606) total time=   1.0s\n",
      "[CV 2/5; 24/72] START classifier__C=0.01, classifier__gamma=100.0, pca=None.....\n",
      "[CV 2/5; 24/72] END classifier__C=0.01, classifier__gamma=100.0, pca=None;, score=(train=0.606, test=0.606) total time=   1.0s\n",
      "[CV 3/5; 24/72] START classifier__C=0.01, classifier__gamma=100.0, pca=None.....\n",
      "[CV 3/5; 24/72] END classifier__C=0.01, classifier__gamma=100.0, pca=None;, score=(train=0.606, test=0.606) total time=   1.0s\n",
      "[CV 4/5; 24/72] START classifier__C=0.01, classifier__gamma=100.0, pca=None.....\n",
      "[CV 4/5; 24/72] END classifier__C=0.01, classifier__gamma=100.0, pca=None;, score=(train=0.606, test=0.606) total time=   1.0s\n",
      "[CV 5/5; 24/72] START classifier__C=0.01, classifier__gamma=100.0, pca=None.....\n",
      "[CV 5/5; 24/72] END classifier__C=0.01, classifier__gamma=100.0, pca=None;, score=(train=0.606, test=0.606) total time=   1.0s\n",
      "[CV 1/5; 25/72] START classifier__C=0.1, classifier__gamma=0.001, pca=PCA(n_components=11)\n",
      "[CV 1/5; 25/72] END classifier__C=0.1, classifier__gamma=0.001, pca=PCA(n_components=11);, score=(train=0.774, test=0.777) total time=   0.4s\n",
      "[CV 2/5; 25/72] START classifier__C=0.1, classifier__gamma=0.001, pca=PCA(n_components=11)\n",
      "[CV 2/5; 25/72] END classifier__C=0.1, classifier__gamma=0.001, pca=PCA(n_components=11);, score=(train=0.773, test=0.789) total time=   0.4s\n",
      "[CV 3/5; 25/72] START classifier__C=0.1, classifier__gamma=0.001, pca=PCA(n_components=11)\n",
      "[CV 3/5; 25/72] END classifier__C=0.1, classifier__gamma=0.001, pca=PCA(n_components=11);, score=(train=0.779, test=0.772) total time=   0.4s\n",
      "[CV 4/5; 25/72] START classifier__C=0.1, classifier__gamma=0.001, pca=PCA(n_components=11)\n",
      "[CV 4/5; 25/72] END classifier__C=0.1, classifier__gamma=0.001, pca=PCA(n_components=11);, score=(train=0.786, test=0.781) total time=   0.3s\n",
      "[CV 5/5; 25/72] START classifier__C=0.1, classifier__gamma=0.001, pca=PCA(n_components=11)\n",
      "[CV 5/5; 25/72] END classifier__C=0.1, classifier__gamma=0.001, pca=PCA(n_components=11);, score=(train=0.778, test=0.770) total time=   0.3s\n",
      "[CV 1/5; 26/72] START classifier__C=0.1, classifier__gamma=0.001, pca=None......\n",
      "[CV 1/5; 26/72] END classifier__C=0.1, classifier__gamma=0.001, pca=None;, score=(train=0.789, test=0.784) total time=   0.5s\n",
      "[CV 2/5; 26/72] START classifier__C=0.1, classifier__gamma=0.001, pca=None......\n",
      "[CV 2/5; 26/72] END classifier__C=0.1, classifier__gamma=0.001, pca=None;, score=(train=0.788, test=0.800) total time=   0.5s\n",
      "[CV 3/5; 26/72] START classifier__C=0.1, classifier__gamma=0.001, pca=None......\n",
      "[CV 3/5; 26/72] END classifier__C=0.1, classifier__gamma=0.001, pca=None;, score=(train=0.789, test=0.785) total time=   0.5s\n",
      "[CV 4/5; 26/72] START classifier__C=0.1, classifier__gamma=0.001, pca=None......\n",
      "[CV 4/5; 26/72] END classifier__C=0.1, classifier__gamma=0.001, pca=None;, score=(train=0.800, test=0.789) total time=   0.5s\n",
      "[CV 5/5; 26/72] START classifier__C=0.1, classifier__gamma=0.001, pca=None......\n",
      "[CV 5/5; 26/72] END classifier__C=0.1, classifier__gamma=0.001, pca=None;, score=(train=0.787, test=0.785) total time=   0.5s\n",
      "[CV 1/5; 27/72] START classifier__C=0.1, classifier__gamma=0.01, pca=PCA(n_components=11)\n",
      "[CV 1/5; 27/72] END classifier__C=0.1, classifier__gamma=0.01, pca=PCA(n_components=11);, score=(train=0.885, test=0.868) total time=   0.2s\n",
      "[CV 2/5; 27/72] START classifier__C=0.1, classifier__gamma=0.01, pca=PCA(n_components=11)\n",
      "[CV 2/5; 27/72] END classifier__C=0.1, classifier__gamma=0.01, pca=PCA(n_components=11);, score=(train=0.879, test=0.879) total time=   0.2s\n",
      "[CV 3/5; 27/72] START classifier__C=0.1, classifier__gamma=0.01, pca=PCA(n_components=11)\n",
      "[CV 3/5; 27/72] END classifier__C=0.1, classifier__gamma=0.01, pca=PCA(n_components=11);, score=(train=0.876, test=0.878) total time=   0.2s\n",
      "[CV 4/5; 27/72] START classifier__C=0.1, classifier__gamma=0.01, pca=PCA(n_components=11)\n",
      "[CV 4/5; 27/72] END classifier__C=0.1, classifier__gamma=0.01, pca=PCA(n_components=11);, score=(train=0.883, test=0.879) total time=   0.2s\n",
      "[CV 5/5; 27/72] START classifier__C=0.1, classifier__gamma=0.01, pca=PCA(n_components=11)\n",
      "[CV 5/5; 27/72] END classifier__C=0.1, classifier__gamma=0.01, pca=PCA(n_components=11);, score=(train=0.879, test=0.890) total time=   0.2s\n",
      "[CV 1/5; 28/72] START classifier__C=0.1, classifier__gamma=0.01, pca=None.......\n",
      "[CV 1/5; 28/72] END classifier__C=0.1, classifier__gamma=0.01, pca=None;, score=(train=0.901, test=0.898) total time=   0.3s\n",
      "[CV 2/5; 28/72] START classifier__C=0.1, classifier__gamma=0.01, pca=None.......\n",
      "[CV 2/5; 28/72] END classifier__C=0.1, classifier__gamma=0.01, pca=None;, score=(train=0.898, test=0.906) total time=   0.3s\n",
      "[CV 3/5; 28/72] START classifier__C=0.1, classifier__gamma=0.01, pca=None.......\n",
      "[CV 3/5; 28/72] END classifier__C=0.1, classifier__gamma=0.01, pca=None;, score=(train=0.899, test=0.891) total time=   0.3s\n",
      "[CV 4/5; 28/72] START classifier__C=0.1, classifier__gamma=0.01, pca=None.......\n",
      "[CV 4/5; 28/72] END classifier__C=0.1, classifier__gamma=0.01, pca=None;, score=(train=0.904, test=0.895) total time=   0.3s\n",
      "[CV 5/5; 28/72] START classifier__C=0.1, classifier__gamma=0.01, pca=None.......\n",
      "[CV 5/5; 28/72] END classifier__C=0.1, classifier__gamma=0.01, pca=None;, score=(train=0.901, test=0.898) total time=   0.3s\n",
      "[CV 1/5; 29/72] START classifier__C=0.1, classifier__gamma=0.1, pca=PCA(n_components=11)\n",
      "[CV 1/5; 29/72] END classifier__C=0.1, classifier__gamma=0.1, pca=PCA(n_components=11);, score=(train=0.899, test=0.874) total time=   0.2s\n",
      "[CV 2/5; 29/72] START classifier__C=0.1, classifier__gamma=0.1, pca=PCA(n_components=11)\n",
      "[CV 2/5; 29/72] END classifier__C=0.1, classifier__gamma=0.1, pca=PCA(n_components=11);, score=(train=0.897, test=0.899) total time=   0.2s\n",
      "[CV 3/5; 29/72] START classifier__C=0.1, classifier__gamma=0.1, pca=PCA(n_components=11)\n",
      "[CV 3/5; 29/72] END classifier__C=0.1, classifier__gamma=0.1, pca=PCA(n_components=11);, score=(train=0.898, test=0.901) total time=   0.2s\n",
      "[CV 4/5; 29/72] START classifier__C=0.1, classifier__gamma=0.1, pca=PCA(n_components=11)\n",
      "[CV 4/5; 29/72] END classifier__C=0.1, classifier__gamma=0.1, pca=PCA(n_components=11);, score=(train=0.896, test=0.880) total time=   0.2s\n",
      "[CV 5/5; 29/72] START classifier__C=0.1, classifier__gamma=0.1, pca=PCA(n_components=11)\n",
      "[CV 5/5; 29/72] END classifier__C=0.1, classifier__gamma=0.1, pca=PCA(n_components=11);, score=(train=0.897, test=0.893) total time=   0.2s\n",
      "[CV 1/5; 30/72] START classifier__C=0.1, classifier__gamma=0.1, pca=None........\n",
      "[CV 1/5; 30/72] END classifier__C=0.1, classifier__gamma=0.1, pca=None;, score=(train=0.827, test=0.796) total time=   0.5s\n",
      "[CV 2/5; 30/72] START classifier__C=0.1, classifier__gamma=0.1, pca=None........\n",
      "[CV 2/5; 30/72] END classifier__C=0.1, classifier__gamma=0.1, pca=None;, score=(train=0.819, test=0.804) total time=   0.5s\n",
      "[CV 3/5; 30/72] START classifier__C=0.1, classifier__gamma=0.1, pca=None........\n",
      "[CV 3/5; 30/72] END classifier__C=0.1, classifier__gamma=0.1, pca=None;, score=(train=0.828, test=0.818) total time=   0.5s\n",
      "[CV 4/5; 30/72] START classifier__C=0.1, classifier__gamma=0.1, pca=None........\n",
      "[CV 4/5; 30/72] END classifier__C=0.1, classifier__gamma=0.1, pca=None;, score=(train=0.837, test=0.806) total time=   0.5s\n",
      "[CV 5/5; 30/72] START classifier__C=0.1, classifier__gamma=0.1, pca=None........\n",
      "[CV 5/5; 30/72] END classifier__C=0.1, classifier__gamma=0.1, pca=None;, score=(train=0.812, test=0.795) total time=   0.5s\n",
      "[CV 1/5; 31/72] START classifier__C=0.1, classifier__gamma=1.0, pca=PCA(n_components=11)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 31/72] END classifier__C=0.1, classifier__gamma=1.0, pca=PCA(n_components=11);, score=(train=0.755, test=0.736) total time=   0.4s\n",
      "[CV 2/5; 31/72] START classifier__C=0.1, classifier__gamma=1.0, pca=PCA(n_components=11)\n",
      "[CV 2/5; 31/72] END classifier__C=0.1, classifier__gamma=1.0, pca=PCA(n_components=11);, score=(train=0.750, test=0.716) total time=   0.4s\n",
      "[CV 3/5; 31/72] START classifier__C=0.1, classifier__gamma=1.0, pca=PCA(n_components=11)\n",
      "[CV 3/5; 31/72] END classifier__C=0.1, classifier__gamma=1.0, pca=PCA(n_components=11);, score=(train=0.743, test=0.739) total time=   0.4s\n",
      "[CV 4/5; 31/72] START classifier__C=0.1, classifier__gamma=1.0, pca=PCA(n_components=11)\n",
      "[CV 4/5; 31/72] END classifier__C=0.1, classifier__gamma=1.0, pca=PCA(n_components=11);, score=(train=0.762, test=0.742) total time=   0.4s\n",
      "[CV 5/5; 31/72] START classifier__C=0.1, classifier__gamma=1.0, pca=PCA(n_components=11)\n",
      "[CV 5/5; 31/72] END classifier__C=0.1, classifier__gamma=1.0, pca=PCA(n_components=11);, score=(train=0.748, test=0.726) total time=   0.4s\n",
      "[CV 1/5; 32/72] START classifier__C=0.1, classifier__gamma=1.0, pca=None........\n",
      "[CV 1/5; 32/72] END classifier__C=0.1, classifier__gamma=1.0, pca=None;, score=(train=0.606, test=0.606) total time=   0.7s\n",
      "[CV 2/5; 32/72] START classifier__C=0.1, classifier__gamma=1.0, pca=None........\n",
      "[CV 2/5; 32/72] END classifier__C=0.1, classifier__gamma=1.0, pca=None;, score=(train=0.611, test=0.607) total time=   0.7s\n",
      "[CV 3/5; 32/72] START classifier__C=0.1, classifier__gamma=1.0, pca=None........\n",
      "[CV 3/5; 32/72] END classifier__C=0.1, classifier__gamma=1.0, pca=None;, score=(train=0.606, test=0.606) total time=   0.7s\n",
      "[CV 4/5; 32/72] START classifier__C=0.1, classifier__gamma=1.0, pca=None........\n",
      "[CV 4/5; 32/72] END classifier__C=0.1, classifier__gamma=1.0, pca=None;, score=(train=0.609, test=0.607) total time=   0.7s\n",
      "[CV 5/5; 32/72] START classifier__C=0.1, classifier__gamma=1.0, pca=None........\n",
      "[CV 5/5; 32/72] END classifier__C=0.1, classifier__gamma=1.0, pca=None;, score=(train=0.609, test=0.607) total time=   0.7s\n",
      "[CV 1/5; 33/72] START classifier__C=0.1, classifier__gamma=10.0, pca=PCA(n_components=11)\n",
      "[CV 1/5; 33/72] END classifier__C=0.1, classifier__gamma=10.0, pca=PCA(n_components=11);, score=(train=0.606, test=0.606) total time=   0.5s\n",
      "[CV 2/5; 33/72] START classifier__C=0.1, classifier__gamma=10.0, pca=PCA(n_components=11)\n",
      "[CV 2/5; 33/72] END classifier__C=0.1, classifier__gamma=10.0, pca=PCA(n_components=11);, score=(train=0.606, test=0.606) total time=   0.5s\n",
      "[CV 3/5; 33/72] START classifier__C=0.1, classifier__gamma=10.0, pca=PCA(n_components=11)\n",
      "[CV 3/5; 33/72] END classifier__C=0.1, classifier__gamma=10.0, pca=PCA(n_components=11);, score=(train=0.606, test=0.606) total time=   0.5s\n",
      "[CV 4/5; 33/72] START classifier__C=0.1, classifier__gamma=10.0, pca=PCA(n_components=11)\n",
      "[CV 4/5; 33/72] END classifier__C=0.1, classifier__gamma=10.0, pca=PCA(n_components=11);, score=(train=0.606, test=0.606) total time=   0.5s\n",
      "[CV 5/5; 33/72] START classifier__C=0.1, classifier__gamma=10.0, pca=PCA(n_components=11)\n",
      "[CV 5/5; 33/72] END classifier__C=0.1, classifier__gamma=10.0, pca=PCA(n_components=11);, score=(train=0.606, test=0.606) total time=   0.5s\n",
      "[CV 1/5; 34/72] START classifier__C=0.1, classifier__gamma=10.0, pca=None.......\n",
      "[CV 1/5; 34/72] END classifier__C=0.1, classifier__gamma=10.0, pca=None;, score=(train=0.606, test=0.606) total time=   0.8s\n",
      "[CV 2/5; 34/72] START classifier__C=0.1, classifier__gamma=10.0, pca=None.......\n",
      "[CV 2/5; 34/72] END classifier__C=0.1, classifier__gamma=10.0, pca=None;, score=(train=0.606, test=0.606) total time=   0.8s\n",
      "[CV 3/5; 34/72] START classifier__C=0.1, classifier__gamma=10.0, pca=None.......\n",
      "[CV 3/5; 34/72] END classifier__C=0.1, classifier__gamma=10.0, pca=None;, score=(train=0.606, test=0.606) total time=   0.8s\n",
      "[CV 4/5; 34/72] START classifier__C=0.1, classifier__gamma=10.0, pca=None.......\n",
      "[CV 4/5; 34/72] END classifier__C=0.1, classifier__gamma=10.0, pca=None;, score=(train=0.606, test=0.606) total time=   0.8s\n",
      "[CV 5/5; 34/72] START classifier__C=0.1, classifier__gamma=10.0, pca=None.......\n",
      "[CV 5/5; 34/72] END classifier__C=0.1, classifier__gamma=10.0, pca=None;, score=(train=0.606, test=0.606) total time=   0.8s\n",
      "[CV 1/5; 35/72] START classifier__C=0.1, classifier__gamma=100.0, pca=PCA(n_components=11)\n",
      "[CV 1/5; 35/72] END classifier__C=0.1, classifier__gamma=100.0, pca=PCA(n_components=11);, score=(train=0.606, test=0.606) total time=   0.8s\n",
      "[CV 2/5; 35/72] START classifier__C=0.1, classifier__gamma=100.0, pca=PCA(n_components=11)\n",
      "[CV 2/5; 35/72] END classifier__C=0.1, classifier__gamma=100.0, pca=PCA(n_components=11);, score=(train=0.606, test=0.606) total time=   0.8s\n",
      "[CV 3/5; 35/72] START classifier__C=0.1, classifier__gamma=100.0, pca=PCA(n_components=11)\n",
      "[CV 3/5; 35/72] END classifier__C=0.1, classifier__gamma=100.0, pca=PCA(n_components=11);, score=(train=0.606, test=0.606) total time=   0.8s\n",
      "[CV 4/5; 35/72] START classifier__C=0.1, classifier__gamma=100.0, pca=PCA(n_components=11)\n",
      "[CV 4/5; 35/72] END classifier__C=0.1, classifier__gamma=100.0, pca=PCA(n_components=11);, score=(train=0.606, test=0.606) total time=   0.8s\n",
      "[CV 5/5; 35/72] START classifier__C=0.1, classifier__gamma=100.0, pca=PCA(n_components=11)\n",
      "[CV 5/5; 35/72] END classifier__C=0.1, classifier__gamma=100.0, pca=PCA(n_components=11);, score=(train=0.606, test=0.606) total time=   0.8s\n",
      "[CV 1/5; 36/72] START classifier__C=0.1, classifier__gamma=100.0, pca=None......\n",
      "[CV 1/5; 36/72] END classifier__C=0.1, classifier__gamma=100.0, pca=None;, score=(train=0.606, test=0.606) total time=   1.0s\n",
      "[CV 2/5; 36/72] START classifier__C=0.1, classifier__gamma=100.0, pca=None......\n",
      "[CV 2/5; 36/72] END classifier__C=0.1, classifier__gamma=100.0, pca=None;, score=(train=0.606, test=0.606) total time=   1.0s\n",
      "[CV 3/5; 36/72] START classifier__C=0.1, classifier__gamma=100.0, pca=None......\n",
      "[CV 3/5; 36/72] END classifier__C=0.1, classifier__gamma=100.0, pca=None;, score=(train=0.606, test=0.606) total time=   1.0s\n",
      "[CV 4/5; 36/72] START classifier__C=0.1, classifier__gamma=100.0, pca=None......\n",
      "[CV 4/5; 36/72] END classifier__C=0.1, classifier__gamma=100.0, pca=None;, score=(train=0.606, test=0.606) total time=   1.0s\n",
      "[CV 5/5; 36/72] START classifier__C=0.1, classifier__gamma=100.0, pca=None......\n",
      "[CV 5/5; 36/72] END classifier__C=0.1, classifier__gamma=100.0, pca=None;, score=(train=0.606, test=0.606) total time=   1.0s\n",
      "[CV 1/5; 37/72] START classifier__C=1.0, classifier__gamma=0.001, pca=PCA(n_components=11)\n",
      "[CV 1/5; 37/72] END classifier__C=1.0, classifier__gamma=0.001, pca=PCA(n_components=11);, score=(train=0.877, test=0.864) total time=   0.2s\n",
      "[CV 2/5; 37/72] START classifier__C=1.0, classifier__gamma=0.001, pca=PCA(n_components=11)\n",
      "[CV 2/5; 37/72] END classifier__C=1.0, classifier__gamma=0.001, pca=PCA(n_components=11);, score=(train=0.875, test=0.885) total time=   0.2s\n",
      "[CV 3/5; 37/72] START classifier__C=1.0, classifier__gamma=0.001, pca=PCA(n_components=11)\n",
      "[CV 3/5; 37/72] END classifier__C=1.0, classifier__gamma=0.001, pca=PCA(n_components=11);, score=(train=0.880, test=0.876) total time=   0.2s\n",
      "[CV 4/5; 37/72] START classifier__C=1.0, classifier__gamma=0.001, pca=PCA(n_components=11)\n",
      "[CV 4/5; 37/72] END classifier__C=1.0, classifier__gamma=0.001, pca=PCA(n_components=11);, score=(train=0.883, test=0.879) total time=   0.2s\n",
      "[CV 5/5; 37/72] START classifier__C=1.0, classifier__gamma=0.001, pca=PCA(n_components=11)\n",
      "[CV 5/5; 37/72] END classifier__C=1.0, classifier__gamma=0.001, pca=PCA(n_components=11);, score=(train=0.869, test=0.872) total time=   0.2s\n",
      "[CV 1/5; 38/72] START classifier__C=1.0, classifier__gamma=0.001, pca=None......\n",
      "[CV 1/5; 38/72] END classifier__C=1.0, classifier__gamma=0.001, pca=None;, score=(train=0.892, test=0.898) total time=   0.3s\n",
      "[CV 2/5; 38/72] START classifier__C=1.0, classifier__gamma=0.001, pca=None......\n",
      "[CV 2/5; 38/72] END classifier__C=1.0, classifier__gamma=0.001, pca=None;, score=(train=0.894, test=0.895) total time=   0.3s\n",
      "[CV 3/5; 38/72] START classifier__C=1.0, classifier__gamma=0.001, pca=None......\n",
      "[CV 3/5; 38/72] END classifier__C=1.0, classifier__gamma=0.001, pca=None;, score=(train=0.895, test=0.882) total time=   0.3s\n",
      "[CV 4/5; 38/72] START classifier__C=1.0, classifier__gamma=0.001, pca=None......\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 38/72] END classifier__C=1.0, classifier__gamma=0.001, pca=None;, score=(train=0.899, test=0.889) total time=   0.3s\n",
      "[CV 5/5; 38/72] START classifier__C=1.0, classifier__gamma=0.001, pca=None......\n",
      "[CV 5/5; 38/72] END classifier__C=1.0, classifier__gamma=0.001, pca=None;, score=(train=0.895, test=0.894) total time=   0.3s\n",
      "[CV 1/5; 39/72] START classifier__C=1.0, classifier__gamma=0.01, pca=PCA(n_components=11)\n",
      "[CV 1/5; 39/72] END classifier__C=1.0, classifier__gamma=0.01, pca=PCA(n_components=11);, score=(train=0.905, test=0.879) total time=   0.1s\n",
      "[CV 2/5; 39/72] START classifier__C=1.0, classifier__gamma=0.01, pca=PCA(n_components=11)\n",
      "[CV 2/5; 39/72] END classifier__C=1.0, classifier__gamma=0.01, pca=PCA(n_components=11);, score=(train=0.900, test=0.897) total time=   0.1s\n",
      "[CV 3/5; 39/72] START classifier__C=1.0, classifier__gamma=0.01, pca=PCA(n_components=11)\n",
      "[CV 3/5; 39/72] END classifier__C=1.0, classifier__gamma=0.01, pca=PCA(n_components=11);, score=(train=0.907, test=0.912) total time=   0.1s\n",
      "[CV 4/5; 39/72] START classifier__C=1.0, classifier__gamma=0.01, pca=PCA(n_components=11)\n",
      "[CV 4/5; 39/72] END classifier__C=1.0, classifier__gamma=0.01, pca=PCA(n_components=11);, score=(train=0.906, test=0.904) total time=   0.1s\n",
      "[CV 5/5; 39/72] START classifier__C=1.0, classifier__gamma=0.01, pca=PCA(n_components=11)\n",
      "[CV 5/5; 39/72] END classifier__C=1.0, classifier__gamma=0.01, pca=PCA(n_components=11);, score=(train=0.909, test=0.909) total time=   0.1s\n",
      "[CV 1/5; 40/72] START classifier__C=1.0, classifier__gamma=0.01, pca=None.......\n",
      "[CV 1/5; 40/72] END classifier__C=1.0, classifier__gamma=0.01, pca=None;, score=(train=0.941, test=0.925) total time=   0.2s\n",
      "[CV 2/5; 40/72] START classifier__C=1.0, classifier__gamma=0.01, pca=None.......\n",
      "[CV 2/5; 40/72] END classifier__C=1.0, classifier__gamma=0.01, pca=None;, score=(train=0.936, test=0.932) total time=   0.2s\n",
      "[CV 3/5; 40/72] START classifier__C=1.0, classifier__gamma=0.01, pca=None.......\n",
      "[CV 3/5; 40/72] END classifier__C=1.0, classifier__gamma=0.01, pca=None;, score=(train=0.936, test=0.928) total time=   0.2s\n",
      "[CV 4/5; 40/72] START classifier__C=1.0, classifier__gamma=0.01, pca=None.......\n",
      "[CV 4/5; 40/72] END classifier__C=1.0, classifier__gamma=0.01, pca=None;, score=(train=0.939, test=0.923) total time=   0.2s\n",
      "[CV 5/5; 40/72] START classifier__C=1.0, classifier__gamma=0.01, pca=None.......\n",
      "[CV 5/5; 40/72] END classifier__C=1.0, classifier__gamma=0.01, pca=None;, score=(train=0.936, test=0.929) total time=   0.2s\n",
      "[CV 1/5; 41/72] START classifier__C=1.0, classifier__gamma=0.1, pca=PCA(n_components=11)\n",
      "[CV 1/5; 41/72] END classifier__C=1.0, classifier__gamma=0.1, pca=PCA(n_components=11);, score=(train=0.930, test=0.897) total time=   0.1s\n",
      "[CV 2/5; 41/72] START classifier__C=1.0, classifier__gamma=0.1, pca=PCA(n_components=11)\n",
      "[CV 2/5; 41/72] END classifier__C=1.0, classifier__gamma=0.1, pca=PCA(n_components=11);, score=(train=0.927, test=0.916) total time=   0.1s\n",
      "[CV 3/5; 41/72] START classifier__C=1.0, classifier__gamma=0.1, pca=PCA(n_components=11)\n",
      "[CV 3/5; 41/72] END classifier__C=1.0, classifier__gamma=0.1, pca=PCA(n_components=11);, score=(train=0.930, test=0.914) total time=   0.1s\n",
      "[CV 4/5; 41/72] START classifier__C=1.0, classifier__gamma=0.1, pca=PCA(n_components=11)\n",
      "[CV 4/5; 41/72] END classifier__C=1.0, classifier__gamma=0.1, pca=PCA(n_components=11);, score=(train=0.928, test=0.908) total time=   0.2s\n",
      "[CV 5/5; 41/72] START classifier__C=1.0, classifier__gamma=0.1, pca=PCA(n_components=11)\n",
      "[CV 5/5; 41/72] END classifier__C=1.0, classifier__gamma=0.1, pca=PCA(n_components=11);, score=(train=0.925, test=0.924) total time=   0.1s\n",
      "[CV 1/5; 42/72] START classifier__C=1.0, classifier__gamma=0.1, pca=None........\n",
      "[CV 1/5; 42/72] END classifier__C=1.0, classifier__gamma=0.1, pca=None;, score=(train=0.969, test=0.898) total time=   0.4s\n",
      "[CV 2/5; 42/72] START classifier__C=1.0, classifier__gamma=0.1, pca=None........\n",
      "[CV 2/5; 42/72] END classifier__C=1.0, classifier__gamma=0.1, pca=None;, score=(train=0.964, test=0.909) total time=   0.4s\n",
      "[CV 3/5; 42/72] START classifier__C=1.0, classifier__gamma=0.1, pca=None........\n",
      "[CV 3/5; 42/72] END classifier__C=1.0, classifier__gamma=0.1, pca=None;, score=(train=0.964, test=0.914) total time=   0.4s\n",
      "[CV 4/5; 42/72] START classifier__C=1.0, classifier__gamma=0.1, pca=None........\n",
      "[CV 4/5; 42/72] END classifier__C=1.0, classifier__gamma=0.1, pca=None;, score=(train=0.967, test=0.899) total time=   0.4s\n",
      "[CV 5/5; 42/72] START classifier__C=1.0, classifier__gamma=0.1, pca=None........\n",
      "[CV 5/5; 42/72] END classifier__C=1.0, classifier__gamma=0.1, pca=None;, score=(train=0.967, test=0.899) total time=   0.4s\n",
      "[CV 1/5; 43/72] START classifier__C=1.0, classifier__gamma=1.0, pca=PCA(n_components=11)\n",
      "[CV 1/5; 43/72] END classifier__C=1.0, classifier__gamma=1.0, pca=PCA(n_components=11);, score=(train=0.966, test=0.872) total time=   0.3s\n",
      "[CV 2/5; 43/72] START classifier__C=1.0, classifier__gamma=1.0, pca=PCA(n_components=11)\n",
      "[CV 2/5; 43/72] END classifier__C=1.0, classifier__gamma=1.0, pca=PCA(n_components=11);, score=(train=0.960, test=0.891) total time=   0.4s\n",
      "[CV 3/5; 43/72] START classifier__C=1.0, classifier__gamma=1.0, pca=PCA(n_components=11)\n",
      "[CV 3/5; 43/72] END classifier__C=1.0, classifier__gamma=1.0, pca=PCA(n_components=11);, score=(train=0.963, test=0.901) total time=   0.4s\n",
      "[CV 4/5; 43/72] START classifier__C=1.0, classifier__gamma=1.0, pca=PCA(n_components=11)\n",
      "[CV 4/5; 43/72] END classifier__C=1.0, classifier__gamma=1.0, pca=PCA(n_components=11);, score=(train=0.964, test=0.867) total time=   0.3s\n",
      "[CV 5/5; 43/72] START classifier__C=1.0, classifier__gamma=1.0, pca=PCA(n_components=11)\n",
      "[CV 5/5; 43/72] END classifier__C=1.0, classifier__gamma=1.0, pca=PCA(n_components=11);, score=(train=0.966, test=0.886) total time=   0.3s\n",
      "[CV 1/5; 44/72] START classifier__C=1.0, classifier__gamma=1.0, pca=None........\n",
      "[CV 1/5; 44/72] END classifier__C=1.0, classifier__gamma=1.0, pca=None;, score=(train=0.992, test=0.753) total time=   0.7s\n",
      "[CV 2/5; 44/72] START classifier__C=1.0, classifier__gamma=1.0, pca=None........\n",
      "[CV 2/5; 44/72] END classifier__C=1.0, classifier__gamma=1.0, pca=None;, score=(train=0.990, test=0.736) total time=   0.7s\n",
      "[CV 3/5; 44/72] START classifier__C=1.0, classifier__gamma=1.0, pca=None........\n",
      "[CV 3/5; 44/72] END classifier__C=1.0, classifier__gamma=1.0, pca=None;, score=(train=0.992, test=0.724) total time=   0.7s\n",
      "[CV 4/5; 44/72] START classifier__C=1.0, classifier__gamma=1.0, pca=None........\n",
      "[CV 4/5; 44/72] END classifier__C=1.0, classifier__gamma=1.0, pca=None;, score=(train=0.993, test=0.735) total time=   0.7s\n",
      "[CV 5/5; 44/72] START classifier__C=1.0, classifier__gamma=1.0, pca=None........\n",
      "[CV 5/5; 44/72] END classifier__C=1.0, classifier__gamma=1.0, pca=None;, score=(train=0.994, test=0.735) total time=   0.7s\n",
      "[CV 1/5; 45/72] START classifier__C=1.0, classifier__gamma=10.0, pca=PCA(n_components=11)\n",
      "[CV 1/5; 45/72] END classifier__C=1.0, classifier__gamma=10.0, pca=PCA(n_components=11);, score=(train=0.977, test=0.719) total time=   0.6s\n",
      "[CV 2/5; 45/72] START classifier__C=1.0, classifier__gamma=10.0, pca=PCA(n_components=11)\n",
      "[CV 2/5; 45/72] END classifier__C=1.0, classifier__gamma=10.0, pca=PCA(n_components=11);, score=(train=0.967, test=0.690) total time=   0.6s\n",
      "[CV 3/5; 45/72] START classifier__C=1.0, classifier__gamma=10.0, pca=PCA(n_components=11)\n",
      "[CV 3/5; 45/72] END classifier__C=1.0, classifier__gamma=10.0, pca=PCA(n_components=11);, score=(train=0.983, test=0.702) total time=   0.6s\n",
      "[CV 4/5; 45/72] START classifier__C=1.0, classifier__gamma=10.0, pca=PCA(n_components=11)\n",
      "[CV 4/5; 45/72] END classifier__C=1.0, classifier__gamma=10.0, pca=PCA(n_components=11);, score=(train=0.984, test=0.715) total time=   0.6s\n",
      "[CV 5/5; 45/72] START classifier__C=1.0, classifier__gamma=10.0, pca=PCA(n_components=11)\n",
      "[CV 5/5; 45/72] END classifier__C=1.0, classifier__gamma=10.0, pca=PCA(n_components=11);, score=(train=0.975, test=0.698) total time=   0.6s\n",
      "[CV 1/5; 46/72] START classifier__C=1.0, classifier__gamma=10.0, pca=None.......\n",
      "[CV 1/5; 46/72] END classifier__C=1.0, classifier__gamma=10.0, pca=None;, score=(train=0.997, test=0.667) total time=   0.9s\n",
      "[CV 2/5; 46/72] START classifier__C=1.0, classifier__gamma=10.0, pca=None.......\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 46/72] END classifier__C=1.0, classifier__gamma=10.0, pca=None;, score=(train=0.997, test=0.662) total time=   0.9s\n",
      "[CV 3/5; 46/72] START classifier__C=1.0, classifier__gamma=10.0, pca=None.......\n",
      "[CV 3/5; 46/72] END classifier__C=1.0, classifier__gamma=10.0, pca=None;, score=(train=0.996, test=0.667) total time=   0.9s\n",
      "[CV 4/5; 46/72] START classifier__C=1.0, classifier__gamma=10.0, pca=None.......\n",
      "[CV 4/5; 46/72] END classifier__C=1.0, classifier__gamma=10.0, pca=None;, score=(train=0.997, test=0.659) total time=   0.9s\n",
      "[CV 5/5; 46/72] START classifier__C=1.0, classifier__gamma=10.0, pca=None.......\n",
      "[CV 5/5; 46/72] END classifier__C=1.0, classifier__gamma=10.0, pca=None;, score=(train=0.998, test=0.664) total time=   0.9s\n",
      "[CV 1/5; 47/72] START classifier__C=1.0, classifier__gamma=100.0, pca=PCA(n_components=11)\n",
      "[CV 1/5; 47/72] END classifier__C=1.0, classifier__gamma=100.0, pca=PCA(n_components=11);, score=(train=0.737, test=0.625) total time=   0.8s\n",
      "[CV 2/5; 47/72] START classifier__C=1.0, classifier__gamma=100.0, pca=PCA(n_components=11)\n",
      "[CV 2/5; 47/72] END classifier__C=1.0, classifier__gamma=100.0, pca=PCA(n_components=11);, score=(train=0.751, test=0.618) total time=   0.8s\n",
      "[CV 3/5; 47/72] START classifier__C=1.0, classifier__gamma=100.0, pca=PCA(n_components=11)\n",
      "[CV 3/5; 47/72] END classifier__C=1.0, classifier__gamma=100.0, pca=PCA(n_components=11);, score=(train=0.771, test=0.629) total time=   0.8s\n",
      "[CV 4/5; 47/72] START classifier__C=1.0, classifier__gamma=100.0, pca=PCA(n_components=11)\n",
      "[CV 4/5; 47/72] END classifier__C=1.0, classifier__gamma=100.0, pca=PCA(n_components=11);, score=(train=0.735, test=0.618) total time=   0.8s\n",
      "[CV 5/5; 47/72] START classifier__C=1.0, classifier__gamma=100.0, pca=PCA(n_components=11)\n",
      "[CV 5/5; 47/72] END classifier__C=1.0, classifier__gamma=100.0, pca=PCA(n_components=11);, score=(train=0.711, test=0.613) total time=   0.8s\n",
      "[CV 1/5; 48/72] START classifier__C=1.0, classifier__gamma=100.0, pca=None......\n",
      "[CV 1/5; 48/72] END classifier__C=1.0, classifier__gamma=100.0, pca=None;, score=(train=0.999, test=0.630) total time=   1.0s\n",
      "[CV 2/5; 48/72] START classifier__C=1.0, classifier__gamma=100.0, pca=None......\n",
      "[CV 2/5; 48/72] END classifier__C=1.0, classifier__gamma=100.0, pca=None;, score=(train=0.999, test=0.628) total time=   1.0s\n",
      "[CV 3/5; 48/72] START classifier__C=1.0, classifier__gamma=100.0, pca=None......\n",
      "[CV 3/5; 48/72] END classifier__C=1.0, classifier__gamma=100.0, pca=None;, score=(train=0.998, test=0.628) total time=   1.0s\n",
      "[CV 4/5; 48/72] START classifier__C=1.0, classifier__gamma=100.0, pca=None......\n",
      "[CV 4/5; 48/72] END classifier__C=1.0, classifier__gamma=100.0, pca=None;, score=(train=0.999, test=0.635) total time=   1.0s\n",
      "[CV 5/5; 48/72] START classifier__C=1.0, classifier__gamma=100.0, pca=None......\n",
      "[CV 5/5; 48/72] END classifier__C=1.0, classifier__gamma=100.0, pca=None;, score=(train=0.999, test=0.628) total time=   1.0s\n",
      "[CV 1/5; 49/72] START classifier__C=10.0, classifier__gamma=0.001, pca=PCA(n_components=11)\n",
      "[CV 1/5; 49/72] END classifier__C=10.0, classifier__gamma=0.001, pca=PCA(n_components=11);, score=(train=0.900, test=0.885) total time=   0.1s\n",
      "[CV 2/5; 49/72] START classifier__C=10.0, classifier__gamma=0.001, pca=PCA(n_components=11)\n",
      "[CV 2/5; 49/72] END classifier__C=10.0, classifier__gamma=0.001, pca=PCA(n_components=11);, score=(train=0.893, test=0.890) total time=   0.1s\n",
      "[CV 3/5; 49/72] START classifier__C=10.0, classifier__gamma=0.001, pca=PCA(n_components=11)\n",
      "[CV 3/5; 49/72] END classifier__C=10.0, classifier__gamma=0.001, pca=PCA(n_components=11);, score=(train=0.891, test=0.901) total time=   0.1s\n",
      "[CV 4/5; 49/72] START classifier__C=10.0, classifier__gamma=0.001, pca=PCA(n_components=11)\n",
      "[CV 4/5; 49/72] END classifier__C=10.0, classifier__gamma=0.001, pca=PCA(n_components=11);, score=(train=0.898, test=0.890) total time=   0.1s\n",
      "[CV 5/5; 49/72] START classifier__C=10.0, classifier__gamma=0.001, pca=PCA(n_components=11)\n",
      "[CV 5/5; 49/72] END classifier__C=10.0, classifier__gamma=0.001, pca=PCA(n_components=11);, score=(train=0.897, test=0.902) total time=   0.1s\n",
      "[CV 1/5; 50/72] START classifier__C=10.0, classifier__gamma=0.001, pca=None.....\n",
      "[CV 1/5; 50/72] END classifier__C=10.0, classifier__gamma=0.001, pca=None;, score=(train=0.931, test=0.916) total time=   0.2s\n",
      "[CV 2/5; 50/72] START classifier__C=10.0, classifier__gamma=0.001, pca=None.....\n",
      "[CV 2/5; 50/72] END classifier__C=10.0, classifier__gamma=0.001, pca=None;, score=(train=0.928, test=0.927) total time=   0.2s\n",
      "[CV 3/5; 50/72] START classifier__C=10.0, classifier__gamma=0.001, pca=None.....\n",
      "[CV 3/5; 50/72] END classifier__C=10.0, classifier__gamma=0.001, pca=None;, score=(train=0.929, test=0.924) total time=   0.2s\n",
      "[CV 4/5; 50/72] START classifier__C=10.0, classifier__gamma=0.001, pca=None.....\n",
      "[CV 4/5; 50/72] END classifier__C=10.0, classifier__gamma=0.001, pca=None;, score=(train=0.931, test=0.927) total time=   0.2s\n",
      "[CV 5/5; 50/72] START classifier__C=10.0, classifier__gamma=0.001, pca=None.....\n",
      "[CV 5/5; 50/72] END classifier__C=10.0, classifier__gamma=0.001, pca=None;, score=(train=0.929, test=0.929) total time=   0.1s\n",
      "[CV 1/5; 51/72] START classifier__C=10.0, classifier__gamma=0.01, pca=PCA(n_components=11)\n",
      "[CV 1/5; 51/72] END classifier__C=10.0, classifier__gamma=0.01, pca=PCA(n_components=11);, score=(train=0.923, test=0.902) total time=   0.1s\n",
      "[CV 2/5; 51/72] START classifier__C=10.0, classifier__gamma=0.01, pca=PCA(n_components=11)\n",
      "[CV 2/5; 51/72] END classifier__C=10.0, classifier__gamma=0.01, pca=PCA(n_components=11);, score=(train=0.913, test=0.916) total time=   0.1s\n",
      "[CV 3/5; 51/72] START classifier__C=10.0, classifier__gamma=0.01, pca=PCA(n_components=11)\n",
      "[CV 3/5; 51/72] END classifier__C=10.0, classifier__gamma=0.01, pca=PCA(n_components=11);, score=(train=0.912, test=0.908) total time=   0.1s\n",
      "[CV 4/5; 51/72] START classifier__C=10.0, classifier__gamma=0.01, pca=PCA(n_components=11)\n",
      "[CV 4/5; 51/72] END classifier__C=10.0, classifier__gamma=0.01, pca=PCA(n_components=11);, score=(train=0.918, test=0.905) total time=   0.1s\n",
      "[CV 5/5; 51/72] START classifier__C=10.0, classifier__gamma=0.01, pca=PCA(n_components=11)\n",
      "[CV 5/5; 51/72] END classifier__C=10.0, classifier__gamma=0.01, pca=PCA(n_components=11);, score=(train=0.916, test=0.914) total time=   0.1s\n",
      "[CV 1/5; 52/72] START classifier__C=10.0, classifier__gamma=0.01, pca=None......\n",
      "[CV 1/5; 52/72] END classifier__C=10.0, classifier__gamma=0.01, pca=None;, score=(train=0.957, test=0.925) total time=   0.1s\n",
      "[CV 2/5; 52/72] START classifier__C=10.0, classifier__gamma=0.01, pca=None......\n",
      "[CV 2/5; 52/72] END classifier__C=10.0, classifier__gamma=0.01, pca=None;, score=(train=0.956, test=0.946) total time=   0.1s\n",
      "[CV 3/5; 52/72] START classifier__C=10.0, classifier__gamma=0.01, pca=None......\n",
      "[CV 3/5; 52/72] END classifier__C=10.0, classifier__gamma=0.01, pca=None;, score=(train=0.952, test=0.932) total time=   0.1s\n",
      "[CV 4/5; 52/72] START classifier__C=10.0, classifier__gamma=0.01, pca=None......\n",
      "[CV 4/5; 52/72] END classifier__C=10.0, classifier__gamma=0.01, pca=None;, score=(train=0.956, test=0.917) total time=   0.1s\n",
      "[CV 5/5; 52/72] START classifier__C=10.0, classifier__gamma=0.01, pca=None......\n",
      "[CV 5/5; 52/72] END classifier__C=10.0, classifier__gamma=0.01, pca=None;, score=(train=0.956, test=0.932) total time=   0.1s\n",
      "[CV 1/5; 53/72] START classifier__C=10.0, classifier__gamma=0.1, pca=PCA(n_components=11)\n",
      "[CV 1/5; 53/72] END classifier__C=10.0, classifier__gamma=0.1, pca=PCA(n_components=11);, score=(train=0.947, test=0.897) total time=   0.1s\n",
      "[CV 2/5; 53/72] START classifier__C=10.0, classifier__gamma=0.1, pca=PCA(n_components=11)\n",
      "[CV 2/5; 53/72] END classifier__C=10.0, classifier__gamma=0.1, pca=PCA(n_components=11);, score=(train=0.943, test=0.916) total time=   0.1s\n",
      "[CV 3/5; 53/72] START classifier__C=10.0, classifier__gamma=0.1, pca=PCA(n_components=11)\n",
      "[CV 3/5; 53/72] END classifier__C=10.0, classifier__gamma=0.1, pca=PCA(n_components=11);, score=(train=0.940, test=0.920) total time=   0.1s\n",
      "[CV 4/5; 53/72] START classifier__C=10.0, classifier__gamma=0.1, pca=PCA(n_components=11)\n",
      "[CV 4/5; 53/72] END classifier__C=10.0, classifier__gamma=0.1, pca=PCA(n_components=11);, score=(train=0.952, test=0.902) total time=   0.1s\n",
      "[CV 5/5; 53/72] START classifier__C=10.0, classifier__gamma=0.1, pca=PCA(n_components=11)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 53/72] END classifier__C=10.0, classifier__gamma=0.1, pca=PCA(n_components=11);, score=(train=0.946, test=0.920) total time=   0.1s\n",
      "[CV 1/5; 54/72] START classifier__C=10.0, classifier__gamma=0.1, pca=None.......\n",
      "[CV 1/5; 54/72] END classifier__C=10.0, classifier__gamma=0.1, pca=None;, score=(train=0.989, test=0.902) total time=   0.4s\n",
      "[CV 2/5; 54/72] START classifier__C=10.0, classifier__gamma=0.1, pca=None.......\n",
      "[CV 2/5; 54/72] END classifier__C=10.0, classifier__gamma=0.1, pca=None;, score=(train=0.988, test=0.912) total time=   0.5s\n",
      "[CV 3/5; 54/72] START classifier__C=10.0, classifier__gamma=0.1, pca=None.......\n",
      "[CV 3/5; 54/72] END classifier__C=10.0, classifier__gamma=0.1, pca=None;, score=(train=0.987, test=0.910) total time=   0.4s\n",
      "[CV 4/5; 54/72] START classifier__C=10.0, classifier__gamma=0.1, pca=None.......\n",
      "[CV 4/5; 54/72] END classifier__C=10.0, classifier__gamma=0.1, pca=None;, score=(train=0.991, test=0.887) total time=   0.4s\n",
      "[CV 5/5; 54/72] START classifier__C=10.0, classifier__gamma=0.1, pca=None.......\n",
      "[CV 5/5; 54/72] END classifier__C=10.0, classifier__gamma=0.1, pca=None;, score=(train=0.989, test=0.891) total time=   0.5s\n",
      "[CV 1/5; 55/72] START classifier__C=10.0, classifier__gamma=1.0, pca=PCA(n_components=11)\n",
      "[CV 1/5; 55/72] END classifier__C=10.0, classifier__gamma=1.0, pca=PCA(n_components=11);, score=(train=0.991, test=0.865) total time=   0.4s\n",
      "[CV 2/5; 55/72] START classifier__C=10.0, classifier__gamma=1.0, pca=PCA(n_components=11)\n",
      "[CV 2/5; 55/72] END classifier__C=10.0, classifier__gamma=1.0, pca=PCA(n_components=11);, score=(train=0.986, test=0.890) total time=   0.4s\n",
      "[CV 3/5; 55/72] START classifier__C=10.0, classifier__gamma=1.0, pca=PCA(n_components=11)\n",
      "[CV 3/5; 55/72] END classifier__C=10.0, classifier__gamma=1.0, pca=PCA(n_components=11);, score=(train=0.988, test=0.890) total time=   0.4s\n",
      "[CV 4/5; 55/72] START classifier__C=10.0, classifier__gamma=1.0, pca=PCA(n_components=11)\n",
      "[CV 4/5; 55/72] END classifier__C=10.0, classifier__gamma=1.0, pca=PCA(n_components=11);, score=(train=0.988, test=0.857) total time=   0.4s\n",
      "[CV 5/5; 55/72] START classifier__C=10.0, classifier__gamma=1.0, pca=PCA(n_components=11)\n",
      "[CV 5/5; 55/72] END classifier__C=10.0, classifier__gamma=1.0, pca=PCA(n_components=11);, score=(train=0.992, test=0.887) total time=   0.5s\n",
      "[CV 1/5; 56/72] START classifier__C=10.0, classifier__gamma=1.0, pca=None.......\n",
      "[CV 1/5; 56/72] END classifier__C=10.0, classifier__gamma=1.0, pca=None;, score=(train=0.996, test=0.760) total time=   0.8s\n",
      "[CV 2/5; 56/72] START classifier__C=10.0, classifier__gamma=1.0, pca=None.......\n",
      "[CV 2/5; 56/72] END classifier__C=10.0, classifier__gamma=1.0, pca=None;, score=(train=0.996, test=0.750) total time=   0.7s\n",
      "[CV 3/5; 56/72] START classifier__C=10.0, classifier__gamma=1.0, pca=None.......\n",
      "[CV 3/5; 56/72] END classifier__C=10.0, classifier__gamma=1.0, pca=None;, score=(train=0.995, test=0.735) total time=   0.7s\n",
      "[CV 4/5; 56/72] START classifier__C=10.0, classifier__gamma=1.0, pca=None.......\n",
      "[CV 4/5; 56/72] END classifier__C=10.0, classifier__gamma=1.0, pca=None;, score=(train=0.997, test=0.732) total time=   0.7s\n",
      "[CV 5/5; 56/72] START classifier__C=10.0, classifier__gamma=1.0, pca=None.......\n",
      "[CV 5/5; 56/72] END classifier__C=10.0, classifier__gamma=1.0, pca=None;, score=(train=0.997, test=0.745) total time=   0.8s\n",
      "[CV 1/5; 57/72] START classifier__C=10.0, classifier__gamma=10.0, pca=PCA(n_components=11)\n",
      "[CV 1/5; 57/72] END classifier__C=10.0, classifier__gamma=10.0, pca=PCA(n_components=11);, score=(train=0.981, test=0.738) total time=   0.6s\n",
      "[CV 2/5; 57/72] START classifier__C=10.0, classifier__gamma=10.0, pca=PCA(n_components=11)\n",
      "[CV 2/5; 57/72] END classifier__C=10.0, classifier__gamma=10.0, pca=PCA(n_components=11);, score=(train=0.986, test=0.709) total time=   0.6s\n",
      "[CV 3/5; 57/72] START classifier__C=10.0, classifier__gamma=10.0, pca=PCA(n_components=11)\n",
      "[CV 3/5; 57/72] END classifier__C=10.0, classifier__gamma=10.0, pca=PCA(n_components=11);, score=(train=0.991, test=0.702) total time=   0.6s\n",
      "[CV 4/5; 57/72] START classifier__C=10.0, classifier__gamma=10.0, pca=PCA(n_components=11)\n",
      "[CV 4/5; 57/72] END classifier__C=10.0, classifier__gamma=10.0, pca=PCA(n_components=11);, score=(train=0.984, test=0.716) total time=   0.6s\n",
      "[CV 5/5; 57/72] START classifier__C=10.0, classifier__gamma=10.0, pca=PCA(n_components=11)\n",
      "[CV 5/5; 57/72] END classifier__C=10.0, classifier__gamma=10.0, pca=PCA(n_components=11);, score=(train=0.985, test=0.702) total time=   0.6s\n",
      "[CV 1/5; 58/72] START classifier__C=10.0, classifier__gamma=10.0, pca=None......\n",
      "[CV 1/5; 58/72] END classifier__C=10.0, classifier__gamma=10.0, pca=None;, score=(train=0.999, test=0.677) total time=   0.9s\n",
      "[CV 2/5; 58/72] START classifier__C=10.0, classifier__gamma=10.0, pca=None......\n",
      "[CV 2/5; 58/72] END classifier__C=10.0, classifier__gamma=10.0, pca=None;, score=(train=0.999, test=0.662) total time=   0.9s\n",
      "[CV 3/5; 58/72] START classifier__C=10.0, classifier__gamma=10.0, pca=None......\n",
      "[CV 3/5; 58/72] END classifier__C=10.0, classifier__gamma=10.0, pca=None;, score=(train=0.998, test=0.675) total time=   0.9s\n",
      "[CV 4/5; 58/72] START classifier__C=10.0, classifier__gamma=10.0, pca=None......\n",
      "[CV 4/5; 58/72] END classifier__C=10.0, classifier__gamma=10.0, pca=None;, score=(train=0.998, test=0.667) total time=   0.9s\n",
      "[CV 5/5; 58/72] START classifier__C=10.0, classifier__gamma=10.0, pca=None......\n",
      "[CV 5/5; 58/72] END classifier__C=10.0, classifier__gamma=10.0, pca=None;, score=(train=0.999, test=0.671) total time=   0.9s\n",
      "[CV 1/5; 59/72] START classifier__C=10.0, classifier__gamma=100.0, pca=PCA(n_components=11)\n",
      "[CV 1/5; 59/72] END classifier__C=10.0, classifier__gamma=100.0, pca=PCA(n_components=11);, score=(train=0.766, test=0.620) total time=   0.9s\n",
      "[CV 2/5; 59/72] START classifier__C=10.0, classifier__gamma=100.0, pca=PCA(n_components=11)\n",
      "[CV 2/5; 59/72] END classifier__C=10.0, classifier__gamma=100.0, pca=PCA(n_components=11);, score=(train=0.794, test=0.626) total time=   0.8s\n",
      "[CV 3/5; 59/72] START classifier__C=10.0, classifier__gamma=100.0, pca=PCA(n_components=11)\n",
      "[CV 3/5; 59/72] END classifier__C=10.0, classifier__gamma=100.0, pca=PCA(n_components=11);, score=(train=0.796, test=0.628) total time=   0.9s\n",
      "[CV 4/5; 59/72] START classifier__C=10.0, classifier__gamma=100.0, pca=PCA(n_components=11)\n",
      "[CV 4/5; 59/72] END classifier__C=10.0, classifier__gamma=100.0, pca=PCA(n_components=11);, score=(train=0.821, test=0.628) total time=   0.9s\n",
      "[CV 5/5; 59/72] START classifier__C=10.0, classifier__gamma=100.0, pca=PCA(n_components=11)\n",
      "[CV 5/5; 59/72] END classifier__C=10.0, classifier__gamma=100.0, pca=PCA(n_components=11);, score=(train=0.794, test=0.626) total time=   0.9s\n",
      "[CV 1/5; 60/72] START classifier__C=10.0, classifier__gamma=100.0, pca=None.....\n",
      "[CV 1/5; 60/72] END classifier__C=10.0, classifier__gamma=100.0, pca=None;, score=(train=1.000, test=0.632) total time=   1.1s\n",
      "[CV 2/5; 60/72] START classifier__C=10.0, classifier__gamma=100.0, pca=None.....\n",
      "[CV 2/5; 60/72] END classifier__C=10.0, classifier__gamma=100.0, pca=None;, score=(train=0.999, test=0.632) total time=   1.1s\n",
      "[CV 3/5; 60/72] START classifier__C=10.0, classifier__gamma=100.0, pca=None.....\n",
      "[CV 3/5; 60/72] END classifier__C=10.0, classifier__gamma=100.0, pca=None;, score=(train=0.999, test=0.628) total time=   1.1s\n",
      "[CV 4/5; 60/72] START classifier__C=10.0, classifier__gamma=100.0, pca=None.....\n",
      "[CV 4/5; 60/72] END classifier__C=10.0, classifier__gamma=100.0, pca=None;, score=(train=0.999, test=0.639) total time=   1.1s\n",
      "[CV 5/5; 60/72] START classifier__C=10.0, classifier__gamma=100.0, pca=None.....\n",
      "[CV 5/5; 60/72] END classifier__C=10.0, classifier__gamma=100.0, pca=None;, score=(train=0.999, test=0.630) total time=   1.1s\n",
      "[CV 1/5; 61/72] START classifier__C=100.0, classifier__gamma=0.001, pca=PCA(n_components=11)\n",
      "[CV 1/5; 61/72] END classifier__C=100.0, classifier__gamma=0.001, pca=PCA(n_components=11);, score=(train=0.907, test=0.890) total time=   0.1s\n",
      "[CV 2/5; 61/72] START classifier__C=100.0, classifier__gamma=0.001, pca=PCA(n_components=11)\n",
      "[CV 2/5; 61/72] END classifier__C=100.0, classifier__gamma=0.001, pca=PCA(n_components=11);, score=(train=0.903, test=0.902) total time=   0.1s\n",
      "[CV 3/5; 61/72] START classifier__C=100.0, classifier__gamma=0.001, pca=PCA(n_components=11)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 61/72] END classifier__C=100.0, classifier__gamma=0.001, pca=PCA(n_components=11);, score=(train=0.912, test=0.913) total time=   0.1s\n",
      "[CV 4/5; 61/72] START classifier__C=100.0, classifier__gamma=0.001, pca=PCA(n_components=11)\n",
      "[CV 4/5; 61/72] END classifier__C=100.0, classifier__gamma=0.001, pca=PCA(n_components=11);, score=(train=0.912, test=0.905) total time=   0.1s\n",
      "[CV 5/5; 61/72] START classifier__C=100.0, classifier__gamma=0.001, pca=PCA(n_components=11)\n",
      "[CV 5/5; 61/72] END classifier__C=100.0, classifier__gamma=0.001, pca=PCA(n_components=11);, score=(train=0.916, test=0.918) total time=   0.1s\n",
      "[CV 1/5; 62/72] START classifier__C=100.0, classifier__gamma=0.001, pca=None....\n",
      "[CV 1/5; 62/72] END classifier__C=100.0, classifier__gamma=0.001, pca=None;, score=(train=0.943, test=0.917) total time=   0.1s\n",
      "[CV 2/5; 62/72] START classifier__C=100.0, classifier__gamma=0.001, pca=None....\n",
      "[CV 2/5; 62/72] END classifier__C=100.0, classifier__gamma=0.001, pca=None;, score=(train=0.942, test=0.942) total time=   0.2s\n",
      "[CV 3/5; 62/72] START classifier__C=100.0, classifier__gamma=0.001, pca=None....\n",
      "[CV 3/5; 62/72] END classifier__C=100.0, classifier__gamma=0.001, pca=None;, score=(train=0.939, test=0.936) total time=   0.1s\n",
      "[CV 4/5; 62/72] START classifier__C=100.0, classifier__gamma=0.001, pca=None....\n",
      "[CV 4/5; 62/72] END classifier__C=100.0, classifier__gamma=0.001, pca=None;, score=(train=0.946, test=0.927) total time=   0.1s\n",
      "[CV 5/5; 62/72] START classifier__C=100.0, classifier__gamma=0.001, pca=None....\n",
      "[CV 5/5; 62/72] END classifier__C=100.0, classifier__gamma=0.001, pca=None;, score=(train=0.944, test=0.931) total time=   0.1s\n",
      "[CV 1/5; 63/72] START classifier__C=100.0, classifier__gamma=0.01, pca=PCA(n_components=11)\n",
      "[CV 1/5; 63/72] END classifier__C=100.0, classifier__gamma=0.01, pca=PCA(n_components=11);, score=(train=0.931, test=0.895) total time=   0.1s\n",
      "[CV 2/5; 63/72] START classifier__C=100.0, classifier__gamma=0.01, pca=PCA(n_components=11)\n",
      "[CV 2/5; 63/72] END classifier__C=100.0, classifier__gamma=0.01, pca=PCA(n_components=11);, score=(train=0.920, test=0.914) total time=   0.1s\n",
      "[CV 3/5; 63/72] START classifier__C=100.0, classifier__gamma=0.01, pca=PCA(n_components=11)\n",
      "[CV 3/5; 63/72] END classifier__C=100.0, classifier__gamma=0.01, pca=PCA(n_components=11);, score=(train=0.926, test=0.921) total time=   0.1s\n",
      "[CV 4/5; 63/72] START classifier__C=100.0, classifier__gamma=0.01, pca=PCA(n_components=11)\n",
      "[CV 4/5; 63/72] END classifier__C=100.0, classifier__gamma=0.01, pca=PCA(n_components=11);, score=(train=0.930, test=0.905) total time=   0.1s\n",
      "[CV 5/5; 63/72] START classifier__C=100.0, classifier__gamma=0.01, pca=PCA(n_components=11)\n",
      "[CV 5/5; 63/72] END classifier__C=100.0, classifier__gamma=0.01, pca=PCA(n_components=11);, score=(train=0.926, test=0.921) total time=   0.2s\n",
      "[CV 1/5; 64/72] START classifier__C=100.0, classifier__gamma=0.01, pca=None.....\n",
      "[CV 1/5; 64/72] END classifier__C=100.0, classifier__gamma=0.01, pca=None;, score=(train=0.973, test=0.914) total time=   0.2s\n",
      "[CV 2/5; 64/72] START classifier__C=100.0, classifier__gamma=0.01, pca=None.....\n",
      "[CV 2/5; 64/72] END classifier__C=100.0, classifier__gamma=0.01, pca=None;, score=(train=0.972, test=0.928) total time=   0.2s\n",
      "[CV 3/5; 64/72] START classifier__C=100.0, classifier__gamma=0.01, pca=None.....\n",
      "[CV 3/5; 64/72] END classifier__C=100.0, classifier__gamma=0.01, pca=None;, score=(train=0.970, test=0.927) total time=   0.2s\n",
      "[CV 4/5; 64/72] START classifier__C=100.0, classifier__gamma=0.01, pca=None.....\n",
      "[CV 4/5; 64/72] END classifier__C=100.0, classifier__gamma=0.01, pca=None;, score=(train=0.977, test=0.901) total time=   0.2s\n",
      "[CV 5/5; 64/72] START classifier__C=100.0, classifier__gamma=0.01, pca=None.....\n",
      "[CV 5/5; 64/72] END classifier__C=100.0, classifier__gamma=0.01, pca=None;, score=(train=0.971, test=0.910) total time=   0.2s\n",
      "[CV 1/5; 65/72] START classifier__C=100.0, classifier__gamma=0.1, pca=PCA(n_components=11)\n",
      "[CV 1/5; 65/72] END classifier__C=100.0, classifier__gamma=0.1, pca=PCA(n_components=11);, score=(train=0.964, test=0.891) total time=   0.3s\n",
      "[CV 2/5; 65/72] START classifier__C=100.0, classifier__gamma=0.1, pca=PCA(n_components=11)\n",
      "[CV 2/5; 65/72] END classifier__C=100.0, classifier__gamma=0.1, pca=PCA(n_components=11);, score=(train=0.960, test=0.914) total time=   0.2s\n",
      "[CV 3/5; 65/72] START classifier__C=100.0, classifier__gamma=0.1, pca=PCA(n_components=11)\n",
      "[CV 3/5; 65/72] END classifier__C=100.0, classifier__gamma=0.1, pca=PCA(n_components=11);, score=(train=0.962, test=0.932) total time=   0.2s\n",
      "[CV 4/5; 65/72] START classifier__C=100.0, classifier__gamma=0.1, pca=PCA(n_components=11)\n",
      "[CV 4/5; 65/72] END classifier__C=100.0, classifier__gamma=0.1, pca=PCA(n_components=11);, score=(train=0.962, test=0.890) total time=   0.2s\n",
      "[CV 5/5; 65/72] START classifier__C=100.0, classifier__gamma=0.1, pca=PCA(n_components=11)\n",
      "[CV 5/5; 65/72] END classifier__C=100.0, classifier__gamma=0.1, pca=PCA(n_components=11);, score=(train=0.959, test=0.904) total time=   0.2s\n",
      "[CV 1/5; 66/72] START classifier__C=100.0, classifier__gamma=0.1, pca=None......\n",
      "[CV 1/5; 66/72] END classifier__C=100.0, classifier__gamma=0.1, pca=None;, score=(train=0.995, test=0.895) total time=   0.4s\n",
      "[CV 2/5; 66/72] START classifier__C=100.0, classifier__gamma=0.1, pca=None......\n",
      "[CV 2/5; 66/72] END classifier__C=100.0, classifier__gamma=0.1, pca=None;, score=(train=0.994, test=0.918) total time=   0.6s\n",
      "[CV 3/5; 66/72] START classifier__C=100.0, classifier__gamma=0.1, pca=None......\n",
      "[CV 3/5; 66/72] END classifier__C=100.0, classifier__gamma=0.1, pca=None;, score=(train=0.994, test=0.895) total time=   0.4s\n",
      "[CV 4/5; 66/72] START classifier__C=100.0, classifier__gamma=0.1, pca=None......\n",
      "[CV 4/5; 66/72] END classifier__C=100.0, classifier__gamma=0.1, pca=None;, score=(train=0.995, test=0.878) total time=   0.4s\n",
      "[CV 5/5; 66/72] START classifier__C=100.0, classifier__gamma=0.1, pca=None......\n",
      "[CV 5/5; 66/72] END classifier__C=100.0, classifier__gamma=0.1, pca=None;, score=(train=0.995, test=0.898) total time=   0.6s\n",
      "[CV 1/5; 67/72] START classifier__C=100.0, classifier__gamma=1.0, pca=PCA(n_components=11)\n",
      "[CV 1/5; 67/72] END classifier__C=100.0, classifier__gamma=1.0, pca=PCA(n_components=11);, score=(train=0.993, test=0.876) total time=   0.5s\n",
      "[CV 2/5; 67/72] START classifier__C=100.0, classifier__gamma=1.0, pca=PCA(n_components=11)\n",
      "[CV 2/5; 67/72] END classifier__C=100.0, classifier__gamma=1.0, pca=PCA(n_components=11);, score=(train=0.994, test=0.880) total time=   0.5s\n",
      "[CV 3/5; 67/72] START classifier__C=100.0, classifier__gamma=1.0, pca=PCA(n_components=11)\n",
      "[CV 3/5; 67/72] END classifier__C=100.0, classifier__gamma=1.0, pca=PCA(n_components=11);, score=(train=0.993, test=0.893) total time=   0.6s\n",
      "[CV 4/5; 67/72] START classifier__C=100.0, classifier__gamma=1.0, pca=PCA(n_components=11)\n",
      "[CV 4/5; 67/72] END classifier__C=100.0, classifier__gamma=1.0, pca=PCA(n_components=11);, score=(train=0.994, test=0.857) total time=   0.5s\n",
      "[CV 5/5; 67/72] START classifier__C=100.0, classifier__gamma=1.0, pca=PCA(n_components=11)\n",
      "[CV 5/5; 67/72] END classifier__C=100.0, classifier__gamma=1.0, pca=PCA(n_components=11);, score=(train=0.995, test=0.880) total time=   0.5s\n",
      "[CV 1/5; 68/72] START classifier__C=100.0, classifier__gamma=1.0, pca=None......\n",
      "[CV 1/5; 68/72] END classifier__C=100.0, classifier__gamma=1.0, pca=None;, score=(train=0.999, test=0.760) total time=   0.7s\n",
      "[CV 2/5; 68/72] START classifier__C=100.0, classifier__gamma=1.0, pca=None......\n",
      "[CV 2/5; 68/72] END classifier__C=100.0, classifier__gamma=1.0, pca=None;, score=(train=0.998, test=0.749) total time=   0.7s\n",
      "[CV 3/5; 68/72] START classifier__C=100.0, classifier__gamma=1.0, pca=None......\n",
      "[CV 3/5; 68/72] END classifier__C=100.0, classifier__gamma=1.0, pca=None;, score=(train=0.998, test=0.728) total time=   0.8s\n",
      "[CV 4/5; 68/72] START classifier__C=100.0, classifier__gamma=1.0, pca=None......\n",
      "[CV 4/5; 68/72] END classifier__C=100.0, classifier__gamma=1.0, pca=None;, score=(train=0.999, test=0.727) total time=   0.7s\n",
      "[CV 5/5; 68/72] START classifier__C=100.0, classifier__gamma=1.0, pca=None......\n",
      "[CV 5/5; 68/72] END classifier__C=100.0, classifier__gamma=1.0, pca=None;, score=(train=0.999, test=0.743) total time=   0.7s\n",
      "[CV 1/5; 69/72] START classifier__C=100.0, classifier__gamma=10.0, pca=PCA(n_components=11)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 69/72] END classifier__C=100.0, classifier__gamma=10.0, pca=PCA(n_components=11);, score=(train=0.989, test=0.730) total time=   0.6s\n",
      "[CV 2/5; 69/72] START classifier__C=100.0, classifier__gamma=10.0, pca=PCA(n_components=11)\n",
      "[CV 2/5; 69/72] END classifier__C=100.0, classifier__gamma=10.0, pca=PCA(n_components=11);, score=(train=0.986, test=0.702) total time=   0.6s\n",
      "[CV 3/5; 69/72] START classifier__C=100.0, classifier__gamma=10.0, pca=PCA(n_components=11)\n",
      "[CV 3/5; 69/72] END classifier__C=100.0, classifier__gamma=10.0, pca=PCA(n_components=11);, score=(train=0.986, test=0.708) total time=   0.6s\n",
      "[CV 4/5; 69/72] START classifier__C=100.0, classifier__gamma=10.0, pca=PCA(n_components=11)\n",
      "[CV 4/5; 69/72] END classifier__C=100.0, classifier__gamma=10.0, pca=PCA(n_components=11);, score=(train=0.981, test=0.709) total time=   0.6s\n",
      "[CV 5/5; 69/72] START classifier__C=100.0, classifier__gamma=10.0, pca=PCA(n_components=11)\n",
      "[CV 5/5; 69/72] END classifier__C=100.0, classifier__gamma=10.0, pca=PCA(n_components=11);, score=(train=0.990, test=0.709) total time=   0.7s\n",
      "[CV 1/5; 70/72] START classifier__C=100.0, classifier__gamma=10.0, pca=None.....\n",
      "[CV 1/5; 70/72] END classifier__C=100.0, classifier__gamma=10.0, pca=None;, score=(train=0.999, test=0.677) total time=   0.9s\n",
      "[CV 2/5; 70/72] START classifier__C=100.0, classifier__gamma=10.0, pca=None.....\n",
      "[CV 2/5; 70/72] END classifier__C=100.0, classifier__gamma=10.0, pca=None;, score=(train=0.999, test=0.662) total time=   1.0s\n",
      "[CV 3/5; 70/72] START classifier__C=100.0, classifier__gamma=10.0, pca=None.....\n",
      "[CV 3/5; 70/72] END classifier__C=100.0, classifier__gamma=10.0, pca=None;, score=(train=0.999, test=0.671) total time=   0.9s\n",
      "[CV 4/5; 70/72] START classifier__C=100.0, classifier__gamma=10.0, pca=None.....\n",
      "[CV 4/5; 70/72] END classifier__C=100.0, classifier__gamma=10.0, pca=None;, score=(train=0.999, test=0.666) total time=   1.1s\n",
      "[CV 5/5; 70/72] START classifier__C=100.0, classifier__gamma=10.0, pca=None.....\n",
      "[CV 5/5; 70/72] END classifier__C=100.0, classifier__gamma=10.0, pca=None;, score=(train=0.999, test=0.671) total time=   0.9s\n",
      "[CV 1/5; 71/72] START classifier__C=100.0, classifier__gamma=100.0, pca=PCA(n_components=11)\n",
      "[CV 1/5; 71/72] END classifier__C=100.0, classifier__gamma=100.0, pca=PCA(n_components=11);, score=(train=0.805, test=0.601) total time=   0.8s\n",
      "[CV 2/5; 71/72] START classifier__C=100.0, classifier__gamma=100.0, pca=PCA(n_components=11)\n",
      "[CV 2/5; 71/72] END classifier__C=100.0, classifier__gamma=100.0, pca=PCA(n_components=11);, score=(train=0.818, test=0.625) total time=   0.8s\n",
      "[CV 3/5; 71/72] START classifier__C=100.0, classifier__gamma=100.0, pca=PCA(n_components=11)\n",
      "[CV 3/5; 71/72] END classifier__C=100.0, classifier__gamma=100.0, pca=PCA(n_components=11);, score=(train=0.795, test=0.625) total time=   0.8s\n",
      "[CV 4/5; 71/72] START classifier__C=100.0, classifier__gamma=100.0, pca=PCA(n_components=11)\n",
      "[CV 4/5; 71/72] END classifier__C=100.0, classifier__gamma=100.0, pca=PCA(n_components=11);, score=(train=0.771, test=0.620) total time=   1.0s\n",
      "[CV 5/5; 71/72] START classifier__C=100.0, classifier__gamma=100.0, pca=PCA(n_components=11)\n",
      "[CV 5/5; 71/72] END classifier__C=100.0, classifier__gamma=100.0, pca=PCA(n_components=11);, score=(train=0.836, test=0.629) total time=   0.8s\n",
      "[CV 1/5; 72/72] START classifier__C=100.0, classifier__gamma=100.0, pca=None....\n",
      "[CV 1/5; 72/72] END classifier__C=100.0, classifier__gamma=100.0, pca=None;, score=(train=1.000, test=0.632) total time=   1.1s\n",
      "[CV 2/5; 72/72] START classifier__C=100.0, classifier__gamma=100.0, pca=None....\n",
      "[CV 2/5; 72/72] END classifier__C=100.0, classifier__gamma=100.0, pca=None;, score=(train=0.999, test=0.632) total time=   1.1s\n",
      "[CV 3/5; 72/72] START classifier__C=100.0, classifier__gamma=100.0, pca=None....\n",
      "[CV 3/5; 72/72] END classifier__C=100.0, classifier__gamma=100.0, pca=None;, score=(train=0.999, test=0.628) total time=   1.0s\n",
      "[CV 4/5; 72/72] START classifier__C=100.0, classifier__gamma=100.0, pca=None....\n",
      "[CV 4/5; 72/72] END classifier__C=100.0, classifier__gamma=100.0, pca=None;, score=(train=0.999, test=0.639) total time=   1.0s\n",
      "[CV 5/5; 72/72] START classifier__C=100.0, classifier__gamma=100.0, pca=None....\n",
      "[CV 5/5; 72/72] END classifier__C=100.0, classifier__gamma=100.0, pca=None;, score=(train=0.999, test=0.629) total time=   1.1s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'classifier__C': 10.0, 'classifier__gamma': 0.01, 'pca': None}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('preprocessing', final_pipeline), \n",
    "    ('pca', PCA(11)),\n",
    "    ('classifier', SVC(kernel='rbf'))\n",
    "])\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=5, random_state=seed, shuffle=True)\n",
    "\n",
    "param_grid = {\n",
    "            'pca': [PCA(11), None],\n",
    "            'classifier__gamma': [0.001, 0.01, 0.1, 1., 10., 100.],\n",
    "            'classifier__C': [0.001, 0.01, 0.1, 1., 10., 100.],\n",
    "}\n",
    "\n",
    "\n",
    "grid_1 = GridSearchCV(pipe, param_grid, cv=kfold, return_train_score=True, verbose=10)\n",
    "\n",
    "grid_1.fit(X_train, y_train)\n",
    "grid_1.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9f7a5d20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'classifier__C': 0.001,\n",
       "  'classifier__gamma': 0.001,\n",
       "  'pca': PCA(n_components=11)},\n",
       " {'classifier__C': 0.001, 'classifier__gamma': 0.001, 'pca': None},\n",
       " {'classifier__C': 0.001,\n",
       "  'classifier__gamma': 0.01,\n",
       "  'pca': PCA(n_components=11)},\n",
       " {'classifier__C': 0.001, 'classifier__gamma': 0.01, 'pca': None},\n",
       " {'classifier__C': 0.001,\n",
       "  'classifier__gamma': 0.1,\n",
       "  'pca': PCA(n_components=11)},\n",
       " {'classifier__C': 0.001, 'classifier__gamma': 0.1, 'pca': None},\n",
       " {'classifier__C': 0.001,\n",
       "  'classifier__gamma': 1.0,\n",
       "  'pca': PCA(n_components=11)},\n",
       " {'classifier__C': 0.001, 'classifier__gamma': 1.0, 'pca': None},\n",
       " {'classifier__C': 0.001,\n",
       "  'classifier__gamma': 10.0,\n",
       "  'pca': PCA(n_components=11)},\n",
       " {'classifier__C': 0.001, 'classifier__gamma': 10.0, 'pca': None},\n",
       " {'classifier__C': 0.001,\n",
       "  'classifier__gamma': 100.0,\n",
       "  'pca': PCA(n_components=11)},\n",
       " {'classifier__C': 0.001, 'classifier__gamma': 100.0, 'pca': None},\n",
       " {'classifier__C': 0.01,\n",
       "  'classifier__gamma': 0.001,\n",
       "  'pca': PCA(n_components=11)},\n",
       " {'classifier__C': 0.01, 'classifier__gamma': 0.001, 'pca': None},\n",
       " {'classifier__C': 0.01,\n",
       "  'classifier__gamma': 0.01,\n",
       "  'pca': PCA(n_components=11)},\n",
       " {'classifier__C': 0.01, 'classifier__gamma': 0.01, 'pca': None},\n",
       " {'classifier__C': 0.01,\n",
       "  'classifier__gamma': 0.1,\n",
       "  'pca': PCA(n_components=11)},\n",
       " {'classifier__C': 0.01, 'classifier__gamma': 0.1, 'pca': None},\n",
       " {'classifier__C': 0.01,\n",
       "  'classifier__gamma': 1.0,\n",
       "  'pca': PCA(n_components=11)},\n",
       " {'classifier__C': 0.01, 'classifier__gamma': 1.0, 'pca': None},\n",
       " {'classifier__C': 0.01,\n",
       "  'classifier__gamma': 10.0,\n",
       "  'pca': PCA(n_components=11)},\n",
       " {'classifier__C': 0.01, 'classifier__gamma': 10.0, 'pca': None},\n",
       " {'classifier__C': 0.01,\n",
       "  'classifier__gamma': 100.0,\n",
       "  'pca': PCA(n_components=11)},\n",
       " {'classifier__C': 0.01, 'classifier__gamma': 100.0, 'pca': None},\n",
       " {'classifier__C': 0.1,\n",
       "  'classifier__gamma': 0.001,\n",
       "  'pca': PCA(n_components=11)},\n",
       " {'classifier__C': 0.1, 'classifier__gamma': 0.001, 'pca': None},\n",
       " {'classifier__C': 0.1,\n",
       "  'classifier__gamma': 0.01,\n",
       "  'pca': PCA(n_components=11)},\n",
       " {'classifier__C': 0.1, 'classifier__gamma': 0.01, 'pca': None},\n",
       " {'classifier__C': 0.1, 'classifier__gamma': 0.1, 'pca': PCA(n_components=11)},\n",
       " {'classifier__C': 0.1, 'classifier__gamma': 0.1, 'pca': None},\n",
       " {'classifier__C': 0.1, 'classifier__gamma': 1.0, 'pca': PCA(n_components=11)},\n",
       " {'classifier__C': 0.1, 'classifier__gamma': 1.0, 'pca': None},\n",
       " {'classifier__C': 0.1,\n",
       "  'classifier__gamma': 10.0,\n",
       "  'pca': PCA(n_components=11)},\n",
       " {'classifier__C': 0.1, 'classifier__gamma': 10.0, 'pca': None},\n",
       " {'classifier__C': 0.1,\n",
       "  'classifier__gamma': 100.0,\n",
       "  'pca': PCA(n_components=11)},\n",
       " {'classifier__C': 0.1, 'classifier__gamma': 100.0, 'pca': None},\n",
       " {'classifier__C': 1.0,\n",
       "  'classifier__gamma': 0.001,\n",
       "  'pca': PCA(n_components=11)},\n",
       " {'classifier__C': 1.0, 'classifier__gamma': 0.001, 'pca': None},\n",
       " {'classifier__C': 1.0,\n",
       "  'classifier__gamma': 0.01,\n",
       "  'pca': PCA(n_components=11)},\n",
       " {'classifier__C': 1.0, 'classifier__gamma': 0.01, 'pca': None},\n",
       " {'classifier__C': 1.0, 'classifier__gamma': 0.1, 'pca': PCA(n_components=11)},\n",
       " {'classifier__C': 1.0, 'classifier__gamma': 0.1, 'pca': None},\n",
       " {'classifier__C': 1.0, 'classifier__gamma': 1.0, 'pca': PCA(n_components=11)},\n",
       " {'classifier__C': 1.0, 'classifier__gamma': 1.0, 'pca': None},\n",
       " {'classifier__C': 1.0,\n",
       "  'classifier__gamma': 10.0,\n",
       "  'pca': PCA(n_components=11)},\n",
       " {'classifier__C': 1.0, 'classifier__gamma': 10.0, 'pca': None},\n",
       " {'classifier__C': 1.0,\n",
       "  'classifier__gamma': 100.0,\n",
       "  'pca': PCA(n_components=11)},\n",
       " {'classifier__C': 1.0, 'classifier__gamma': 100.0, 'pca': None},\n",
       " {'classifier__C': 10.0,\n",
       "  'classifier__gamma': 0.001,\n",
       "  'pca': PCA(n_components=11)},\n",
       " {'classifier__C': 10.0, 'classifier__gamma': 0.001, 'pca': None},\n",
       " {'classifier__C': 10.0,\n",
       "  'classifier__gamma': 0.01,\n",
       "  'pca': PCA(n_components=11)},\n",
       " {'classifier__C': 10.0, 'classifier__gamma': 0.01, 'pca': None},\n",
       " {'classifier__C': 10.0,\n",
       "  'classifier__gamma': 0.1,\n",
       "  'pca': PCA(n_components=11)},\n",
       " {'classifier__C': 10.0, 'classifier__gamma': 0.1, 'pca': None},\n",
       " {'classifier__C': 10.0,\n",
       "  'classifier__gamma': 1.0,\n",
       "  'pca': PCA(n_components=11)},\n",
       " {'classifier__C': 10.0, 'classifier__gamma': 1.0, 'pca': None},\n",
       " {'classifier__C': 10.0,\n",
       "  'classifier__gamma': 10.0,\n",
       "  'pca': PCA(n_components=11)},\n",
       " {'classifier__C': 10.0, 'classifier__gamma': 10.0, 'pca': None},\n",
       " {'classifier__C': 10.0,\n",
       "  'classifier__gamma': 100.0,\n",
       "  'pca': PCA(n_components=11)},\n",
       " {'classifier__C': 10.0, 'classifier__gamma': 100.0, 'pca': None},\n",
       " {'classifier__C': 100.0,\n",
       "  'classifier__gamma': 0.001,\n",
       "  'pca': PCA(n_components=11)},\n",
       " {'classifier__C': 100.0, 'classifier__gamma': 0.001, 'pca': None},\n",
       " {'classifier__C': 100.0,\n",
       "  'classifier__gamma': 0.01,\n",
       "  'pca': PCA(n_components=11)},\n",
       " {'classifier__C': 100.0, 'classifier__gamma': 0.01, 'pca': None},\n",
       " {'classifier__C': 100.0,\n",
       "  'classifier__gamma': 0.1,\n",
       "  'pca': PCA(n_components=11)},\n",
       " {'classifier__C': 100.0, 'classifier__gamma': 0.1, 'pca': None},\n",
       " {'classifier__C': 100.0,\n",
       "  'classifier__gamma': 1.0,\n",
       "  'pca': PCA(n_components=11)},\n",
       " {'classifier__C': 100.0, 'classifier__gamma': 1.0, 'pca': None},\n",
       " {'classifier__C': 100.0,\n",
       "  'classifier__gamma': 10.0,\n",
       "  'pca': PCA(n_components=11)},\n",
       " {'classifier__C': 100.0, 'classifier__gamma': 10.0, 'pca': None},\n",
       " {'classifier__C': 100.0,\n",
       "  'classifier__gamma': 100.0,\n",
       "  'pca': PCA(n_components=11)},\n",
       " {'classifier__C': 100.0, 'classifier__gamma': 100.0, 'pca': None}]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_1.cv_results_['params'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e4f6b297",
   "metadata": {},
   "outputs": [],
   "source": [
    "def heatmap(values, xlabel, ylabel, xticklabels, yticklabels, cmap=None,\n",
    "            vmin=None, vmax=None, ax=None, fmt=\"%0.2f\"):\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "    # plot the mean cross-validation scores\n",
    "    img = ax.pcolor(values, cmap=cmap, vmin=vmin, vmax=vmax)\n",
    "    img.update_scalarmappable()\n",
    "    ax.set_xlabel(xlabel)\n",
    "    ax.set_ylabel(ylabel)\n",
    "    ax.set_xticks(np.arange(len(xticklabels)) + .5)\n",
    "    ax.set_yticks(np.arange(len(yticklabels)) + .5)\n",
    "    ax.set_xticklabels(xticklabels)\n",
    "    ax.set_yticklabels(yticklabels)\n",
    "    ax.set_aspect(1)\n",
    "\n",
    "    for p, color, value in zip(img.get_paths(), img.get_facecolors(),\n",
    "                               img.get_array()):\n",
    "        x, y = p.vertices[:-2, :].mean(0)\n",
    "        if np.mean(color[:3]) > 0.5:\n",
    "            c = 'k'\n",
    "        else:\n",
    "            c = 'w'\n",
    "        ax.text(x, y, fmt % value, color=c, ha=\"center\", va=\"center\")\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "85fad81c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scores = np.array(grid_1.cv_results_['mean_test_score']).reshape(6, 6, 2)\n",
    "scores = scores[:, :, 0]\n",
    "heatmap(scores, xlabel='classifier__gamma', xticklabels=param_grid['classifier__gamma'], ylabel='classifier__C', yticklabels=param_grid['classifier__C'], cmap=\"viridis\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "984253e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scores = np.array(grid_1.cv_results_['mean_test_score']).reshape(6, 6, 2)\n",
    "scores = scores[:, :, 1]\n",
    "heatmap(scores, xlabel='classifier__gamma', xticklabels=param_grid['classifier__gamma'], ylabel='classifier__C', yticklabels=param_grid['classifier__C'], cmap=\"viridis\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fe802249",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "def print_metrics(model, X_test, y_test):\n",
    "    print(\"precision_score: {}\".format(metrics.precision_score(y_test, model.predict(X_test)) ))\n",
    "    print(\"recall_score: {}\".format( metrics.recall_score(y_test, model.predict(X_test)) ))\n",
    "    print(\"f1_score: {}\".format( metrics.f1_score(y_test, model.predict(X_test)) ))\n",
    "    print(\"accuracy_score: {}\".format( metrics.accuracy_score(y_test, model.predict(X_test)) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8788fd64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision_score: 0.9169054441260746\n",
      "recall_score: 0.8815426997245179\n",
      "f1_score: 0.8988764044943821\n",
      "accuracy_score: 0.9218241042345277\n"
     ]
    }
   ],
   "source": [
    "print_metrics(grid_1.best_estimator_, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e0572a",
   "metadata": {},
   "source": [
    "## Drugi model - XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "833ff90c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "[CV 1/5; 1/30] START classifier__colsample_bytree=0.6958432427421151, classifier__gamma=0.4939271691878614, classifier__learning_rate=0.050470016031382264, classifier__max_depth=6, classifier__min_child_weight=5, classifier__n_estimators=301, classifier__subsample=0.7174727068901876\n",
      "[CV 1/5; 1/30] END classifier__colsample_bytree=0.6958432427421151, classifier__gamma=0.4939271691878614, classifier__learning_rate=0.050470016031382264, classifier__max_depth=6, classifier__min_child_weight=5, classifier__n_estimators=301, classifier__subsample=0.7174727068901876;, score=(train=0.955, test=0.906) total time=   0.4s\n",
      "[CV 2/5; 1/30] START classifier__colsample_bytree=0.6958432427421151, classifier__gamma=0.4939271691878614, classifier__learning_rate=0.050470016031382264, classifier__max_depth=6, classifier__min_child_weight=5, classifier__n_estimators=301, classifier__subsample=0.7174727068901876\n",
      "[CV 2/5; 1/30] END classifier__colsample_bytree=0.6958432427421151, classifier__gamma=0.4939271691878614, classifier__learning_rate=0.050470016031382264, classifier__max_depth=6, classifier__min_child_weight=5, classifier__n_estimators=301, classifier__subsample=0.7174727068901876;, score=(train=0.953, test=0.913) total time=   0.4s\n",
      "[CV 3/5; 1/30] START classifier__colsample_bytree=0.6958432427421151, classifier__gamma=0.4939271691878614, classifier__learning_rate=0.050470016031382264, classifier__max_depth=6, classifier__min_child_weight=5, classifier__n_estimators=301, classifier__subsample=0.7174727068901876\n",
      "[CV 3/5; 1/30] END classifier__colsample_bytree=0.6958432427421151, classifier__gamma=0.4939271691878614, classifier__learning_rate=0.050470016031382264, classifier__max_depth=6, classifier__min_child_weight=5, classifier__n_estimators=301, classifier__subsample=0.7174727068901876;, score=(train=0.956, test=0.927) total time=   0.4s\n",
      "[CV 4/5; 1/30] START classifier__colsample_bytree=0.6958432427421151, classifier__gamma=0.4939271691878614, classifier__learning_rate=0.050470016031382264, classifier__max_depth=6, classifier__min_child_weight=5, classifier__n_estimators=301, classifier__subsample=0.7174727068901876\n",
      "[CV 4/5; 1/30] END classifier__colsample_bytree=0.6958432427421151, classifier__gamma=0.4939271691878614, classifier__learning_rate=0.050470016031382264, classifier__max_depth=6, classifier__min_child_weight=5, classifier__n_estimators=301, classifier__subsample=0.7174727068901876;, score=(train=0.958, test=0.893) total time=   0.4s\n",
      "[CV 5/5; 1/30] START classifier__colsample_bytree=0.6958432427421151, classifier__gamma=0.4939271691878614, classifier__learning_rate=0.050470016031382264, classifier__max_depth=6, classifier__min_child_weight=5, classifier__n_estimators=301, classifier__subsample=0.7174727068901876\n",
      "[CV 5/5; 1/30] END classifier__colsample_bytree=0.6958432427421151, classifier__gamma=0.4939271691878614, classifier__learning_rate=0.050470016031382264, classifier__max_depth=6, classifier__min_child_weight=5, classifier__n_estimators=301, classifier__subsample=0.7174727068901876;, score=(train=0.959, test=0.913) total time=   0.4s\n",
      "[CV 1/5; 2/30] START classifier__colsample_bytree=0.9648725663336202, classifier__gamma=1.58821786217404, classifier__learning_rate=0.06147144306746954, classifier__max_depth=37, classifier__min_child_weight=2, classifier__n_estimators=175, classifier__subsample=0.5757729940867148\n",
      "[CV 1/5; 2/30] END classifier__colsample_bytree=0.9648725663336202, classifier__gamma=1.58821786217404, classifier__learning_rate=0.06147144306746954, classifier__max_depth=37, classifier__min_child_weight=2, classifier__n_estimators=175, classifier__subsample=0.5757729940867148;, score=(train=0.968, test=0.899) total time=   0.3s\n",
      "[CV 2/5; 2/30] START classifier__colsample_bytree=0.9648725663336202, classifier__gamma=1.58821786217404, classifier__learning_rate=0.06147144306746954, classifier__max_depth=37, classifier__min_child_weight=2, classifier__n_estimators=175, classifier__subsample=0.5757729940867148\n",
      "[CV 2/5; 2/30] END classifier__colsample_bytree=0.9648725663336202, classifier__gamma=1.58821786217404, classifier__learning_rate=0.06147144306746954, classifier__max_depth=37, classifier__min_child_weight=2, classifier__n_estimators=175, classifier__subsample=0.5757729940867148;, score=(train=0.963, test=0.928) total time=   0.3s\n",
      "[CV 3/5; 2/30] START classifier__colsample_bytree=0.9648725663336202, classifier__gamma=1.58821786217404, classifier__learning_rate=0.06147144306746954, classifier__max_depth=37, classifier__min_child_weight=2, classifier__n_estimators=175, classifier__subsample=0.5757729940867148\n",
      "[CV 3/5; 2/30] END classifier__colsample_bytree=0.9648725663336202, classifier__gamma=1.58821786217404, classifier__learning_rate=0.06147144306746954, classifier__max_depth=37, classifier__min_child_weight=2, classifier__n_estimators=175, classifier__subsample=0.5757729940867148;, score=(train=0.963, test=0.933) total time=   0.3s\n",
      "[CV 4/5; 2/30] START classifier__colsample_bytree=0.9648725663336202, classifier__gamma=1.58821786217404, classifier__learning_rate=0.06147144306746954, classifier__max_depth=37, classifier__min_child_weight=2, classifier__n_estimators=175, classifier__subsample=0.5757729940867148\n",
      "[CV 4/5; 2/30] END classifier__colsample_bytree=0.9648725663336202, classifier__gamma=1.58821786217404, classifier__learning_rate=0.06147144306746954, classifier__max_depth=37, classifier__min_child_weight=2, classifier__n_estimators=175, classifier__subsample=0.5757729940867148;, score=(train=0.971, test=0.912) total time=   0.3s\n",
      "[CV 5/5; 2/30] START classifier__colsample_bytree=0.9648725663336202, classifier__gamma=1.58821786217404, classifier__learning_rate=0.06147144306746954, classifier__max_depth=37, classifier__min_child_weight=2, classifier__n_estimators=175, classifier__subsample=0.5757729940867148\n",
      "[CV 5/5; 2/30] END classifier__colsample_bytree=0.9648725663336202, classifier__gamma=1.58821786217404, classifier__learning_rate=0.06147144306746954, classifier__max_depth=37, classifier__min_child_weight=2, classifier__n_estimators=175, classifier__subsample=0.5757729940867148;, score=(train=0.966, test=0.918) total time=   0.4s\n",
      "[CV 1/5; 3/30] START classifier__colsample_bytree=0.9310385767462995, classifier__gamma=0.6995717576537875, classifier__learning_rate=0.005433396138009138, classifier__max_depth=25, classifier__min_child_weight=5, classifier__n_estimators=261, classifier__subsample=0.5307587967329506\n",
      "[CV 1/5; 3/30] END classifier__colsample_bytree=0.9310385767462995, classifier__gamma=0.6995717576537875, classifier__learning_rate=0.005433396138009138, classifier__max_depth=25, classifier__min_child_weight=5, classifier__n_estimators=261, classifier__subsample=0.5307587967329506;, score=(train=0.915, test=0.897) total time=   0.4s\n",
      "[CV 2/5; 3/30] START classifier__colsample_bytree=0.9310385767462995, classifier__gamma=0.6995717576537875, classifier__learning_rate=0.005433396138009138, classifier__max_depth=25, classifier__min_child_weight=5, classifier__n_estimators=261, classifier__subsample=0.5307587967329506\n",
      "[CV 2/5; 3/30] END classifier__colsample_bytree=0.9310385767462995, classifier__gamma=0.6995717576537875, classifier__learning_rate=0.005433396138009138, classifier__max_depth=25, classifier__min_child_weight=5, classifier__n_estimators=261, classifier__subsample=0.5307587967329506;, score=(train=0.917, test=0.902) total time=   0.4s\n",
      "[CV 3/5; 3/30] START classifier__colsample_bytree=0.9310385767462995, classifier__gamma=0.6995717576537875, classifier__learning_rate=0.005433396138009138, classifier__max_depth=25, classifier__min_child_weight=5, classifier__n_estimators=261, classifier__subsample=0.5307587967329506\n",
      "[CV 3/5; 3/30] END classifier__colsample_bytree=0.9310385767462995, classifier__gamma=0.6995717576537875, classifier__learning_rate=0.005433396138009138, classifier__max_depth=25, classifier__min_child_weight=5, classifier__n_estimators=261, classifier__subsample=0.5307587967329506;, score=(train=0.914, test=0.906) total time=   0.4s\n",
      "[CV 4/5; 3/30] START classifier__colsample_bytree=0.9310385767462995, classifier__gamma=0.6995717576537875, classifier__learning_rate=0.005433396138009138, classifier__max_depth=25, classifier__min_child_weight=5, classifier__n_estimators=261, classifier__subsample=0.5307587967329506\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 3/30] END classifier__colsample_bytree=0.9310385767462995, classifier__gamma=0.6995717576537875, classifier__learning_rate=0.005433396138009138, classifier__max_depth=25, classifier__min_child_weight=5, classifier__n_estimators=261, classifier__subsample=0.5307587967329506;, score=(train=0.920, test=0.890) total time=   0.4s\n",
      "[CV 5/5; 3/30] START classifier__colsample_bytree=0.9310385767462995, classifier__gamma=0.6995717576537875, classifier__learning_rate=0.005433396138009138, classifier__max_depth=25, classifier__min_child_weight=5, classifier__n_estimators=261, classifier__subsample=0.5307587967329506\n",
      "[CV 5/5; 3/30] END classifier__colsample_bytree=0.9310385767462995, classifier__gamma=0.6995717576537875, classifier__learning_rate=0.005433396138009138, classifier__max_depth=25, classifier__min_child_weight=5, classifier__n_estimators=261, classifier__subsample=0.5307587967329506;, score=(train=0.919, test=0.909) total time=   0.4s\n",
      "[CV 1/5; 4/30] START classifier__colsample_bytree=0.5412342648080697, classifier__gamma=0.28049499951401013, classifier__learning_rate=0.0015280321358900387, classifier__max_depth=47, classifier__min_child_weight=9, classifier__n_estimators=417, classifier__subsample=0.9017443104378217\n",
      "[CV 1/5; 4/30] END classifier__colsample_bytree=0.5412342648080697, classifier__gamma=0.28049499951401013, classifier__learning_rate=0.0015280321358900387, classifier__max_depth=47, classifier__min_child_weight=9, classifier__n_estimators=417, classifier__subsample=0.9017443104378217;, score=(train=0.909, test=0.886) total time=   0.8s\n",
      "[CV 2/5; 4/30] START classifier__colsample_bytree=0.5412342648080697, classifier__gamma=0.28049499951401013, classifier__learning_rate=0.0015280321358900387, classifier__max_depth=47, classifier__min_child_weight=9, classifier__n_estimators=417, classifier__subsample=0.9017443104378217\n",
      "[CV 2/5; 4/30] END classifier__colsample_bytree=0.5412342648080697, classifier__gamma=0.28049499951401013, classifier__learning_rate=0.0015280321358900387, classifier__max_depth=47, classifier__min_child_weight=9, classifier__n_estimators=417, classifier__subsample=0.9017443104378217;, score=(train=0.906, test=0.890) total time=   0.8s\n",
      "[CV 3/5; 4/30] START classifier__colsample_bytree=0.5412342648080697, classifier__gamma=0.28049499951401013, classifier__learning_rate=0.0015280321358900387, classifier__max_depth=47, classifier__min_child_weight=9, classifier__n_estimators=417, classifier__subsample=0.9017443104378217\n",
      "[CV 3/5; 4/30] END classifier__colsample_bytree=0.5412342648080697, classifier__gamma=0.28049499951401013, classifier__learning_rate=0.0015280321358900387, classifier__max_depth=47, classifier__min_child_weight=9, classifier__n_estimators=417, classifier__subsample=0.9017443104378217;, score=(train=0.912, test=0.902) total time=   0.8s\n",
      "[CV 4/5; 4/30] START classifier__colsample_bytree=0.5412342648080697, classifier__gamma=0.28049499951401013, classifier__learning_rate=0.0015280321358900387, classifier__max_depth=47, classifier__min_child_weight=9, classifier__n_estimators=417, classifier__subsample=0.9017443104378217\n",
      "[CV 4/5; 4/30] END classifier__colsample_bytree=0.5412342648080697, classifier__gamma=0.28049499951401013, classifier__learning_rate=0.0015280321358900387, classifier__max_depth=47, classifier__min_child_weight=9, classifier__n_estimators=417, classifier__subsample=0.9017443104378217;, score=(train=0.910, test=0.876) total time=   0.8s\n",
      "[CV 5/5; 4/30] START classifier__colsample_bytree=0.5412342648080697, classifier__gamma=0.28049499951401013, classifier__learning_rate=0.0015280321358900387, classifier__max_depth=47, classifier__min_child_weight=9, classifier__n_estimators=417, classifier__subsample=0.9017443104378217\n",
      "[CV 5/5; 4/30] END classifier__colsample_bytree=0.5412342648080697, classifier__gamma=0.28049499951401013, classifier__learning_rate=0.0015280321358900387, classifier__max_depth=47, classifier__min_child_weight=9, classifier__n_estimators=417, classifier__subsample=0.9017443104378217;, score=(train=0.907, test=0.902) total time=   0.9s\n",
      "[CV 1/5; 5/30] START classifier__colsample_bytree=0.9857058573070699, classifier__gamma=0.2607337795661122, classifier__learning_rate=0.01795635769949269, classifier__max_depth=35, classifier__min_child_weight=4, classifier__n_estimators=266, classifier__subsample=0.613926971166302\n",
      "[CV 1/5; 5/30] END classifier__colsample_bytree=0.9857058573070699, classifier__gamma=0.2607337795661122, classifier__learning_rate=0.01795635769949269, classifier__max_depth=35, classifier__min_child_weight=4, classifier__n_estimators=266, classifier__subsample=0.613926971166302;, score=(train=0.946, test=0.899) total time=   0.5s\n",
      "[CV 2/5; 5/30] START classifier__colsample_bytree=0.9857058573070699, classifier__gamma=0.2607337795661122, classifier__learning_rate=0.01795635769949269, classifier__max_depth=35, classifier__min_child_weight=4, classifier__n_estimators=266, classifier__subsample=0.613926971166302\n",
      "[CV 2/5; 5/30] END classifier__colsample_bytree=0.9857058573070699, classifier__gamma=0.2607337795661122, classifier__learning_rate=0.01795635769949269, classifier__max_depth=35, classifier__min_child_weight=4, classifier__n_estimators=266, classifier__subsample=0.613926971166302;, score=(train=0.946, test=0.914) total time=   0.5s\n",
      "[CV 3/5; 5/30] START classifier__colsample_bytree=0.9857058573070699, classifier__gamma=0.2607337795661122, classifier__learning_rate=0.01795635769949269, classifier__max_depth=35, classifier__min_child_weight=4, classifier__n_estimators=266, classifier__subsample=0.613926971166302\n",
      "[CV 3/5; 5/30] END classifier__colsample_bytree=0.9857058573070699, classifier__gamma=0.2607337795661122, classifier__learning_rate=0.01795635769949269, classifier__max_depth=35, classifier__min_child_weight=4, classifier__n_estimators=266, classifier__subsample=0.613926971166302;, score=(train=0.944, test=0.927) total time=   0.5s\n",
      "[CV 4/5; 5/30] START classifier__colsample_bytree=0.9857058573070699, classifier__gamma=0.2607337795661122, classifier__learning_rate=0.01795635769949269, classifier__max_depth=35, classifier__min_child_weight=4, classifier__n_estimators=266, classifier__subsample=0.613926971166302\n",
      "[CV 4/5; 5/30] END classifier__colsample_bytree=0.9857058573070699, classifier__gamma=0.2607337795661122, classifier__learning_rate=0.01795635769949269, classifier__max_depth=35, classifier__min_child_weight=4, classifier__n_estimators=266, classifier__subsample=0.613926971166302;, score=(train=0.944, test=0.906) total time=   0.5s\n",
      "[CV 5/5; 5/30] START classifier__colsample_bytree=0.9857058573070699, classifier__gamma=0.2607337795661122, classifier__learning_rate=0.01795635769949269, classifier__max_depth=35, classifier__min_child_weight=4, classifier__n_estimators=266, classifier__subsample=0.613926971166302\n",
      "[CV 5/5; 5/30] END classifier__colsample_bytree=0.9857058573070699, classifier__gamma=0.2607337795661122, classifier__learning_rate=0.01795635769949269, classifier__max_depth=35, classifier__min_child_weight=4, classifier__n_estimators=266, classifier__subsample=0.613926971166302;, score=(train=0.947, test=0.916) total time=   0.5s\n",
      "[CV 1/5; 6/30] START classifier__colsample_bytree=0.7508812021895441, classifier__gamma=0.2996068951546379, classifier__learning_rate=0.08257477986711842, classifier__max_depth=14, classifier__min_child_weight=7, classifier__n_estimators=376, classifier__subsample=0.6924737941973009\n",
      "[CV 1/5; 6/30] END classifier__colsample_bytree=0.7508812021895441, classifier__gamma=0.2996068951546379, classifier__learning_rate=0.08257477986711842, classifier__max_depth=14, classifier__min_child_weight=7, classifier__n_estimators=376, classifier__subsample=0.6924737941973009;, score=(train=0.965, test=0.901) total time=   0.5s\n",
      "[CV 2/5; 6/30] START classifier__colsample_bytree=0.7508812021895441, classifier__gamma=0.2996068951546379, classifier__learning_rate=0.08257477986711842, classifier__max_depth=14, classifier__min_child_weight=7, classifier__n_estimators=376, classifier__subsample=0.6924737941973009\n",
      "[CV 2/5; 6/30] END classifier__colsample_bytree=0.7508812021895441, classifier__gamma=0.2996068951546379, classifier__learning_rate=0.08257477986711842, classifier__max_depth=14, classifier__min_child_weight=7, classifier__n_estimators=376, classifier__subsample=0.6924737941973009;, score=(train=0.967, test=0.920) total time=   0.6s\n",
      "[CV 3/5; 6/30] START classifier__colsample_bytree=0.7508812021895441, classifier__gamma=0.2996068951546379, classifier__learning_rate=0.08257477986711842, classifier__max_depth=14, classifier__min_child_weight=7, classifier__n_estimators=376, classifier__subsample=0.6924737941973009\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 6/30] END classifier__colsample_bytree=0.7508812021895441, classifier__gamma=0.2996068951546379, classifier__learning_rate=0.08257477986711842, classifier__max_depth=14, classifier__min_child_weight=7, classifier__n_estimators=376, classifier__subsample=0.6924737941973009;, score=(train=0.967, test=0.933) total time=   0.5s\n",
      "[CV 4/5; 6/30] START classifier__colsample_bytree=0.7508812021895441, classifier__gamma=0.2996068951546379, classifier__learning_rate=0.08257477986711842, classifier__max_depth=14, classifier__min_child_weight=7, classifier__n_estimators=376, classifier__subsample=0.6924737941973009\n",
      "[CV 4/5; 6/30] END classifier__colsample_bytree=0.7508812021895441, classifier__gamma=0.2996068951546379, classifier__learning_rate=0.08257477986711842, classifier__max_depth=14, classifier__min_child_weight=7, classifier__n_estimators=376, classifier__subsample=0.6924737941973009;, score=(train=0.965, test=0.904) total time=   0.6s\n",
      "[CV 5/5; 6/30] START classifier__colsample_bytree=0.7508812021895441, classifier__gamma=0.2996068951546379, classifier__learning_rate=0.08257477986711842, classifier__max_depth=14, classifier__min_child_weight=7, classifier__n_estimators=376, classifier__subsample=0.6924737941973009\n",
      "[CV 5/5; 6/30] END classifier__colsample_bytree=0.7508812021895441, classifier__gamma=0.2996068951546379, classifier__learning_rate=0.08257477986711842, classifier__max_depth=14, classifier__min_child_weight=7, classifier__n_estimators=376, classifier__subsample=0.6924737941973009;, score=(train=0.968, test=0.927) total time=   0.6s\n",
      "[CV 1/5; 7/30] START classifier__colsample_bytree=0.6149797826436689, classifier__gamma=0.4949198339368057, classifier__learning_rate=0.05501460684031166, classifier__max_depth=44, classifier__min_child_weight=1, classifier__n_estimators=281, classifier__subsample=0.9680220569471438\n",
      "[CV 1/5; 7/30] END classifier__colsample_bytree=0.6149797826436689, classifier__gamma=0.4949198339368057, classifier__learning_rate=0.05501460684031166, classifier__max_depth=44, classifier__min_child_weight=1, classifier__n_estimators=281, classifier__subsample=0.9680220569471438;, score=(train=0.983, test=0.909) total time=   1.0s\n",
      "[CV 2/5; 7/30] START classifier__colsample_bytree=0.6149797826436689, classifier__gamma=0.4949198339368057, classifier__learning_rate=0.05501460684031166, classifier__max_depth=44, classifier__min_child_weight=1, classifier__n_estimators=281, classifier__subsample=0.9680220569471438\n",
      "[CV 2/5; 7/30] END classifier__colsample_bytree=0.6149797826436689, classifier__gamma=0.4949198339368057, classifier__learning_rate=0.05501460684031166, classifier__max_depth=44, classifier__min_child_weight=1, classifier__n_estimators=281, classifier__subsample=0.9680220569471438;, score=(train=0.982, test=0.924) total time=   0.9s\n",
      "[CV 3/5; 7/30] START classifier__colsample_bytree=0.6149797826436689, classifier__gamma=0.4949198339368057, classifier__learning_rate=0.05501460684031166, classifier__max_depth=44, classifier__min_child_weight=1, classifier__n_estimators=281, classifier__subsample=0.9680220569471438\n",
      "[CV 3/5; 7/30] END classifier__colsample_bytree=0.6149797826436689, classifier__gamma=0.4949198339368057, classifier__learning_rate=0.05501460684031166, classifier__max_depth=44, classifier__min_child_weight=1, classifier__n_estimators=281, classifier__subsample=0.9680220569471438;, score=(train=0.981, test=0.927) total time=   0.9s\n",
      "[CV 4/5; 7/30] START classifier__colsample_bytree=0.6149797826436689, classifier__gamma=0.4949198339368057, classifier__learning_rate=0.05501460684031166, classifier__max_depth=44, classifier__min_child_weight=1, classifier__n_estimators=281, classifier__subsample=0.9680220569471438\n",
      "[CV 4/5; 7/30] END classifier__colsample_bytree=0.6149797826436689, classifier__gamma=0.4949198339368057, classifier__learning_rate=0.05501460684031166, classifier__max_depth=44, classifier__min_child_weight=1, classifier__n_estimators=281, classifier__subsample=0.9680220569471438;, score=(train=0.983, test=0.914) total time=   0.8s\n",
      "[CV 5/5; 7/30] START classifier__colsample_bytree=0.6149797826436689, classifier__gamma=0.4949198339368057, classifier__learning_rate=0.05501460684031166, classifier__max_depth=44, classifier__min_child_weight=1, classifier__n_estimators=281, classifier__subsample=0.9680220569471438\n",
      "[CV 5/5; 7/30] END classifier__colsample_bytree=0.6149797826436689, classifier__gamma=0.4949198339368057, classifier__learning_rate=0.05501460684031166, classifier__max_depth=44, classifier__min_child_weight=1, classifier__n_estimators=281, classifier__subsample=0.9680220569471438;, score=(train=0.983, test=0.927) total time=   0.8s\n",
      "[CV 1/5; 8/30] START classifier__colsample_bytree=0.8475848910871195, classifier__gamma=2.1338942902376736, classifier__learning_rate=0.0336376017340045, classifier__max_depth=33, classifier__min_child_weight=2, classifier__n_estimators=179, classifier__subsample=0.8507334526640621\n",
      "[CV 1/5; 8/30] END classifier__colsample_bytree=0.8475848910871195, classifier__gamma=2.1338942902376736, classifier__learning_rate=0.0336376017340045, classifier__max_depth=33, classifier__min_child_weight=2, classifier__n_estimators=179, classifier__subsample=0.8507334526640621;, score=(train=0.958, test=0.898) total time=   0.5s\n",
      "[CV 2/5; 8/30] START classifier__colsample_bytree=0.8475848910871195, classifier__gamma=2.1338942902376736, classifier__learning_rate=0.0336376017340045, classifier__max_depth=33, classifier__min_child_weight=2, classifier__n_estimators=179, classifier__subsample=0.8507334526640621\n",
      "[CV 2/5; 8/30] END classifier__colsample_bytree=0.8475848910871195, classifier__gamma=2.1338942902376736, classifier__learning_rate=0.0336376017340045, classifier__max_depth=33, classifier__min_child_weight=2, classifier__n_estimators=179, classifier__subsample=0.8507334526640621;, score=(train=0.966, test=0.920) total time=   0.6s\n",
      "[CV 3/5; 8/30] START classifier__colsample_bytree=0.8475848910871195, classifier__gamma=2.1338942902376736, classifier__learning_rate=0.0336376017340045, classifier__max_depth=33, classifier__min_child_weight=2, classifier__n_estimators=179, classifier__subsample=0.8507334526640621\n",
      "[CV 3/5; 8/30] END classifier__colsample_bytree=0.8475848910871195, classifier__gamma=2.1338942902376736, classifier__learning_rate=0.0336376017340045, classifier__max_depth=33, classifier__min_child_weight=2, classifier__n_estimators=179, classifier__subsample=0.8507334526640621;, score=(train=0.958, test=0.921) total time=   0.6s\n",
      "[CV 4/5; 8/30] START classifier__colsample_bytree=0.8475848910871195, classifier__gamma=2.1338942902376736, classifier__learning_rate=0.0336376017340045, classifier__max_depth=33, classifier__min_child_weight=2, classifier__n_estimators=179, classifier__subsample=0.8507334526640621\n",
      "[CV 4/5; 8/30] END classifier__colsample_bytree=0.8475848910871195, classifier__gamma=2.1338942902376736, classifier__learning_rate=0.0336376017340045, classifier__max_depth=33, classifier__min_child_weight=2, classifier__n_estimators=179, classifier__subsample=0.8507334526640621;, score=(train=0.963, test=0.909) total time=   0.6s\n",
      "[CV 5/5; 8/30] START classifier__colsample_bytree=0.8475848910871195, classifier__gamma=2.1338942902376736, classifier__learning_rate=0.0336376017340045, classifier__max_depth=33, classifier__min_child_weight=2, classifier__n_estimators=179, classifier__subsample=0.8507334526640621\n",
      "[CV 5/5; 8/30] END classifier__colsample_bytree=0.8475848910871195, classifier__gamma=2.1338942902376736, classifier__learning_rate=0.0336376017340045, classifier__max_depth=33, classifier__min_child_weight=2, classifier__n_estimators=179, classifier__subsample=0.8507334526640621;, score=(train=0.962, test=0.921) total time=   0.5s\n",
      "[CV 1/5; 9/30] START classifier__colsample_bytree=0.8271409571459092, classifier__gamma=2.6695385613854663, classifier__learning_rate=0.0868922507795908, classifier__max_depth=44, classifier__min_child_weight=7, classifier__n_estimators=322, classifier__subsample=0.9755989276575676\n",
      "[CV 1/5; 9/30] END classifier__colsample_bytree=0.8271409571459092, classifier__gamma=2.6695385613854663, classifier__learning_rate=0.0868922507795908, classifier__max_depth=44, classifier__min_child_weight=7, classifier__n_estimators=322, classifier__subsample=0.9755989276575676;, score=(train=0.958, test=0.906) total time=   0.6s\n",
      "[CV 2/5; 9/30] START classifier__colsample_bytree=0.8271409571459092, classifier__gamma=2.6695385613854663, classifier__learning_rate=0.0868922507795908, classifier__max_depth=44, classifier__min_child_weight=7, classifier__n_estimators=322, classifier__subsample=0.9755989276575676\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 9/30] END classifier__colsample_bytree=0.8271409571459092, classifier__gamma=2.6695385613854663, classifier__learning_rate=0.0868922507795908, classifier__max_depth=44, classifier__min_child_weight=7, classifier__n_estimators=322, classifier__subsample=0.9755989276575676;, score=(train=0.956, test=0.923) total time=   0.7s\n",
      "[CV 3/5; 9/30] START classifier__colsample_bytree=0.8271409571459092, classifier__gamma=2.6695385613854663, classifier__learning_rate=0.0868922507795908, classifier__max_depth=44, classifier__min_child_weight=7, classifier__n_estimators=322, classifier__subsample=0.9755989276575676\n",
      "[CV 3/5; 9/30] END classifier__colsample_bytree=0.8271409571459092, classifier__gamma=2.6695385613854663, classifier__learning_rate=0.0868922507795908, classifier__max_depth=44, classifier__min_child_weight=7, classifier__n_estimators=322, classifier__subsample=0.9755989276575676;, score=(train=0.959, test=0.932) total time=   0.7s\n",
      "[CV 4/5; 9/30] START classifier__colsample_bytree=0.8271409571459092, classifier__gamma=2.6695385613854663, classifier__learning_rate=0.0868922507795908, classifier__max_depth=44, classifier__min_child_weight=7, classifier__n_estimators=322, classifier__subsample=0.9755989276575676\n",
      "[CV 4/5; 9/30] END classifier__colsample_bytree=0.8271409571459092, classifier__gamma=2.6695385613854663, classifier__learning_rate=0.0868922507795908, classifier__max_depth=44, classifier__min_child_weight=7, classifier__n_estimators=322, classifier__subsample=0.9755989276575676;, score=(train=0.961, test=0.909) total time=   0.6s\n",
      "[CV 5/5; 9/30] START classifier__colsample_bytree=0.8271409571459092, classifier__gamma=2.6695385613854663, classifier__learning_rate=0.0868922507795908, classifier__max_depth=44, classifier__min_child_weight=7, classifier__n_estimators=322, classifier__subsample=0.9755989276575676\n",
      "[CV 5/5; 9/30] END classifier__colsample_bytree=0.8271409571459092, classifier__gamma=2.6695385613854663, classifier__learning_rate=0.0868922507795908, classifier__max_depth=44, classifier__min_child_weight=7, classifier__n_estimators=322, classifier__subsample=0.9755989276575676;, score=(train=0.957, test=0.925) total time=   0.6s\n",
      "[CV 1/5; 10/30] START classifier__colsample_bytree=0.5448334582800938, classifier__gamma=0.63699793975817, classifier__learning_rate=0.028426602930029535, classifier__max_depth=38, classifier__min_child_weight=6, classifier__n_estimators=273, classifier__subsample=0.6905421434359236\n",
      "[CV 1/5; 10/30] END classifier__colsample_bytree=0.5448334582800938, classifier__gamma=0.63699793975817, classifier__learning_rate=0.028426602930029535, classifier__max_depth=38, classifier__min_child_weight=6, classifier__n_estimators=273, classifier__subsample=0.6905421434359236;, score=(train=0.948, test=0.890) total time=   0.5s\n",
      "[CV 2/5; 10/30] START classifier__colsample_bytree=0.5448334582800938, classifier__gamma=0.63699793975817, classifier__learning_rate=0.028426602930029535, classifier__max_depth=38, classifier__min_child_weight=6, classifier__n_estimators=273, classifier__subsample=0.6905421434359236\n",
      "[CV 2/5; 10/30] END classifier__colsample_bytree=0.5448334582800938, classifier__gamma=0.63699793975817, classifier__learning_rate=0.028426602930029535, classifier__max_depth=38, classifier__min_child_weight=6, classifier__n_estimators=273, classifier__subsample=0.6905421434359236;, score=(train=0.945, test=0.906) total time=   0.5s\n",
      "[CV 3/5; 10/30] START classifier__colsample_bytree=0.5448334582800938, classifier__gamma=0.63699793975817, classifier__learning_rate=0.028426602930029535, classifier__max_depth=38, classifier__min_child_weight=6, classifier__n_estimators=273, classifier__subsample=0.6905421434359236\n",
      "[CV 3/5; 10/30] END classifier__colsample_bytree=0.5448334582800938, classifier__gamma=0.63699793975817, classifier__learning_rate=0.028426602930029535, classifier__max_depth=38, classifier__min_child_weight=6, classifier__n_estimators=273, classifier__subsample=0.6905421434359236;, score=(train=0.942, test=0.932) total time=   0.5s\n",
      "[CV 4/5; 10/30] START classifier__colsample_bytree=0.5448334582800938, classifier__gamma=0.63699793975817, classifier__learning_rate=0.028426602930029535, classifier__max_depth=38, classifier__min_child_weight=6, classifier__n_estimators=273, classifier__subsample=0.6905421434359236\n",
      "[CV 4/5; 10/30] END classifier__colsample_bytree=0.5448334582800938, classifier__gamma=0.63699793975817, classifier__learning_rate=0.028426602930029535, classifier__max_depth=38, classifier__min_child_weight=6, classifier__n_estimators=273, classifier__subsample=0.6905421434359236;, score=(train=0.947, test=0.909) total time=   0.5s\n",
      "[CV 5/5; 10/30] START classifier__colsample_bytree=0.5448334582800938, classifier__gamma=0.63699793975817, classifier__learning_rate=0.028426602930029535, classifier__max_depth=38, classifier__min_child_weight=6, classifier__n_estimators=273, classifier__subsample=0.6905421434359236\n",
      "[CV 5/5; 10/30] END classifier__colsample_bytree=0.5448334582800938, classifier__gamma=0.63699793975817, classifier__learning_rate=0.028426602930029535, classifier__max_depth=38, classifier__min_child_weight=6, classifier__n_estimators=273, classifier__subsample=0.6905421434359236;, score=(train=0.950, test=0.917) total time=   0.5s\n",
      "[CV 1/5; 11/30] START classifier__colsample_bytree=0.5593951617242559, classifier__gamma=1.2310428790004073, classifier__learning_rate=0.04127171008794778, classifier__max_depth=28, classifier__min_child_weight=10, classifier__n_estimators=277, classifier__subsample=0.9641827432087491\n",
      "[CV 1/5; 11/30] END classifier__colsample_bytree=0.5593951617242559, classifier__gamma=1.2310428790004073, classifier__learning_rate=0.04127171008794778, classifier__max_depth=28, classifier__min_child_weight=10, classifier__n_estimators=277, classifier__subsample=0.9641827432087491;, score=(train=0.950, test=0.899) total time=   0.5s\n",
      "[CV 2/5; 11/30] START classifier__colsample_bytree=0.5593951617242559, classifier__gamma=1.2310428790004073, classifier__learning_rate=0.04127171008794778, classifier__max_depth=28, classifier__min_child_weight=10, classifier__n_estimators=277, classifier__subsample=0.9641827432087491\n",
      "[CV 2/5; 11/30] END classifier__colsample_bytree=0.5593951617242559, classifier__gamma=1.2310428790004073, classifier__learning_rate=0.04127171008794778, classifier__max_depth=28, classifier__min_child_weight=10, classifier__n_estimators=277, classifier__subsample=0.9641827432087491;, score=(train=0.947, test=0.905) total time=   0.5s\n",
      "[CV 3/5; 11/30] START classifier__colsample_bytree=0.5593951617242559, classifier__gamma=1.2310428790004073, classifier__learning_rate=0.04127171008794778, classifier__max_depth=28, classifier__min_child_weight=10, classifier__n_estimators=277, classifier__subsample=0.9641827432087491\n",
      "[CV 3/5; 11/30] END classifier__colsample_bytree=0.5593951617242559, classifier__gamma=1.2310428790004073, classifier__learning_rate=0.04127171008794778, classifier__max_depth=28, classifier__min_child_weight=10, classifier__n_estimators=277, classifier__subsample=0.9641827432087491;, score=(train=0.952, test=0.940) total time=   0.5s\n",
      "[CV 4/5; 11/30] START classifier__colsample_bytree=0.5593951617242559, classifier__gamma=1.2310428790004073, classifier__learning_rate=0.04127171008794778, classifier__max_depth=28, classifier__min_child_weight=10, classifier__n_estimators=277, classifier__subsample=0.9641827432087491\n",
      "[CV 4/5; 11/30] END classifier__colsample_bytree=0.5593951617242559, classifier__gamma=1.2310428790004073, classifier__learning_rate=0.04127171008794778, classifier__max_depth=28, classifier__min_child_weight=10, classifier__n_estimators=277, classifier__subsample=0.9641827432087491;, score=(train=0.952, test=0.904) total time=   0.5s\n",
      "[CV 5/5; 11/30] START classifier__colsample_bytree=0.5593951617242559, classifier__gamma=1.2310428790004073, classifier__learning_rate=0.04127171008794778, classifier__max_depth=28, classifier__min_child_weight=10, classifier__n_estimators=277, classifier__subsample=0.9641827432087491\n",
      "[CV 5/5; 11/30] END classifier__colsample_bytree=0.5593951617242559, classifier__gamma=1.2310428790004073, classifier__learning_rate=0.04127171008794778, classifier__max_depth=28, classifier__min_child_weight=10, classifier__n_estimators=277, classifier__subsample=0.9641827432087491;, score=(train=0.950, test=0.920) total time=   0.5s\n",
      "[CV 1/5; 12/30] START classifier__colsample_bytree=0.9778882816821055, classifier__gamma=1.244783105453331, classifier__learning_rate=0.01886454192348758, classifier__max_depth=27, classifier__min_child_weight=6, classifier__n_estimators=259, classifier__subsample=0.8211225952699415\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 12/30] END classifier__colsample_bytree=0.9778882816821055, classifier__gamma=1.244783105453331, classifier__learning_rate=0.01886454192348758, classifier__max_depth=27, classifier__min_child_weight=6, classifier__n_estimators=259, classifier__subsample=0.8211225952699415;, score=(train=0.947, test=0.901) total time=   0.5s\n",
      "[CV 2/5; 12/30] START classifier__colsample_bytree=0.9778882816821055, classifier__gamma=1.244783105453331, classifier__learning_rate=0.01886454192348758, classifier__max_depth=27, classifier__min_child_weight=6, classifier__n_estimators=259, classifier__subsample=0.8211225952699415\n",
      "[CV 2/5; 12/30] END classifier__colsample_bytree=0.9778882816821055, classifier__gamma=1.244783105453331, classifier__learning_rate=0.01886454192348758, classifier__max_depth=27, classifier__min_child_weight=6, classifier__n_estimators=259, classifier__subsample=0.8211225952699415;, score=(train=0.941, test=0.912) total time=   0.5s\n",
      "[CV 3/5; 12/30] START classifier__colsample_bytree=0.9778882816821055, classifier__gamma=1.244783105453331, classifier__learning_rate=0.01886454192348758, classifier__max_depth=27, classifier__min_child_weight=6, classifier__n_estimators=259, classifier__subsample=0.8211225952699415\n",
      "[CV 3/5; 12/30] END classifier__colsample_bytree=0.9778882816821055, classifier__gamma=1.244783105453331, classifier__learning_rate=0.01886454192348758, classifier__max_depth=27, classifier__min_child_weight=6, classifier__n_estimators=259, classifier__subsample=0.8211225952699415;, score=(train=0.948, test=0.924) total time=   0.5s\n",
      "[CV 4/5; 12/30] START classifier__colsample_bytree=0.9778882816821055, classifier__gamma=1.244783105453331, classifier__learning_rate=0.01886454192348758, classifier__max_depth=27, classifier__min_child_weight=6, classifier__n_estimators=259, classifier__subsample=0.8211225952699415\n",
      "[CV 4/5; 12/30] END classifier__colsample_bytree=0.9778882816821055, classifier__gamma=1.244783105453331, classifier__learning_rate=0.01886454192348758, classifier__max_depth=27, classifier__min_child_weight=6, classifier__n_estimators=259, classifier__subsample=0.8211225952699415;, score=(train=0.949, test=0.913) total time=   0.5s\n",
      "[CV 5/5; 12/30] START classifier__colsample_bytree=0.9778882816821055, classifier__gamma=1.244783105453331, classifier__learning_rate=0.01886454192348758, classifier__max_depth=27, classifier__min_child_weight=6, classifier__n_estimators=259, classifier__subsample=0.8211225952699415\n",
      "[CV 5/5; 12/30] END classifier__colsample_bytree=0.9778882816821055, classifier__gamma=1.244783105453331, classifier__learning_rate=0.01886454192348758, classifier__max_depth=27, classifier__min_child_weight=6, classifier__n_estimators=259, classifier__subsample=0.8211225952699415;, score=(train=0.948, test=0.918) total time=   0.5s\n",
      "[CV 1/5; 13/30] START classifier__colsample_bytree=0.7737743059316542, classifier__gamma=0.8514569446080041, classifier__learning_rate=0.031098116649683268, classifier__max_depth=33, classifier__min_child_weight=8, classifier__n_estimators=379, classifier__subsample=0.7096870129376738\n",
      "[CV 1/5; 13/30] END classifier__colsample_bytree=0.7737743059316542, classifier__gamma=0.8514569446080041, classifier__learning_rate=0.031098116649683268, classifier__max_depth=33, classifier__min_child_weight=8, classifier__n_estimators=379, classifier__subsample=0.7096870129376738;, score=(train=0.951, test=0.906) total time=   0.6s\n",
      "[CV 2/5; 13/30] START classifier__colsample_bytree=0.7737743059316542, classifier__gamma=0.8514569446080041, classifier__learning_rate=0.031098116649683268, classifier__max_depth=33, classifier__min_child_weight=8, classifier__n_estimators=379, classifier__subsample=0.7096870129376738\n",
      "[CV 2/5; 13/30] END classifier__colsample_bytree=0.7737743059316542, classifier__gamma=0.8514569446080041, classifier__learning_rate=0.031098116649683268, classifier__max_depth=33, classifier__min_child_weight=8, classifier__n_estimators=379, classifier__subsample=0.7096870129376738;, score=(train=0.948, test=0.906) total time=   0.6s\n",
      "[CV 3/5; 13/30] START classifier__colsample_bytree=0.7737743059316542, classifier__gamma=0.8514569446080041, classifier__learning_rate=0.031098116649683268, classifier__max_depth=33, classifier__min_child_weight=8, classifier__n_estimators=379, classifier__subsample=0.7096870129376738\n",
      "[CV 3/5; 13/30] END classifier__colsample_bytree=0.7737743059316542, classifier__gamma=0.8514569446080041, classifier__learning_rate=0.031098116649683268, classifier__max_depth=33, classifier__min_child_weight=8, classifier__n_estimators=379, classifier__subsample=0.7096870129376738;, score=(train=0.952, test=0.929) total time=   0.6s\n",
      "[CV 4/5; 13/30] START classifier__colsample_bytree=0.7737743059316542, classifier__gamma=0.8514569446080041, classifier__learning_rate=0.031098116649683268, classifier__max_depth=33, classifier__min_child_weight=8, classifier__n_estimators=379, classifier__subsample=0.7096870129376738\n",
      "[CV 4/5; 13/30] END classifier__colsample_bytree=0.7737743059316542, classifier__gamma=0.8514569446080041, classifier__learning_rate=0.031098116649683268, classifier__max_depth=33, classifier__min_child_weight=8, classifier__n_estimators=379, classifier__subsample=0.7096870129376738;, score=(train=0.951, test=0.905) total time=   0.6s\n",
      "[CV 5/5; 13/30] START classifier__colsample_bytree=0.7737743059316542, classifier__gamma=0.8514569446080041, classifier__learning_rate=0.031098116649683268, classifier__max_depth=33, classifier__min_child_weight=8, classifier__n_estimators=379, classifier__subsample=0.7096870129376738\n",
      "[CV 5/5; 13/30] END classifier__colsample_bytree=0.7737743059316542, classifier__gamma=0.8514569446080041, classifier__learning_rate=0.031098116649683268, classifier__max_depth=33, classifier__min_child_weight=8, classifier__n_estimators=379, classifier__subsample=0.7096870129376738;, score=(train=0.959, test=0.916) total time=   0.6s\n",
      "[CV 1/5; 14/30] START classifier__colsample_bytree=0.7779514329030388, classifier__gamma=1.6466606086842885, classifier__learning_rate=0.028499172092863657, classifier__max_depth=27, classifier__min_child_weight=4, classifier__n_estimators=447, classifier__subsample=0.7904257392049987\n",
      "[CV 1/5; 14/30] END classifier__colsample_bytree=0.7779514329030388, classifier__gamma=1.6466606086842885, classifier__learning_rate=0.028499172092863657, classifier__max_depth=27, classifier__min_child_weight=4, classifier__n_estimators=447, classifier__subsample=0.7904257392049987;, score=(train=0.962, test=0.901) total time=   0.9s\n",
      "[CV 2/5; 14/30] START classifier__colsample_bytree=0.7779514329030388, classifier__gamma=1.6466606086842885, classifier__learning_rate=0.028499172092863657, classifier__max_depth=27, classifier__min_child_weight=4, classifier__n_estimators=447, classifier__subsample=0.7904257392049987\n",
      "[CV 2/5; 14/30] END classifier__colsample_bytree=0.7779514329030388, classifier__gamma=1.6466606086842885, classifier__learning_rate=0.028499172092863657, classifier__max_depth=27, classifier__min_child_weight=4, classifier__n_estimators=447, classifier__subsample=0.7904257392049987;, score=(train=0.962, test=0.912) total time=   1.0s\n",
      "[CV 3/5; 14/30] START classifier__colsample_bytree=0.7779514329030388, classifier__gamma=1.6466606086842885, classifier__learning_rate=0.028499172092863657, classifier__max_depth=27, classifier__min_child_weight=4, classifier__n_estimators=447, classifier__subsample=0.7904257392049987\n",
      "[CV 3/5; 14/30] END classifier__colsample_bytree=0.7779514329030388, classifier__gamma=1.6466606086842885, classifier__learning_rate=0.028499172092863657, classifier__max_depth=27, classifier__min_child_weight=4, classifier__n_estimators=447, classifier__subsample=0.7904257392049987;, score=(train=0.966, test=0.928) total time=   1.0s\n",
      "[CV 4/5; 14/30] START classifier__colsample_bytree=0.7779514329030388, classifier__gamma=1.6466606086842885, classifier__learning_rate=0.028499172092863657, classifier__max_depth=27, classifier__min_child_weight=4, classifier__n_estimators=447, classifier__subsample=0.7904257392049987\n",
      "[CV 4/5; 14/30] END classifier__colsample_bytree=0.7779514329030388, classifier__gamma=1.6466606086842885, classifier__learning_rate=0.028499172092863657, classifier__max_depth=27, classifier__min_child_weight=4, classifier__n_estimators=447, classifier__subsample=0.7904257392049987;, score=(train=0.966, test=0.906) total time=   1.0s\n",
      "[CV 5/5; 14/30] START classifier__colsample_bytree=0.7779514329030388, classifier__gamma=1.6466606086842885, classifier__learning_rate=0.028499172092863657, classifier__max_depth=27, classifier__min_child_weight=4, classifier__n_estimators=447, classifier__subsample=0.7904257392049987\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 14/30] END classifier__colsample_bytree=0.7779514329030388, classifier__gamma=1.6466606086842885, classifier__learning_rate=0.028499172092863657, classifier__max_depth=27, classifier__min_child_weight=4, classifier__n_estimators=447, classifier__subsample=0.7904257392049987;, score=(train=0.966, test=0.908) total time=   1.0s\n",
      "[CV 1/5; 15/30] START classifier__colsample_bytree=0.6481984597541752, classifier__gamma=1.940228532275312, classifier__learning_rate=0.06092640531838534, classifier__max_depth=15, classifier__min_child_weight=1, classifier__n_estimators=161, classifier__subsample=0.667139046059865\n",
      "[CV 1/5; 15/30] END classifier__colsample_bytree=0.6481984597541752, classifier__gamma=1.940228532275312, classifier__learning_rate=0.06092640531838534, classifier__max_depth=15, classifier__min_child_weight=1, classifier__n_estimators=161, classifier__subsample=0.667139046059865;, score=(train=0.966, test=0.914) total time=   0.4s\n",
      "[CV 2/5; 15/30] START classifier__colsample_bytree=0.6481984597541752, classifier__gamma=1.940228532275312, classifier__learning_rate=0.06092640531838534, classifier__max_depth=15, classifier__min_child_weight=1, classifier__n_estimators=161, classifier__subsample=0.667139046059865\n",
      "[CV 2/5; 15/30] END classifier__colsample_bytree=0.6481984597541752, classifier__gamma=1.940228532275312, classifier__learning_rate=0.06092640531838534, classifier__max_depth=15, classifier__min_child_weight=1, classifier__n_estimators=161, classifier__subsample=0.667139046059865;, score=(train=0.964, test=0.916) total time=   0.4s\n",
      "[CV 3/5; 15/30] START classifier__colsample_bytree=0.6481984597541752, classifier__gamma=1.940228532275312, classifier__learning_rate=0.06092640531838534, classifier__max_depth=15, classifier__min_child_weight=1, classifier__n_estimators=161, classifier__subsample=0.667139046059865\n",
      "[CV 3/5; 15/30] END classifier__colsample_bytree=0.6481984597541752, classifier__gamma=1.940228532275312, classifier__learning_rate=0.06092640531838534, classifier__max_depth=15, classifier__min_child_weight=1, classifier__n_estimators=161, classifier__subsample=0.667139046059865;, score=(train=0.966, test=0.931) total time=   0.4s\n",
      "[CV 4/5; 15/30] START classifier__colsample_bytree=0.6481984597541752, classifier__gamma=1.940228532275312, classifier__learning_rate=0.06092640531838534, classifier__max_depth=15, classifier__min_child_weight=1, classifier__n_estimators=161, classifier__subsample=0.667139046059865\n",
      "[CV 4/5; 15/30] END classifier__colsample_bytree=0.6481984597541752, classifier__gamma=1.940228532275312, classifier__learning_rate=0.06092640531838534, classifier__max_depth=15, classifier__min_child_weight=1, classifier__n_estimators=161, classifier__subsample=0.667139046059865;, score=(train=0.966, test=0.906) total time=   0.4s\n",
      "[CV 5/5; 15/30] START classifier__colsample_bytree=0.6481984597541752, classifier__gamma=1.940228532275312, classifier__learning_rate=0.06092640531838534, classifier__max_depth=15, classifier__min_child_weight=1, classifier__n_estimators=161, classifier__subsample=0.667139046059865\n",
      "[CV 5/5; 15/30] END classifier__colsample_bytree=0.6481984597541752, classifier__gamma=1.940228532275312, classifier__learning_rate=0.06092640531838534, classifier__max_depth=15, classifier__min_child_weight=1, classifier__n_estimators=161, classifier__subsample=0.667139046059865;, score=(train=0.964, test=0.925) total time=   0.4s\n",
      "[CV 1/5; 16/30] START classifier__colsample_bytree=0.5200705399078565, classifier__gamma=2.4532153012492115, classifier__learning_rate=0.028798205792368185, classifier__max_depth=27, classifier__min_child_weight=8, classifier__n_estimators=265, classifier__subsample=0.561430864861984\n",
      "[CV 1/5; 16/30] END classifier__colsample_bytree=0.5200705399078565, classifier__gamma=2.4532153012492115, classifier__learning_rate=0.028798205792368185, classifier__max_depth=27, classifier__min_child_weight=8, classifier__n_estimators=265, classifier__subsample=0.561430864861984;, score=(train=0.932, test=0.889) total time=   0.4s\n",
      "[CV 2/5; 16/30] START classifier__colsample_bytree=0.5200705399078565, classifier__gamma=2.4532153012492115, classifier__learning_rate=0.028798205792368185, classifier__max_depth=27, classifier__min_child_weight=8, classifier__n_estimators=265, classifier__subsample=0.561430864861984\n",
      "[CV 2/5; 16/30] END classifier__colsample_bytree=0.5200705399078565, classifier__gamma=2.4532153012492115, classifier__learning_rate=0.028798205792368185, classifier__max_depth=27, classifier__min_child_weight=8, classifier__n_estimators=265, classifier__subsample=0.561430864861984;, score=(train=0.926, test=0.918) total time=   0.3s\n",
      "[CV 3/5; 16/30] START classifier__colsample_bytree=0.5200705399078565, classifier__gamma=2.4532153012492115, classifier__learning_rate=0.028798205792368185, classifier__max_depth=27, classifier__min_child_weight=8, classifier__n_estimators=265, classifier__subsample=0.561430864861984\n",
      "[CV 3/5; 16/30] END classifier__colsample_bytree=0.5200705399078565, classifier__gamma=2.4532153012492115, classifier__learning_rate=0.028798205792368185, classifier__max_depth=27, classifier__min_child_weight=8, classifier__n_estimators=265, classifier__subsample=0.561430864861984;, score=(train=0.925, test=0.924) total time=   0.4s\n",
      "[CV 4/5; 16/30] START classifier__colsample_bytree=0.5200705399078565, classifier__gamma=2.4532153012492115, classifier__learning_rate=0.028798205792368185, classifier__max_depth=27, classifier__min_child_weight=8, classifier__n_estimators=265, classifier__subsample=0.561430864861984\n",
      "[CV 4/5; 16/30] END classifier__colsample_bytree=0.5200705399078565, classifier__gamma=2.4532153012492115, classifier__learning_rate=0.028798205792368185, classifier__max_depth=27, classifier__min_child_weight=8, classifier__n_estimators=265, classifier__subsample=0.561430864861984;, score=(train=0.930, test=0.904) total time=   0.4s\n",
      "[CV 5/5; 16/30] START classifier__colsample_bytree=0.5200705399078565, classifier__gamma=2.4532153012492115, classifier__learning_rate=0.028798205792368185, classifier__max_depth=27, classifier__min_child_weight=8, classifier__n_estimators=265, classifier__subsample=0.561430864861984\n",
      "[CV 5/5; 16/30] END classifier__colsample_bytree=0.5200705399078565, classifier__gamma=2.4532153012492115, classifier__learning_rate=0.028798205792368185, classifier__max_depth=27, classifier__min_child_weight=8, classifier__n_estimators=265, classifier__subsample=0.561430864861984;, score=(train=0.938, test=0.917) total time=   0.3s\n",
      "[CV 1/5; 17/30] START classifier__colsample_bytree=0.7229513031060903, classifier__gamma=2.4175053971633726, classifier__learning_rate=0.010754384190700923, classifier__max_depth=17, classifier__min_child_weight=5, classifier__n_estimators=155, classifier__subsample=0.6886591313949849\n",
      "[CV 1/5; 17/30] END classifier__colsample_bytree=0.7229513031060903, classifier__gamma=2.4175053971633726, classifier__learning_rate=0.010754384190700923, classifier__max_depth=17, classifier__min_child_weight=5, classifier__n_estimators=155, classifier__subsample=0.6886591313949849;, score=(train=0.925, test=0.893) total time=   0.3s\n",
      "[CV 2/5; 17/30] START classifier__colsample_bytree=0.7229513031060903, classifier__gamma=2.4175053971633726, classifier__learning_rate=0.010754384190700923, classifier__max_depth=17, classifier__min_child_weight=5, classifier__n_estimators=155, classifier__subsample=0.6886591313949849\n",
      "[CV 2/5; 17/30] END classifier__colsample_bytree=0.7229513031060903, classifier__gamma=2.4175053971633726, classifier__learning_rate=0.010754384190700923, classifier__max_depth=17, classifier__min_child_weight=5, classifier__n_estimators=155, classifier__subsample=0.6886591313949849;, score=(train=0.925, test=0.912) total time=   0.3s\n",
      "[CV 3/5; 17/30] START classifier__colsample_bytree=0.7229513031060903, classifier__gamma=2.4175053971633726, classifier__learning_rate=0.010754384190700923, classifier__max_depth=17, classifier__min_child_weight=5, classifier__n_estimators=155, classifier__subsample=0.6886591313949849\n",
      "[CV 3/5; 17/30] END classifier__colsample_bytree=0.7229513031060903, classifier__gamma=2.4175053971633726, classifier__learning_rate=0.010754384190700923, classifier__max_depth=17, classifier__min_child_weight=5, classifier__n_estimators=155, classifier__subsample=0.6886591313949849;, score=(train=0.921, test=0.912) total time=   0.3s\n",
      "[CV 4/5; 17/30] START classifier__colsample_bytree=0.7229513031060903, classifier__gamma=2.4175053971633726, classifier__learning_rate=0.010754384190700923, classifier__max_depth=17, classifier__min_child_weight=5, classifier__n_estimators=155, classifier__subsample=0.6886591313949849\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 17/30] END classifier__colsample_bytree=0.7229513031060903, classifier__gamma=2.4175053971633726, classifier__learning_rate=0.010754384190700923, classifier__max_depth=17, classifier__min_child_weight=5, classifier__n_estimators=155, classifier__subsample=0.6886591313949849;, score=(train=0.925, test=0.898) total time=   0.3s\n",
      "[CV 5/5; 17/30] START classifier__colsample_bytree=0.7229513031060903, classifier__gamma=2.4175053971633726, classifier__learning_rate=0.010754384190700923, classifier__max_depth=17, classifier__min_child_weight=5, classifier__n_estimators=155, classifier__subsample=0.6886591313949849\n",
      "[CV 5/5; 17/30] END classifier__colsample_bytree=0.7229513031060903, classifier__gamma=2.4175053971633726, classifier__learning_rate=0.010754384190700923, classifier__max_depth=17, classifier__min_child_weight=5, classifier__n_estimators=155, classifier__subsample=0.6886591313949849;, score=(train=0.926, test=0.916) total time=   0.3s\n",
      "[CV 1/5; 18/30] START classifier__colsample_bytree=0.5782308082130909, classifier__gamma=0.44612428386215064, classifier__learning_rate=0.0755440173387222, classifier__max_depth=28, classifier__min_child_weight=9, classifier__n_estimators=151, classifier__subsample=0.9883347028410325\n",
      "[CV 1/5; 18/30] END classifier__colsample_bytree=0.5782308082130909, classifier__gamma=0.44612428386215064, classifier__learning_rate=0.0755440173387222, classifier__max_depth=28, classifier__min_child_weight=9, classifier__n_estimators=151, classifier__subsample=0.9883347028410325;, score=(train=0.957, test=0.901) total time=   0.3s\n",
      "[CV 2/5; 18/30] START classifier__colsample_bytree=0.5782308082130909, classifier__gamma=0.44612428386215064, classifier__learning_rate=0.0755440173387222, classifier__max_depth=28, classifier__min_child_weight=9, classifier__n_estimators=151, classifier__subsample=0.9883347028410325\n",
      "[CV 2/5; 18/30] END classifier__colsample_bytree=0.5782308082130909, classifier__gamma=0.44612428386215064, classifier__learning_rate=0.0755440173387222, classifier__max_depth=28, classifier__min_child_weight=9, classifier__n_estimators=151, classifier__subsample=0.9883347028410325;, score=(train=0.951, test=0.908) total time=   0.3s\n",
      "[CV 3/5; 18/30] START classifier__colsample_bytree=0.5782308082130909, classifier__gamma=0.44612428386215064, classifier__learning_rate=0.0755440173387222, classifier__max_depth=28, classifier__min_child_weight=9, classifier__n_estimators=151, classifier__subsample=0.9883347028410325\n",
      "[CV 3/5; 18/30] END classifier__colsample_bytree=0.5782308082130909, classifier__gamma=0.44612428386215064, classifier__learning_rate=0.0755440173387222, classifier__max_depth=28, classifier__min_child_weight=9, classifier__n_estimators=151, classifier__subsample=0.9883347028410325;, score=(train=0.957, test=0.927) total time=   0.3s\n",
      "[CV 4/5; 18/30] START classifier__colsample_bytree=0.5782308082130909, classifier__gamma=0.44612428386215064, classifier__learning_rate=0.0755440173387222, classifier__max_depth=28, classifier__min_child_weight=9, classifier__n_estimators=151, classifier__subsample=0.9883347028410325\n",
      "[CV 4/5; 18/30] END classifier__colsample_bytree=0.5782308082130909, classifier__gamma=0.44612428386215064, classifier__learning_rate=0.0755440173387222, classifier__max_depth=28, classifier__min_child_weight=9, classifier__n_estimators=151, classifier__subsample=0.9883347028410325;, score=(train=0.954, test=0.904) total time=   0.3s\n",
      "[CV 5/5; 18/30] START classifier__colsample_bytree=0.5782308082130909, classifier__gamma=0.44612428386215064, classifier__learning_rate=0.0755440173387222, classifier__max_depth=28, classifier__min_child_weight=9, classifier__n_estimators=151, classifier__subsample=0.9883347028410325\n",
      "[CV 5/5; 18/30] END classifier__colsample_bytree=0.5782308082130909, classifier__gamma=0.44612428386215064, classifier__learning_rate=0.0755440173387222, classifier__max_depth=28, classifier__min_child_weight=9, classifier__n_estimators=151, classifier__subsample=0.9883347028410325;, score=(train=0.955, test=0.914) total time=   0.3s\n",
      "[CV 1/5; 19/30] START classifier__colsample_bytree=0.6584346118471973, classifier__gamma=2.481510202998349, classifier__learning_rate=0.09062750614802531, classifier__max_depth=36, classifier__min_child_weight=5, classifier__n_estimators=417, classifier__subsample=0.5714116200449091\n",
      "[CV 1/5; 19/30] END classifier__colsample_bytree=0.6584346118471973, classifier__gamma=2.481510202998349, classifier__learning_rate=0.09062750614802531, classifier__max_depth=36, classifier__min_child_weight=5, classifier__n_estimators=417, classifier__subsample=0.5714116200449091;, score=(train=0.956, test=0.904) total time=   0.6s\n",
      "[CV 2/5; 19/30] START classifier__colsample_bytree=0.6584346118471973, classifier__gamma=2.481510202998349, classifier__learning_rate=0.09062750614802531, classifier__max_depth=36, classifier__min_child_weight=5, classifier__n_estimators=417, classifier__subsample=0.5714116200449091\n",
      "[CV 2/5; 19/30] END classifier__colsample_bytree=0.6584346118471973, classifier__gamma=2.481510202998349, classifier__learning_rate=0.09062750614802531, classifier__max_depth=36, classifier__min_child_weight=5, classifier__n_estimators=417, classifier__subsample=0.5714116200449091;, score=(train=0.959, test=0.912) total time=   0.6s\n",
      "[CV 3/5; 19/30] START classifier__colsample_bytree=0.6584346118471973, classifier__gamma=2.481510202998349, classifier__learning_rate=0.09062750614802531, classifier__max_depth=36, classifier__min_child_weight=5, classifier__n_estimators=417, classifier__subsample=0.5714116200449091\n",
      "[CV 3/5; 19/30] END classifier__colsample_bytree=0.6584346118471973, classifier__gamma=2.481510202998349, classifier__learning_rate=0.09062750614802531, classifier__max_depth=36, classifier__min_child_weight=5, classifier__n_estimators=417, classifier__subsample=0.5714116200449091;, score=(train=0.954, test=0.924) total time=   0.6s\n",
      "[CV 4/5; 19/30] START classifier__colsample_bytree=0.6584346118471973, classifier__gamma=2.481510202998349, classifier__learning_rate=0.09062750614802531, classifier__max_depth=36, classifier__min_child_weight=5, classifier__n_estimators=417, classifier__subsample=0.5714116200449091\n",
      "[CV 4/5; 19/30] END classifier__colsample_bytree=0.6584346118471973, classifier__gamma=2.481510202998349, classifier__learning_rate=0.09062750614802531, classifier__max_depth=36, classifier__min_child_weight=5, classifier__n_estimators=417, classifier__subsample=0.5714116200449091;, score=(train=0.966, test=0.901) total time=   0.6s\n",
      "[CV 5/5; 19/30] START classifier__colsample_bytree=0.6584346118471973, classifier__gamma=2.481510202998349, classifier__learning_rate=0.09062750614802531, classifier__max_depth=36, classifier__min_child_weight=5, classifier__n_estimators=417, classifier__subsample=0.5714116200449091\n",
      "[CV 5/5; 19/30] END classifier__colsample_bytree=0.6584346118471973, classifier__gamma=2.481510202998349, classifier__learning_rate=0.09062750614802531, classifier__max_depth=36, classifier__min_child_weight=5, classifier__n_estimators=417, classifier__subsample=0.5714116200449091;, score=(train=0.963, test=0.916) total time=   0.6s\n",
      "[CV 1/5; 20/30] START classifier__colsample_bytree=0.7359127367119344, classifier__gamma=0.22003540609320438, classifier__learning_rate=0.0547351846514935, classifier__max_depth=41, classifier__min_child_weight=4, classifier__n_estimators=157, classifier__subsample=0.6071622565650958\n",
      "[CV 1/5; 20/30] END classifier__colsample_bytree=0.7359127367119344, classifier__gamma=0.22003540609320438, classifier__learning_rate=0.0547351846514935, classifier__max_depth=41, classifier__min_child_weight=4, classifier__n_estimators=157, classifier__subsample=0.6071622565650958;, score=(train=0.956, test=0.898) total time=   0.3s\n",
      "[CV 2/5; 20/30] START classifier__colsample_bytree=0.7359127367119344, classifier__gamma=0.22003540609320438, classifier__learning_rate=0.0547351846514935, classifier__max_depth=41, classifier__min_child_weight=4, classifier__n_estimators=157, classifier__subsample=0.6071622565650958\n",
      "[CV 2/5; 20/30] END classifier__colsample_bytree=0.7359127367119344, classifier__gamma=0.22003540609320438, classifier__learning_rate=0.0547351846514935, classifier__max_depth=41, classifier__min_child_weight=4, classifier__n_estimators=157, classifier__subsample=0.6071622565650958;, score=(train=0.958, test=0.918) total time=   0.3s\n",
      "[CV 3/5; 20/30] START classifier__colsample_bytree=0.7359127367119344, classifier__gamma=0.22003540609320438, classifier__learning_rate=0.0547351846514935, classifier__max_depth=41, classifier__min_child_weight=4, classifier__n_estimators=157, classifier__subsample=0.6071622565650958\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 20/30] END classifier__colsample_bytree=0.7359127367119344, classifier__gamma=0.22003540609320438, classifier__learning_rate=0.0547351846514935, classifier__max_depth=41, classifier__min_child_weight=4, classifier__n_estimators=157, classifier__subsample=0.6071622565650958;, score=(train=0.958, test=0.935) total time=   0.3s\n",
      "[CV 4/5; 20/30] START classifier__colsample_bytree=0.7359127367119344, classifier__gamma=0.22003540609320438, classifier__learning_rate=0.0547351846514935, classifier__max_depth=41, classifier__min_child_weight=4, classifier__n_estimators=157, classifier__subsample=0.6071622565650958\n",
      "[CV 4/5; 20/30] END classifier__colsample_bytree=0.7359127367119344, classifier__gamma=0.22003540609320438, classifier__learning_rate=0.0547351846514935, classifier__max_depth=41, classifier__min_child_weight=4, classifier__n_estimators=157, classifier__subsample=0.6071622565650958;, score=(train=0.953, test=0.908) total time=   0.3s\n",
      "[CV 5/5; 20/30] START classifier__colsample_bytree=0.7359127367119344, classifier__gamma=0.22003540609320438, classifier__learning_rate=0.0547351846514935, classifier__max_depth=41, classifier__min_child_weight=4, classifier__n_estimators=157, classifier__subsample=0.6071622565650958\n",
      "[CV 5/5; 20/30] END classifier__colsample_bytree=0.7359127367119344, classifier__gamma=0.22003540609320438, classifier__learning_rate=0.0547351846514935, classifier__max_depth=41, classifier__min_child_weight=4, classifier__n_estimators=157, classifier__subsample=0.6071622565650958;, score=(train=0.957, test=0.916) total time=   0.3s\n",
      "[CV 1/5; 21/30] START classifier__colsample_bytree=0.6813181011669082, classifier__gamma=2.1121289642549477, classifier__learning_rate=0.04268766891882211, classifier__max_depth=34, classifier__min_child_weight=4, classifier__n_estimators=298, classifier__subsample=0.5808753760177647\n",
      "[CV 1/5; 21/30] END classifier__colsample_bytree=0.6813181011669082, classifier__gamma=2.1121289642549477, classifier__learning_rate=0.04268766891882211, classifier__max_depth=34, classifier__min_child_weight=4, classifier__n_estimators=298, classifier__subsample=0.5808753760177647;, score=(train=0.954, test=0.889) total time=   0.5s\n",
      "[CV 2/5; 21/30] START classifier__colsample_bytree=0.6813181011669082, classifier__gamma=2.1121289642549477, classifier__learning_rate=0.04268766891882211, classifier__max_depth=34, classifier__min_child_weight=4, classifier__n_estimators=298, classifier__subsample=0.5808753760177647\n",
      "[CV 2/5; 21/30] END classifier__colsample_bytree=0.6813181011669082, classifier__gamma=2.1121289642549477, classifier__learning_rate=0.04268766891882211, classifier__max_depth=34, classifier__min_child_weight=4, classifier__n_estimators=298, classifier__subsample=0.5808753760177647;, score=(train=0.954, test=0.917) total time=   0.6s\n",
      "[CV 3/5; 21/30] START classifier__colsample_bytree=0.6813181011669082, classifier__gamma=2.1121289642549477, classifier__learning_rate=0.04268766891882211, classifier__max_depth=34, classifier__min_child_weight=4, classifier__n_estimators=298, classifier__subsample=0.5808753760177647\n",
      "[CV 3/5; 21/30] END classifier__colsample_bytree=0.6813181011669082, classifier__gamma=2.1121289642549477, classifier__learning_rate=0.04268766891882211, classifier__max_depth=34, classifier__min_child_weight=4, classifier__n_estimators=298, classifier__subsample=0.5808753760177647;, score=(train=0.957, test=0.928) total time=   0.5s\n",
      "[CV 4/5; 21/30] START classifier__colsample_bytree=0.6813181011669082, classifier__gamma=2.1121289642549477, classifier__learning_rate=0.04268766891882211, classifier__max_depth=34, classifier__min_child_weight=4, classifier__n_estimators=298, classifier__subsample=0.5808753760177647\n",
      "[CV 4/5; 21/30] END classifier__colsample_bytree=0.6813181011669082, classifier__gamma=2.1121289642549477, classifier__learning_rate=0.04268766891882211, classifier__max_depth=34, classifier__min_child_weight=4, classifier__n_estimators=298, classifier__subsample=0.5808753760177647;, score=(train=0.954, test=0.910) total time=   0.5s\n",
      "[CV 5/5; 21/30] START classifier__colsample_bytree=0.6813181011669082, classifier__gamma=2.1121289642549477, classifier__learning_rate=0.04268766891882211, classifier__max_depth=34, classifier__min_child_weight=4, classifier__n_estimators=298, classifier__subsample=0.5808753760177647\n",
      "[CV 5/5; 21/30] END classifier__colsample_bytree=0.6813181011669082, classifier__gamma=2.1121289642549477, classifier__learning_rate=0.04268766891882211, classifier__max_depth=34, classifier__min_child_weight=4, classifier__n_estimators=298, classifier__subsample=0.5808753760177647;, score=(train=0.955, test=0.920) total time=   0.5s\n",
      "[CV 1/5; 22/30] START classifier__colsample_bytree=0.6290057073589013, classifier__gamma=0.03246503897015196, classifier__learning_rate=0.049191739615084495, classifier__max_depth=28, classifier__min_child_weight=3, classifier__n_estimators=151, classifier__subsample=0.83745380232335\n",
      "[CV 1/5; 22/30] END classifier__colsample_bytree=0.6290057073589013, classifier__gamma=0.03246503897015196, classifier__learning_rate=0.049191739615084495, classifier__max_depth=28, classifier__min_child_weight=3, classifier__n_estimators=151, classifier__subsample=0.83745380232335;, score=(train=0.968, test=0.893) total time=   0.4s\n",
      "[CV 2/5; 22/30] START classifier__colsample_bytree=0.6290057073589013, classifier__gamma=0.03246503897015196, classifier__learning_rate=0.049191739615084495, classifier__max_depth=28, classifier__min_child_weight=3, classifier__n_estimators=151, classifier__subsample=0.83745380232335\n",
      "[CV 2/5; 22/30] END classifier__colsample_bytree=0.6290057073589013, classifier__gamma=0.03246503897015196, classifier__learning_rate=0.049191739615084495, classifier__max_depth=28, classifier__min_child_weight=3, classifier__n_estimators=151, classifier__subsample=0.83745380232335;, score=(train=0.968, test=0.918) total time=   0.4s\n",
      "[CV 3/5; 22/30] START classifier__colsample_bytree=0.6290057073589013, classifier__gamma=0.03246503897015196, classifier__learning_rate=0.049191739615084495, classifier__max_depth=28, classifier__min_child_weight=3, classifier__n_estimators=151, classifier__subsample=0.83745380232335\n",
      "[CV 3/5; 22/30] END classifier__colsample_bytree=0.6290057073589013, classifier__gamma=0.03246503897015196, classifier__learning_rate=0.049191739615084495, classifier__max_depth=28, classifier__min_child_weight=3, classifier__n_estimators=151, classifier__subsample=0.83745380232335;, score=(train=0.965, test=0.925) total time=   0.4s\n",
      "[CV 4/5; 22/30] START classifier__colsample_bytree=0.6290057073589013, classifier__gamma=0.03246503897015196, classifier__learning_rate=0.049191739615084495, classifier__max_depth=28, classifier__min_child_weight=3, classifier__n_estimators=151, classifier__subsample=0.83745380232335\n",
      "[CV 4/5; 22/30] END classifier__colsample_bytree=0.6290057073589013, classifier__gamma=0.03246503897015196, classifier__learning_rate=0.049191739615084495, classifier__max_depth=28, classifier__min_child_weight=3, classifier__n_estimators=151, classifier__subsample=0.83745380232335;, score=(train=0.968, test=0.904) total time=   0.4s\n",
      "[CV 5/5; 22/30] START classifier__colsample_bytree=0.6290057073589013, classifier__gamma=0.03246503897015196, classifier__learning_rate=0.049191739615084495, classifier__max_depth=28, classifier__min_child_weight=3, classifier__n_estimators=151, classifier__subsample=0.83745380232335\n",
      "[CV 5/5; 22/30] END classifier__colsample_bytree=0.6290057073589013, classifier__gamma=0.03246503897015196, classifier__learning_rate=0.049191739615084495, classifier__max_depth=28, classifier__min_child_weight=3, classifier__n_estimators=151, classifier__subsample=0.83745380232335;, score=(train=0.968, test=0.918) total time=   0.4s\n",
      "[CV 1/5; 23/30] START classifier__colsample_bytree=0.8244274203120341, classifier__gamma=0.8728566349129842, classifier__learning_rate=0.025822874738277057, classifier__max_depth=36, classifier__min_child_weight=9, classifier__n_estimators=228, classifier__subsample=0.8723888102902226\n",
      "[CV 1/5; 23/30] END classifier__colsample_bytree=0.8244274203120341, classifier__gamma=0.8728566349129842, classifier__learning_rate=0.025822874738277057, classifier__max_depth=36, classifier__min_child_weight=9, classifier__n_estimators=228, classifier__subsample=0.8723888102902226;, score=(train=0.941, test=0.895) total time=   0.4s\n",
      "[CV 2/5; 23/30] START classifier__colsample_bytree=0.8244274203120341, classifier__gamma=0.8728566349129842, classifier__learning_rate=0.025822874738277057, classifier__max_depth=36, classifier__min_child_weight=9, classifier__n_estimators=228, classifier__subsample=0.8723888102902226\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 23/30] END classifier__colsample_bytree=0.8244274203120341, classifier__gamma=0.8728566349129842, classifier__learning_rate=0.025822874738277057, classifier__max_depth=36, classifier__min_child_weight=9, classifier__n_estimators=228, classifier__subsample=0.8723888102902226;, score=(train=0.937, test=0.905) total time=   0.5s\n",
      "[CV 3/5; 23/30] START classifier__colsample_bytree=0.8244274203120341, classifier__gamma=0.8728566349129842, classifier__learning_rate=0.025822874738277057, classifier__max_depth=36, classifier__min_child_weight=9, classifier__n_estimators=228, classifier__subsample=0.8723888102902226\n",
      "[CV 3/5; 23/30] END classifier__colsample_bytree=0.8244274203120341, classifier__gamma=0.8728566349129842, classifier__learning_rate=0.025822874738277057, classifier__max_depth=36, classifier__min_child_weight=9, classifier__n_estimators=228, classifier__subsample=0.8723888102902226;, score=(train=0.939, test=0.931) total time=   0.5s\n",
      "[CV 4/5; 23/30] START classifier__colsample_bytree=0.8244274203120341, classifier__gamma=0.8728566349129842, classifier__learning_rate=0.025822874738277057, classifier__max_depth=36, classifier__min_child_weight=9, classifier__n_estimators=228, classifier__subsample=0.8723888102902226\n",
      "[CV 4/5; 23/30] END classifier__colsample_bytree=0.8244274203120341, classifier__gamma=0.8728566349129842, classifier__learning_rate=0.025822874738277057, classifier__max_depth=36, classifier__min_child_weight=9, classifier__n_estimators=228, classifier__subsample=0.8723888102902226;, score=(train=0.942, test=0.898) total time=   0.4s\n",
      "[CV 5/5; 23/30] START classifier__colsample_bytree=0.8244274203120341, classifier__gamma=0.8728566349129842, classifier__learning_rate=0.025822874738277057, classifier__max_depth=36, classifier__min_child_weight=9, classifier__n_estimators=228, classifier__subsample=0.8723888102902226\n",
      "[CV 5/5; 23/30] END classifier__colsample_bytree=0.8244274203120341, classifier__gamma=0.8728566349129842, classifier__learning_rate=0.025822874738277057, classifier__max_depth=36, classifier__min_child_weight=9, classifier__n_estimators=228, classifier__subsample=0.8723888102902226;, score=(train=0.947, test=0.910) total time=   0.4s\n",
      "[CV 1/5; 24/30] START classifier__colsample_bytree=0.6854430795214541, classifier__gamma=1.1658590890946319, classifier__learning_rate=0.01552297977522785, classifier__max_depth=17, classifier__min_child_weight=1, classifier__n_estimators=258, classifier__subsample=0.7825760799855124\n",
      "[CV 1/5; 24/30] END classifier__colsample_bytree=0.6854430795214541, classifier__gamma=1.1658590890946319, classifier__learning_rate=0.01552297977522785, classifier__max_depth=17, classifier__min_child_weight=1, classifier__n_estimators=258, classifier__subsample=0.7825760799855124;, score=(train=0.963, test=0.899) total time=   0.8s\n",
      "[CV 2/5; 24/30] START classifier__colsample_bytree=0.6854430795214541, classifier__gamma=1.1658590890946319, classifier__learning_rate=0.01552297977522785, classifier__max_depth=17, classifier__min_child_weight=1, classifier__n_estimators=258, classifier__subsample=0.7825760799855124\n",
      "[CV 2/5; 24/30] END classifier__colsample_bytree=0.6854430795214541, classifier__gamma=1.1658590890946319, classifier__learning_rate=0.01552297977522785, classifier__max_depth=17, classifier__min_child_weight=1, classifier__n_estimators=258, classifier__subsample=0.7825760799855124;, score=(train=0.964, test=0.920) total time=   0.8s\n",
      "[CV 3/5; 24/30] START classifier__colsample_bytree=0.6854430795214541, classifier__gamma=1.1658590890946319, classifier__learning_rate=0.01552297977522785, classifier__max_depth=17, classifier__min_child_weight=1, classifier__n_estimators=258, classifier__subsample=0.7825760799855124\n",
      "[CV 3/5; 24/30] END classifier__colsample_bytree=0.6854430795214541, classifier__gamma=1.1658590890946319, classifier__learning_rate=0.01552297977522785, classifier__max_depth=17, classifier__min_child_weight=1, classifier__n_estimators=258, classifier__subsample=0.7825760799855124;, score=(train=0.963, test=0.928) total time=   0.9s\n",
      "[CV 4/5; 24/30] START classifier__colsample_bytree=0.6854430795214541, classifier__gamma=1.1658590890946319, classifier__learning_rate=0.01552297977522785, classifier__max_depth=17, classifier__min_child_weight=1, classifier__n_estimators=258, classifier__subsample=0.7825760799855124\n",
      "[CV 4/5; 24/30] END classifier__colsample_bytree=0.6854430795214541, classifier__gamma=1.1658590890946319, classifier__learning_rate=0.01552297977522785, classifier__max_depth=17, classifier__min_child_weight=1, classifier__n_estimators=258, classifier__subsample=0.7825760799855124;, score=(train=0.965, test=0.912) total time=   0.8s\n",
      "[CV 5/5; 24/30] START classifier__colsample_bytree=0.6854430795214541, classifier__gamma=1.1658590890946319, classifier__learning_rate=0.01552297977522785, classifier__max_depth=17, classifier__min_child_weight=1, classifier__n_estimators=258, classifier__subsample=0.7825760799855124\n",
      "[CV 5/5; 24/30] END classifier__colsample_bytree=0.6854430795214541, classifier__gamma=1.1658590890946319, classifier__learning_rate=0.01552297977522785, classifier__max_depth=17, classifier__min_child_weight=1, classifier__n_estimators=258, classifier__subsample=0.7825760799855124;, score=(train=0.963, test=0.917) total time=   0.8s\n",
      "[CV 1/5; 25/30] START classifier__colsample_bytree=0.7088295829917566, classifier__gamma=1.8400399378649264, classifier__learning_rate=0.006305536860378919, classifier__max_depth=36, classifier__min_child_weight=4, classifier__n_estimators=190, classifier__subsample=0.7333902187961578\n",
      "[CV 1/5; 25/30] END classifier__colsample_bytree=0.7088295829917566, classifier__gamma=1.8400399378649264, classifier__learning_rate=0.006305536860378919, classifier__max_depth=36, classifier__min_child_weight=4, classifier__n_estimators=190, classifier__subsample=0.7333902187961578;, score=(train=0.926, test=0.894) total time=   0.4s\n",
      "[CV 2/5; 25/30] START classifier__colsample_bytree=0.7088295829917566, classifier__gamma=1.8400399378649264, classifier__learning_rate=0.006305536860378919, classifier__max_depth=36, classifier__min_child_weight=4, classifier__n_estimators=190, classifier__subsample=0.7333902187961578\n",
      "[CV 2/5; 25/30] END classifier__colsample_bytree=0.7088295829917566, classifier__gamma=1.8400399378649264, classifier__learning_rate=0.006305536860378919, classifier__max_depth=36, classifier__min_child_weight=4, classifier__n_estimators=190, classifier__subsample=0.7333902187961578;, score=(train=0.926, test=0.901) total time=   0.4s\n",
      "[CV 3/5; 25/30] START classifier__colsample_bytree=0.7088295829917566, classifier__gamma=1.8400399378649264, classifier__learning_rate=0.006305536860378919, classifier__max_depth=36, classifier__min_child_weight=4, classifier__n_estimators=190, classifier__subsample=0.7333902187961578\n",
      "[CV 3/5; 25/30] END classifier__colsample_bytree=0.7088295829917566, classifier__gamma=1.8400399378649264, classifier__learning_rate=0.006305536860378919, classifier__max_depth=36, classifier__min_child_weight=4, classifier__n_estimators=190, classifier__subsample=0.7333902187961578;, score=(train=0.929, test=0.916) total time=   0.4s\n",
      "[CV 4/5; 25/30] START classifier__colsample_bytree=0.7088295829917566, classifier__gamma=1.8400399378649264, classifier__learning_rate=0.006305536860378919, classifier__max_depth=36, classifier__min_child_weight=4, classifier__n_estimators=190, classifier__subsample=0.7333902187961578\n",
      "[CV 4/5; 25/30] END classifier__colsample_bytree=0.7088295829917566, classifier__gamma=1.8400399378649264, classifier__learning_rate=0.006305536860378919, classifier__max_depth=36, classifier__min_child_weight=4, classifier__n_estimators=190, classifier__subsample=0.7333902187961578;, score=(train=0.924, test=0.889) total time=   0.4s\n",
      "[CV 5/5; 25/30] START classifier__colsample_bytree=0.7088295829917566, classifier__gamma=1.8400399378649264, classifier__learning_rate=0.006305536860378919, classifier__max_depth=36, classifier__min_child_weight=4, classifier__n_estimators=190, classifier__subsample=0.7333902187961578\n",
      "[CV 5/5; 25/30] END classifier__colsample_bytree=0.7088295829917566, classifier__gamma=1.8400399378649264, classifier__learning_rate=0.006305536860378919, classifier__max_depth=36, classifier__min_child_weight=4, classifier__n_estimators=190, classifier__subsample=0.7333902187961578;, score=(train=0.930, test=0.916) total time=   0.4s\n",
      "[CV 1/5; 26/30] START classifier__colsample_bytree=0.5118355316223766, classifier__gamma=1.172176051325492, classifier__learning_rate=0.08870155313242449, classifier__max_depth=21, classifier__min_child_weight=5, classifier__n_estimators=271, classifier__subsample=0.6427889534869482\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 26/30] END classifier__colsample_bytree=0.5118355316223766, classifier__gamma=1.172176051325492, classifier__learning_rate=0.08870155313242449, classifier__max_depth=21, classifier__min_child_weight=5, classifier__n_estimators=271, classifier__subsample=0.6427889534869482;, score=(train=0.958, test=0.898) total time=   0.4s\n",
      "[CV 2/5; 26/30] START classifier__colsample_bytree=0.5118355316223766, classifier__gamma=1.172176051325492, classifier__learning_rate=0.08870155313242449, classifier__max_depth=21, classifier__min_child_weight=5, classifier__n_estimators=271, classifier__subsample=0.6427889534869482\n",
      "[CV 2/5; 26/30] END classifier__colsample_bytree=0.5118355316223766, classifier__gamma=1.172176051325492, classifier__learning_rate=0.08870155313242449, classifier__max_depth=21, classifier__min_child_weight=5, classifier__n_estimators=271, classifier__subsample=0.6427889534869482;, score=(train=0.966, test=0.916) total time=   0.4s\n",
      "[CV 3/5; 26/30] START classifier__colsample_bytree=0.5118355316223766, classifier__gamma=1.172176051325492, classifier__learning_rate=0.08870155313242449, classifier__max_depth=21, classifier__min_child_weight=5, classifier__n_estimators=271, classifier__subsample=0.6427889534869482\n",
      "[CV 3/5; 26/30] END classifier__colsample_bytree=0.5118355316223766, classifier__gamma=1.172176051325492, classifier__learning_rate=0.08870155313242449, classifier__max_depth=21, classifier__min_child_weight=5, classifier__n_estimators=271, classifier__subsample=0.6427889534869482;, score=(train=0.962, test=0.920) total time=   0.4s\n",
      "[CV 4/5; 26/30] START classifier__colsample_bytree=0.5118355316223766, classifier__gamma=1.172176051325492, classifier__learning_rate=0.08870155313242449, classifier__max_depth=21, classifier__min_child_weight=5, classifier__n_estimators=271, classifier__subsample=0.6427889534869482\n",
      "[CV 4/5; 26/30] END classifier__colsample_bytree=0.5118355316223766, classifier__gamma=1.172176051325492, classifier__learning_rate=0.08870155313242449, classifier__max_depth=21, classifier__min_child_weight=5, classifier__n_estimators=271, classifier__subsample=0.6427889534869482;, score=(train=0.962, test=0.916) total time=   0.4s\n",
      "[CV 5/5; 26/30] START classifier__colsample_bytree=0.5118355316223766, classifier__gamma=1.172176051325492, classifier__learning_rate=0.08870155313242449, classifier__max_depth=21, classifier__min_child_weight=5, classifier__n_estimators=271, classifier__subsample=0.6427889534869482\n",
      "[CV 5/5; 26/30] END classifier__colsample_bytree=0.5118355316223766, classifier__gamma=1.172176051325492, classifier__learning_rate=0.08870155313242449, classifier__max_depth=21, classifier__min_child_weight=5, classifier__n_estimators=271, classifier__subsample=0.6427889534869482;, score=(train=0.961, test=0.906) total time=   0.4s\n",
      "[CV 1/5; 27/30] START classifier__colsample_bytree=0.6468095789770587, classifier__gamma=1.7072791548469521, classifier__learning_rate=0.05868992297790477, classifier__max_depth=34, classifier__min_child_weight=10, classifier__n_estimators=409, classifier__subsample=0.9104848678499233\n",
      "[CV 1/5; 27/30] END classifier__colsample_bytree=0.6468095789770587, classifier__gamma=1.7072791548469521, classifier__learning_rate=0.05868992297790477, classifier__max_depth=34, classifier__min_child_weight=10, classifier__n_estimators=409, classifier__subsample=0.9104848678499233;, score=(train=0.955, test=0.897) total time=   0.7s\n",
      "[CV 2/5; 27/30] START classifier__colsample_bytree=0.6468095789770587, classifier__gamma=1.7072791548469521, classifier__learning_rate=0.05868992297790477, classifier__max_depth=34, classifier__min_child_weight=10, classifier__n_estimators=409, classifier__subsample=0.9104848678499233\n",
      "[CV 2/5; 27/30] END classifier__colsample_bytree=0.6468095789770587, classifier__gamma=1.7072791548469521, classifier__learning_rate=0.05868992297790477, classifier__max_depth=34, classifier__min_child_weight=10, classifier__n_estimators=409, classifier__subsample=0.9104848678499233;, score=(train=0.957, test=0.909) total time=   0.7s\n",
      "[CV 3/5; 27/30] START classifier__colsample_bytree=0.6468095789770587, classifier__gamma=1.7072791548469521, classifier__learning_rate=0.05868992297790477, classifier__max_depth=34, classifier__min_child_weight=10, classifier__n_estimators=409, classifier__subsample=0.9104848678499233\n",
      "[CV 3/5; 27/30] END classifier__colsample_bytree=0.6468095789770587, classifier__gamma=1.7072791548469521, classifier__learning_rate=0.05868992297790477, classifier__max_depth=34, classifier__min_child_weight=10, classifier__n_estimators=409, classifier__subsample=0.9104848678499233;, score=(train=0.957, test=0.925) total time=   0.7s\n",
      "[CV 4/5; 27/30] START classifier__colsample_bytree=0.6468095789770587, classifier__gamma=1.7072791548469521, classifier__learning_rate=0.05868992297790477, classifier__max_depth=34, classifier__min_child_weight=10, classifier__n_estimators=409, classifier__subsample=0.9104848678499233\n",
      "[CV 4/5; 27/30] END classifier__colsample_bytree=0.6468095789770587, classifier__gamma=1.7072791548469521, classifier__learning_rate=0.05868992297790477, classifier__max_depth=34, classifier__min_child_weight=10, classifier__n_estimators=409, classifier__subsample=0.9104848678499233;, score=(train=0.956, test=0.906) total time=   0.7s\n",
      "[CV 5/5; 27/30] START classifier__colsample_bytree=0.6468095789770587, classifier__gamma=1.7072791548469521, classifier__learning_rate=0.05868992297790477, classifier__max_depth=34, classifier__min_child_weight=10, classifier__n_estimators=409, classifier__subsample=0.9104848678499233\n",
      "[CV 5/5; 27/30] END classifier__colsample_bytree=0.6468095789770587, classifier__gamma=1.7072791548469521, classifier__learning_rate=0.05868992297790477, classifier__max_depth=34, classifier__min_child_weight=10, classifier__n_estimators=409, classifier__subsample=0.9104848678499233;, score=(train=0.958, test=0.920) total time=   0.7s\n",
      "[CV 1/5; 28/30] START classifier__colsample_bytree=0.612113199179739, classifier__gamma=0.15977103771821055, classifier__learning_rate=0.08215847284767916, classifier__max_depth=25, classifier__min_child_weight=8, classifier__n_estimators=441, classifier__subsample=0.6905268340496735\n",
      "[CV 1/5; 28/30] END classifier__colsample_bytree=0.612113199179739, classifier__gamma=0.15977103771821055, classifier__learning_rate=0.08215847284767916, classifier__max_depth=25, classifier__min_child_weight=8, classifier__n_estimators=441, classifier__subsample=0.6905268340496735;, score=(train=0.964, test=0.902) total time=   0.6s\n",
      "[CV 2/5; 28/30] START classifier__colsample_bytree=0.612113199179739, classifier__gamma=0.15977103771821055, classifier__learning_rate=0.08215847284767916, classifier__max_depth=25, classifier__min_child_weight=8, classifier__n_estimators=441, classifier__subsample=0.6905268340496735\n",
      "[CV 2/5; 28/30] END classifier__colsample_bytree=0.612113199179739, classifier__gamma=0.15977103771821055, classifier__learning_rate=0.08215847284767916, classifier__max_depth=25, classifier__min_child_weight=8, classifier__n_estimators=441, classifier__subsample=0.6905268340496735;, score=(train=0.961, test=0.909) total time=   0.6s\n",
      "[CV 3/5; 28/30] START classifier__colsample_bytree=0.612113199179739, classifier__gamma=0.15977103771821055, classifier__learning_rate=0.08215847284767916, classifier__max_depth=25, classifier__min_child_weight=8, classifier__n_estimators=441, classifier__subsample=0.6905268340496735\n",
      "[CV 3/5; 28/30] END classifier__colsample_bytree=0.612113199179739, classifier__gamma=0.15977103771821055, classifier__learning_rate=0.08215847284767916, classifier__max_depth=25, classifier__min_child_weight=8, classifier__n_estimators=441, classifier__subsample=0.6905268340496735;, score=(train=0.958, test=0.931) total time=   0.6s\n",
      "[CV 4/5; 28/30] START classifier__colsample_bytree=0.612113199179739, classifier__gamma=0.15977103771821055, classifier__learning_rate=0.08215847284767916, classifier__max_depth=25, classifier__min_child_weight=8, classifier__n_estimators=441, classifier__subsample=0.6905268340496735\n",
      "[CV 4/5; 28/30] END classifier__colsample_bytree=0.612113199179739, classifier__gamma=0.15977103771821055, classifier__learning_rate=0.08215847284767916, classifier__max_depth=25, classifier__min_child_weight=8, classifier__n_estimators=441, classifier__subsample=0.6905268340496735;, score=(train=0.964, test=0.905) total time=   0.6s\n",
      "[CV 5/5; 28/30] START classifier__colsample_bytree=0.612113199179739, classifier__gamma=0.15977103771821055, classifier__learning_rate=0.08215847284767916, classifier__max_depth=25, classifier__min_child_weight=8, classifier__n_estimators=441, classifier__subsample=0.6905268340496735\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 28/30] END classifier__colsample_bytree=0.612113199179739, classifier__gamma=0.15977103771821055, classifier__learning_rate=0.08215847284767916, classifier__max_depth=25, classifier__min_child_weight=8, classifier__n_estimators=441, classifier__subsample=0.6905268340496735;, score=(train=0.962, test=0.924) total time=   0.6s\n",
      "[CV 1/5; 29/30] START classifier__colsample_bytree=0.5950954904203856, classifier__gamma=1.4697875705193713, classifier__learning_rate=0.041752248398231565, classifier__max_depth=42, classifier__min_child_weight=4, classifier__n_estimators=178, classifier__subsample=0.5842935288147577\n",
      "[CV 1/5; 29/30] END classifier__colsample_bytree=0.5950954904203856, classifier__gamma=1.4697875705193713, classifier__learning_rate=0.041752248398231565, classifier__max_depth=42, classifier__min_child_weight=4, classifier__n_estimators=178, classifier__subsample=0.5842935288147577;, score=(train=0.946, test=0.893) total time=   0.3s\n",
      "[CV 2/5; 29/30] START classifier__colsample_bytree=0.5950954904203856, classifier__gamma=1.4697875705193713, classifier__learning_rate=0.041752248398231565, classifier__max_depth=42, classifier__min_child_weight=4, classifier__n_estimators=178, classifier__subsample=0.5842935288147577\n",
      "[CV 2/5; 29/30] END classifier__colsample_bytree=0.5950954904203856, classifier__gamma=1.4697875705193713, classifier__learning_rate=0.041752248398231565, classifier__max_depth=42, classifier__min_child_weight=4, classifier__n_estimators=178, classifier__subsample=0.5842935288147577;, score=(train=0.946, test=0.920) total time=   0.3s\n",
      "[CV 3/5; 29/30] START classifier__colsample_bytree=0.5950954904203856, classifier__gamma=1.4697875705193713, classifier__learning_rate=0.041752248398231565, classifier__max_depth=42, classifier__min_child_weight=4, classifier__n_estimators=178, classifier__subsample=0.5842935288147577\n",
      "[CV 3/5; 29/30] END classifier__colsample_bytree=0.5950954904203856, classifier__gamma=1.4697875705193713, classifier__learning_rate=0.041752248398231565, classifier__max_depth=42, classifier__min_child_weight=4, classifier__n_estimators=178, classifier__subsample=0.5842935288147577;, score=(train=0.949, test=0.929) total time=   0.3s\n",
      "[CV 4/5; 29/30] START classifier__colsample_bytree=0.5950954904203856, classifier__gamma=1.4697875705193713, classifier__learning_rate=0.041752248398231565, classifier__max_depth=42, classifier__min_child_weight=4, classifier__n_estimators=178, classifier__subsample=0.5842935288147577\n",
      "[CV 4/5; 29/30] END classifier__colsample_bytree=0.5950954904203856, classifier__gamma=1.4697875705193713, classifier__learning_rate=0.041752248398231565, classifier__max_depth=42, classifier__min_child_weight=4, classifier__n_estimators=178, classifier__subsample=0.5842935288147577;, score=(train=0.949, test=0.906) total time=   0.3s\n",
      "[CV 5/5; 29/30] START classifier__colsample_bytree=0.5950954904203856, classifier__gamma=1.4697875705193713, classifier__learning_rate=0.041752248398231565, classifier__max_depth=42, classifier__min_child_weight=4, classifier__n_estimators=178, classifier__subsample=0.5842935288147577\n",
      "[CV 5/5; 29/30] END classifier__colsample_bytree=0.5950954904203856, classifier__gamma=1.4697875705193713, classifier__learning_rate=0.041752248398231565, classifier__max_depth=42, classifier__min_child_weight=4, classifier__n_estimators=178, classifier__subsample=0.5842935288147577;, score=(train=0.948, test=0.921) total time=   0.3s\n",
      "[CV 1/5; 30/30] START classifier__colsample_bytree=0.9609438104098937, classifier__gamma=1.960123365573096, classifier__learning_rate=0.05257400670369904, classifier__max_depth=19, classifier__min_child_weight=6, classifier__n_estimators=309, classifier__subsample=0.8522681954443808\n",
      "[CV 1/5; 30/30] END classifier__colsample_bytree=0.9609438104098937, classifier__gamma=1.960123365573096, classifier__learning_rate=0.05257400670369904, classifier__max_depth=19, classifier__min_child_weight=6, classifier__n_estimators=309, classifier__subsample=0.8522681954443808;, score=(train=0.963, test=0.902) total time=   0.6s\n",
      "[CV 2/5; 30/30] START classifier__colsample_bytree=0.9609438104098937, classifier__gamma=1.960123365573096, classifier__learning_rate=0.05257400670369904, classifier__max_depth=19, classifier__min_child_weight=6, classifier__n_estimators=309, classifier__subsample=0.8522681954443808\n",
      "[CV 2/5; 30/30] END classifier__colsample_bytree=0.9609438104098937, classifier__gamma=1.960123365573096, classifier__learning_rate=0.05257400670369904, classifier__max_depth=19, classifier__min_child_weight=6, classifier__n_estimators=309, classifier__subsample=0.8522681954443808;, score=(train=0.963, test=0.924) total time=   0.6s\n",
      "[CV 3/5; 30/30] START classifier__colsample_bytree=0.9609438104098937, classifier__gamma=1.960123365573096, classifier__learning_rate=0.05257400670369904, classifier__max_depth=19, classifier__min_child_weight=6, classifier__n_estimators=309, classifier__subsample=0.8522681954443808\n",
      "[CV 3/5; 30/30] END classifier__colsample_bytree=0.9609438104098937, classifier__gamma=1.960123365573096, classifier__learning_rate=0.05257400670369904, classifier__max_depth=19, classifier__min_child_weight=6, classifier__n_estimators=309, classifier__subsample=0.8522681954443808;, score=(train=0.966, test=0.933) total time=   0.6s\n",
      "[CV 4/5; 30/30] START classifier__colsample_bytree=0.9609438104098937, classifier__gamma=1.960123365573096, classifier__learning_rate=0.05257400670369904, classifier__max_depth=19, classifier__min_child_weight=6, classifier__n_estimators=309, classifier__subsample=0.8522681954443808\n",
      "[CV 4/5; 30/30] END classifier__colsample_bytree=0.9609438104098937, classifier__gamma=1.960123365573096, classifier__learning_rate=0.05257400670369904, classifier__max_depth=19, classifier__min_child_weight=6, classifier__n_estimators=309, classifier__subsample=0.8522681954443808;, score=(train=0.964, test=0.901) total time=   0.6s\n",
      "[CV 5/5; 30/30] START classifier__colsample_bytree=0.9609438104098937, classifier__gamma=1.960123365573096, classifier__learning_rate=0.05257400670369904, classifier__max_depth=19, classifier__min_child_weight=6, classifier__n_estimators=309, classifier__subsample=0.8522681954443808\n",
      "[CV 5/5; 30/30] END classifier__colsample_bytree=0.9609438104098937, classifier__gamma=1.960123365573096, classifier__learning_rate=0.05257400670369904, classifier__max_depth=19, classifier__min_child_weight=6, classifier__n_estimators=309, classifier__subsample=0.8522681954443808;, score=(train=0.966, test=0.912) total time=   0.6s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'classifier__colsample_bytree': 0.6149797826436689,\n",
       " 'classifier__gamma': 0.4949198339368057,\n",
       " 'classifier__learning_rate': 0.05501460684031166,\n",
       " 'classifier__max_depth': 44,\n",
       " 'classifier__min_child_weight': 1,\n",
       " 'classifier__n_estimators': 281,\n",
       " 'classifier__subsample': 0.9680220569471438}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats.distributions import uniform, randint\n",
    "from sklearn.model_selection import RandomizedSearchCV, StratifiedKFold\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "param_distribution = {\n",
    "    'classifier__max_depth': randint(6, 50),\n",
    "    'classifier__learning_rate': uniform(0.001, 0.1-0.001),\n",
    "    'classifier__n_estimators': randint(150, 500),\n",
    "    'classifier__gamma': uniform(0, 3),\n",
    "    'classifier__colsample_bytree': uniform(0.5, 0.5),\n",
    "    'classifier__subsample': uniform(0.5, 0.5),\n",
    "    'classifier__min_child_weight': randint(1, 11)\n",
    "}\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=5, random_state=seed, shuffle=True)\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('preprocessing', final_pipeline),\n",
    "    ('pca', PCA(11)),\n",
    "    ('classifier', XGBClassifier())\n",
    "])\n",
    "                 \n",
    "grid_2 = RandomizedSearchCV(pipe, param_distribution, cv=kfold, return_train_score=True, verbose=10, n_iter=30)\n",
    "\n",
    "grid_2.fit(X_train, y_train)\n",
    "grid_2.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5367e7ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision_score: 0.8934426229508197\n",
      "recall_score: 0.9008264462809917\n",
      "f1_score: 0.897119341563786\n",
      "accuracy_score: 0.9185667752442996\n"
     ]
    }
   ],
   "source": [
    "print_metrics(grid_2.best_estimator_, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2e4380ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "[CV 1/5; 1/30] START classifier__colsample_bytree=0.821814734497404, classifier__gamma=1.6189380401530078, classifier__learning_rate=0.06168728110789939, classifier__max_depth=39, classifier__min_child_weight=9, classifier__n_estimators=365, classifier__subsample=0.6914250819387113\n",
      "[CV 1/5; 1/30] END classifier__colsample_bytree=0.821814734497404, classifier__gamma=1.6189380401530078, classifier__learning_rate=0.06168728110789939, classifier__max_depth=39, classifier__min_child_weight=9, classifier__n_estimators=365, classifier__subsample=0.6914250819387113;, score=(train=0.975, test=0.927) total time=   0.6s\n",
      "[CV 2/5; 1/30] START classifier__colsample_bytree=0.821814734497404, classifier__gamma=1.6189380401530078, classifier__learning_rate=0.06168728110789939, classifier__max_depth=39, classifier__min_child_weight=9, classifier__n_estimators=365, classifier__subsample=0.6914250819387113\n",
      "[CV 2/5; 1/30] END classifier__colsample_bytree=0.821814734497404, classifier__gamma=1.6189380401530078, classifier__learning_rate=0.06168728110789939, classifier__max_depth=39, classifier__min_child_weight=9, classifier__n_estimators=365, classifier__subsample=0.6914250819387113;, score=(train=0.969, test=0.943) total time=   0.6s\n",
      "[CV 3/5; 1/30] START classifier__colsample_bytree=0.821814734497404, classifier__gamma=1.6189380401530078, classifier__learning_rate=0.06168728110789939, classifier__max_depth=39, classifier__min_child_weight=9, classifier__n_estimators=365, classifier__subsample=0.6914250819387113\n",
      "[CV 3/5; 1/30] END classifier__colsample_bytree=0.821814734497404, classifier__gamma=1.6189380401530078, classifier__learning_rate=0.06168728110789939, classifier__max_depth=39, classifier__min_child_weight=9, classifier__n_estimators=365, classifier__subsample=0.6914250819387113;, score=(train=0.975, test=0.942) total time=   0.6s\n",
      "[CV 4/5; 1/30] START classifier__colsample_bytree=0.821814734497404, classifier__gamma=1.6189380401530078, classifier__learning_rate=0.06168728110789939, classifier__max_depth=39, classifier__min_child_weight=9, classifier__n_estimators=365, classifier__subsample=0.6914250819387113\n",
      "[CV 4/5; 1/30] END classifier__colsample_bytree=0.821814734497404, classifier__gamma=1.6189380401530078, classifier__learning_rate=0.06168728110789939, classifier__max_depth=39, classifier__min_child_weight=9, classifier__n_estimators=365, classifier__subsample=0.6914250819387113;, score=(train=0.974, test=0.931) total time=   0.6s\n",
      "[CV 5/5; 1/30] START classifier__colsample_bytree=0.821814734497404, classifier__gamma=1.6189380401530078, classifier__learning_rate=0.06168728110789939, classifier__max_depth=39, classifier__min_child_weight=9, classifier__n_estimators=365, classifier__subsample=0.6914250819387113\n",
      "[CV 5/5; 1/30] END classifier__colsample_bytree=0.821814734497404, classifier__gamma=1.6189380401530078, classifier__learning_rate=0.06168728110789939, classifier__max_depth=39, classifier__min_child_weight=9, classifier__n_estimators=365, classifier__subsample=0.6914250819387113;, score=(train=0.970, test=0.928) total time=   0.6s\n",
      "[CV 1/5; 2/30] START classifier__colsample_bytree=0.7481869440147614, classifier__gamma=2.762139243320071, classifier__learning_rate=0.04835345654426986, classifier__max_depth=33, classifier__min_child_weight=3, classifier__n_estimators=378, classifier__subsample=0.9282573107957768\n",
      "[CV 1/5; 2/30] END classifier__colsample_bytree=0.7481869440147614, classifier__gamma=2.762139243320071, classifier__learning_rate=0.04835345654426986, classifier__max_depth=33, classifier__min_child_weight=3, classifier__n_estimators=378, classifier__subsample=0.9282573107957768;, score=(train=0.985, test=0.939) total time=   1.3s\n",
      "[CV 2/5; 2/30] START classifier__colsample_bytree=0.7481869440147614, classifier__gamma=2.762139243320071, classifier__learning_rate=0.04835345654426986, classifier__max_depth=33, classifier__min_child_weight=3, classifier__n_estimators=378, classifier__subsample=0.9282573107957768\n",
      "[CV 2/5; 2/30] END classifier__colsample_bytree=0.7481869440147614, classifier__gamma=2.762139243320071, classifier__learning_rate=0.04835345654426986, classifier__max_depth=33, classifier__min_child_weight=3, classifier__n_estimators=378, classifier__subsample=0.9282573107957768;, score=(train=0.984, test=0.951) total time=   1.3s\n",
      "[CV 3/5; 2/30] START classifier__colsample_bytree=0.7481869440147614, classifier__gamma=2.762139243320071, classifier__learning_rate=0.04835345654426986, classifier__max_depth=33, classifier__min_child_weight=3, classifier__n_estimators=378, classifier__subsample=0.9282573107957768\n",
      "[CV 3/5; 2/30] END classifier__colsample_bytree=0.7481869440147614, classifier__gamma=2.762139243320071, classifier__learning_rate=0.04835345654426986, classifier__max_depth=33, classifier__min_child_weight=3, classifier__n_estimators=378, classifier__subsample=0.9282573107957768;, score=(train=0.984, test=0.947) total time=   1.2s\n",
      "[CV 4/5; 2/30] START classifier__colsample_bytree=0.7481869440147614, classifier__gamma=2.762139243320071, classifier__learning_rate=0.04835345654426986, classifier__max_depth=33, classifier__min_child_weight=3, classifier__n_estimators=378, classifier__subsample=0.9282573107957768\n",
      "[CV 4/5; 2/30] END classifier__colsample_bytree=0.7481869440147614, classifier__gamma=2.762139243320071, classifier__learning_rate=0.04835345654426986, classifier__max_depth=33, classifier__min_child_weight=3, classifier__n_estimators=378, classifier__subsample=0.9282573107957768;, score=(train=0.987, test=0.938) total time=   1.2s\n",
      "[CV 5/5; 2/30] START classifier__colsample_bytree=0.7481869440147614, classifier__gamma=2.762139243320071, classifier__learning_rate=0.04835345654426986, classifier__max_depth=33, classifier__min_child_weight=3, classifier__n_estimators=378, classifier__subsample=0.9282573107957768\n",
      "[CV 5/5; 2/30] END classifier__colsample_bytree=0.7481869440147614, classifier__gamma=2.762139243320071, classifier__learning_rate=0.04835345654426986, classifier__max_depth=33, classifier__min_child_weight=3, classifier__n_estimators=378, classifier__subsample=0.9282573107957768;, score=(train=0.983, test=0.944) total time=   1.3s\n",
      "[CV 1/5; 3/30] START classifier__colsample_bytree=0.6482880112735234, classifier__gamma=1.6540565444085205, classifier__learning_rate=0.04488070327175445, classifier__max_depth=10, classifier__min_child_weight=8, classifier__n_estimators=438, classifier__subsample=0.9312101593274473\n",
      "[CV 1/5; 3/30] END classifier__colsample_bytree=0.6482880112735234, classifier__gamma=1.6540565444085205, classifier__learning_rate=0.04488070327175445, classifier__max_depth=10, classifier__min_child_weight=8, classifier__n_estimators=438, classifier__subsample=0.9312101593274473;, score=(train=0.978, test=0.940) total time=   0.9s\n",
      "[CV 2/5; 3/30] START classifier__colsample_bytree=0.6482880112735234, classifier__gamma=1.6540565444085205, classifier__learning_rate=0.04488070327175445, classifier__max_depth=10, classifier__min_child_weight=8, classifier__n_estimators=438, classifier__subsample=0.9312101593274473\n",
      "[CV 2/5; 3/30] END classifier__colsample_bytree=0.6482880112735234, classifier__gamma=1.6540565444085205, classifier__learning_rate=0.04488070327175445, classifier__max_depth=10, classifier__min_child_weight=8, classifier__n_estimators=438, classifier__subsample=0.9312101593274473;, score=(train=0.978, test=0.951) total time=   0.9s\n",
      "[CV 3/5; 3/30] START classifier__colsample_bytree=0.6482880112735234, classifier__gamma=1.6540565444085205, classifier__learning_rate=0.04488070327175445, classifier__max_depth=10, classifier__min_child_weight=8, classifier__n_estimators=438, classifier__subsample=0.9312101593274473\n",
      "[CV 3/5; 3/30] END classifier__colsample_bytree=0.6482880112735234, classifier__gamma=1.6540565444085205, classifier__learning_rate=0.04488070327175445, classifier__max_depth=10, classifier__min_child_weight=8, classifier__n_estimators=438, classifier__subsample=0.9312101593274473;, score=(train=0.979, test=0.940) total time=   0.9s\n",
      "[CV 4/5; 3/30] START classifier__colsample_bytree=0.6482880112735234, classifier__gamma=1.6540565444085205, classifier__learning_rate=0.04488070327175445, classifier__max_depth=10, classifier__min_child_weight=8, classifier__n_estimators=438, classifier__subsample=0.9312101593274473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 3/30] END classifier__colsample_bytree=0.6482880112735234, classifier__gamma=1.6540565444085205, classifier__learning_rate=0.04488070327175445, classifier__max_depth=10, classifier__min_child_weight=8, classifier__n_estimators=438, classifier__subsample=0.9312101593274473;, score=(train=0.982, test=0.942) total time=   0.9s\n",
      "[CV 5/5; 3/30] START classifier__colsample_bytree=0.6482880112735234, classifier__gamma=1.6540565444085205, classifier__learning_rate=0.04488070327175445, classifier__max_depth=10, classifier__min_child_weight=8, classifier__n_estimators=438, classifier__subsample=0.9312101593274473\n",
      "[CV 5/5; 3/30] END classifier__colsample_bytree=0.6482880112735234, classifier__gamma=1.6540565444085205, classifier__learning_rate=0.04488070327175445, classifier__max_depth=10, classifier__min_child_weight=8, classifier__n_estimators=438, classifier__subsample=0.9312101593274473;, score=(train=0.978, test=0.939) total time=   0.9s\n",
      "[CV 1/5; 4/30] START classifier__colsample_bytree=0.8141351878507619, classifier__gamma=0.838331528459198, classifier__learning_rate=0.03702536893817694, classifier__max_depth=14, classifier__min_child_weight=4, classifier__n_estimators=323, classifier__subsample=0.807584264264842\n",
      "[CV 1/5; 4/30] END classifier__colsample_bytree=0.8141351878507619, classifier__gamma=0.838331528459198, classifier__learning_rate=0.03702536893817694, classifier__max_depth=14, classifier__min_child_weight=4, classifier__n_estimators=323, classifier__subsample=0.807584264264842;, score=(train=0.989, test=0.935) total time=   0.9s\n",
      "[CV 2/5; 4/30] START classifier__colsample_bytree=0.8141351878507619, classifier__gamma=0.838331528459198, classifier__learning_rate=0.03702536893817694, classifier__max_depth=14, classifier__min_child_weight=4, classifier__n_estimators=323, classifier__subsample=0.807584264264842\n",
      "[CV 2/5; 4/30] END classifier__colsample_bytree=0.8141351878507619, classifier__gamma=0.838331528459198, classifier__learning_rate=0.03702536893817694, classifier__max_depth=14, classifier__min_child_weight=4, classifier__n_estimators=323, classifier__subsample=0.807584264264842;, score=(train=0.987, test=0.954) total time=   0.9s\n",
      "[CV 3/5; 4/30] START classifier__colsample_bytree=0.8141351878507619, classifier__gamma=0.838331528459198, classifier__learning_rate=0.03702536893817694, classifier__max_depth=14, classifier__min_child_weight=4, classifier__n_estimators=323, classifier__subsample=0.807584264264842\n",
      "[CV 3/5; 4/30] END classifier__colsample_bytree=0.8141351878507619, classifier__gamma=0.838331528459198, classifier__learning_rate=0.03702536893817694, classifier__max_depth=14, classifier__min_child_weight=4, classifier__n_estimators=323, classifier__subsample=0.807584264264842;, score=(train=0.989, test=0.944) total time=   0.9s\n",
      "[CV 4/5; 4/30] START classifier__colsample_bytree=0.8141351878507619, classifier__gamma=0.838331528459198, classifier__learning_rate=0.03702536893817694, classifier__max_depth=14, classifier__min_child_weight=4, classifier__n_estimators=323, classifier__subsample=0.807584264264842\n",
      "[CV 4/5; 4/30] END classifier__colsample_bytree=0.8141351878507619, classifier__gamma=0.838331528459198, classifier__learning_rate=0.03702536893817694, classifier__max_depth=14, classifier__min_child_weight=4, classifier__n_estimators=323, classifier__subsample=0.807584264264842;, score=(train=0.989, test=0.936) total time=   0.9s\n",
      "[CV 5/5; 4/30] START classifier__colsample_bytree=0.8141351878507619, classifier__gamma=0.838331528459198, classifier__learning_rate=0.03702536893817694, classifier__max_depth=14, classifier__min_child_weight=4, classifier__n_estimators=323, classifier__subsample=0.807584264264842\n",
      "[CV 5/5; 4/30] END classifier__colsample_bytree=0.8141351878507619, classifier__gamma=0.838331528459198, classifier__learning_rate=0.03702536893817694, classifier__max_depth=14, classifier__min_child_weight=4, classifier__n_estimators=323, classifier__subsample=0.807584264264842;, score=(train=0.987, test=0.943) total time=   0.9s\n",
      "[CV 1/5; 5/30] START classifier__colsample_bytree=0.7054421934113453, classifier__gamma=0.6240150462106769, classifier__learning_rate=0.06504887341003358, classifier__max_depth=15, classifier__min_child_weight=4, classifier__n_estimators=361, classifier__subsample=0.9313111228831967\n",
      "[CV 1/5; 5/30] END classifier__colsample_bytree=0.7054421934113453, classifier__gamma=0.6240150462106769, classifier__learning_rate=0.06504887341003358, classifier__max_depth=15, classifier__min_child_weight=4, classifier__n_estimators=361, classifier__subsample=0.9313111228831967;, score=(train=0.995, test=0.940) total time=   0.9s\n",
      "[CV 2/5; 5/30] START classifier__colsample_bytree=0.7054421934113453, classifier__gamma=0.6240150462106769, classifier__learning_rate=0.06504887341003358, classifier__max_depth=15, classifier__min_child_weight=4, classifier__n_estimators=361, classifier__subsample=0.9313111228831967\n",
      "[CV 2/5; 5/30] END classifier__colsample_bytree=0.7054421934113453, classifier__gamma=0.6240150462106769, classifier__learning_rate=0.06504887341003358, classifier__max_depth=15, classifier__min_child_weight=4, classifier__n_estimators=361, classifier__subsample=0.9313111228831967;, score=(train=0.994, test=0.944) total time=   0.9s\n",
      "[CV 3/5; 5/30] START classifier__colsample_bytree=0.7054421934113453, classifier__gamma=0.6240150462106769, classifier__learning_rate=0.06504887341003358, classifier__max_depth=15, classifier__min_child_weight=4, classifier__n_estimators=361, classifier__subsample=0.9313111228831967\n",
      "[CV 3/5; 5/30] END classifier__colsample_bytree=0.7054421934113453, classifier__gamma=0.6240150462106769, classifier__learning_rate=0.06504887341003358, classifier__max_depth=15, classifier__min_child_weight=4, classifier__n_estimators=361, classifier__subsample=0.9313111228831967;, score=(train=0.995, test=0.946) total time=   0.9s\n",
      "[CV 4/5; 5/30] START classifier__colsample_bytree=0.7054421934113453, classifier__gamma=0.6240150462106769, classifier__learning_rate=0.06504887341003358, classifier__max_depth=15, classifier__min_child_weight=4, classifier__n_estimators=361, classifier__subsample=0.9313111228831967\n",
      "[CV 4/5; 5/30] END classifier__colsample_bytree=0.7054421934113453, classifier__gamma=0.6240150462106769, classifier__learning_rate=0.06504887341003358, classifier__max_depth=15, classifier__min_child_weight=4, classifier__n_estimators=361, classifier__subsample=0.9313111228831967;, score=(train=0.996, test=0.939) total time=   0.9s\n",
      "[CV 5/5; 5/30] START classifier__colsample_bytree=0.7054421934113453, classifier__gamma=0.6240150462106769, classifier__learning_rate=0.06504887341003358, classifier__max_depth=15, classifier__min_child_weight=4, classifier__n_estimators=361, classifier__subsample=0.9313111228831967\n",
      "[CV 5/5; 5/30] END classifier__colsample_bytree=0.7054421934113453, classifier__gamma=0.6240150462106769, classifier__learning_rate=0.06504887341003358, classifier__max_depth=15, classifier__min_child_weight=4, classifier__n_estimators=361, classifier__subsample=0.9313111228831967;, score=(train=0.994, test=0.942) total time=   0.9s\n",
      "[CV 1/5; 6/30] START classifier__colsample_bytree=0.7432676352484477, classifier__gamma=0.3325314231968759, classifier__learning_rate=0.05820006388855853, classifier__max_depth=40, classifier__min_child_weight=6, classifier__n_estimators=332, classifier__subsample=0.7270271942591802\n",
      "[CV 1/5; 6/30] END classifier__colsample_bytree=0.7432676352484477, classifier__gamma=0.3325314231968759, classifier__learning_rate=0.05820006388855853, classifier__max_depth=40, classifier__min_child_weight=6, classifier__n_estimators=332, classifier__subsample=0.7270271942591802;, score=(train=0.986, test=0.932) total time=   0.7s\n",
      "[CV 2/5; 6/30] START classifier__colsample_bytree=0.7432676352484477, classifier__gamma=0.3325314231968759, classifier__learning_rate=0.05820006388855853, classifier__max_depth=40, classifier__min_child_weight=6, classifier__n_estimators=332, classifier__subsample=0.7270271942591802\n",
      "[CV 2/5; 6/30] END classifier__colsample_bytree=0.7432676352484477, classifier__gamma=0.3325314231968759, classifier__learning_rate=0.05820006388855853, classifier__max_depth=40, classifier__min_child_weight=6, classifier__n_estimators=332, classifier__subsample=0.7270271942591802;, score=(train=0.985, test=0.947) total time=   0.7s\n",
      "[CV 3/5; 6/30] START classifier__colsample_bytree=0.7432676352484477, classifier__gamma=0.3325314231968759, classifier__learning_rate=0.05820006388855853, classifier__max_depth=40, classifier__min_child_weight=6, classifier__n_estimators=332, classifier__subsample=0.7270271942591802\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 6/30] END classifier__colsample_bytree=0.7432676352484477, classifier__gamma=0.3325314231968759, classifier__learning_rate=0.05820006388855853, classifier__max_depth=40, classifier__min_child_weight=6, classifier__n_estimators=332, classifier__subsample=0.7270271942591802;, score=(train=0.987, test=0.946) total time=   0.7s\n",
      "[CV 4/5; 6/30] START classifier__colsample_bytree=0.7432676352484477, classifier__gamma=0.3325314231968759, classifier__learning_rate=0.05820006388855853, classifier__max_depth=40, classifier__min_child_weight=6, classifier__n_estimators=332, classifier__subsample=0.7270271942591802\n",
      "[CV 4/5; 6/30] END classifier__colsample_bytree=0.7432676352484477, classifier__gamma=0.3325314231968759, classifier__learning_rate=0.05820006388855853, classifier__max_depth=40, classifier__min_child_weight=6, classifier__n_estimators=332, classifier__subsample=0.7270271942591802;, score=(train=0.987, test=0.939) total time=   0.7s\n",
      "[CV 5/5; 6/30] START classifier__colsample_bytree=0.7432676352484477, classifier__gamma=0.3325314231968759, classifier__learning_rate=0.05820006388855853, classifier__max_depth=40, classifier__min_child_weight=6, classifier__n_estimators=332, classifier__subsample=0.7270271942591802\n",
      "[CV 5/5; 6/30] END classifier__colsample_bytree=0.7432676352484477, classifier__gamma=0.3325314231968759, classifier__learning_rate=0.05820006388855853, classifier__max_depth=40, classifier__min_child_weight=6, classifier__n_estimators=332, classifier__subsample=0.7270271942591802;, score=(train=0.985, test=0.938) total time=   0.7s\n",
      "[CV 1/5; 7/30] START classifier__colsample_bytree=0.7267907298578761, classifier__gamma=1.2990328847987316, classifier__learning_rate=0.03803976530858473, classifier__max_depth=32, classifier__min_child_weight=9, classifier__n_estimators=366, classifier__subsample=0.6344676950169528\n",
      "[CV 1/5; 7/30] END classifier__colsample_bytree=0.7267907298578761, classifier__gamma=1.2990328847987316, classifier__learning_rate=0.03803976530858473, classifier__max_depth=32, classifier__min_child_weight=9, classifier__n_estimators=366, classifier__subsample=0.6344676950169528;, score=(train=0.967, test=0.932) total time=   0.6s\n",
      "[CV 2/5; 7/30] START classifier__colsample_bytree=0.7267907298578761, classifier__gamma=1.2990328847987316, classifier__learning_rate=0.03803976530858473, classifier__max_depth=32, classifier__min_child_weight=9, classifier__n_estimators=366, classifier__subsample=0.6344676950169528\n",
      "[CV 2/5; 7/30] END classifier__colsample_bytree=0.7267907298578761, classifier__gamma=1.2990328847987316, classifier__learning_rate=0.03803976530858473, classifier__max_depth=32, classifier__min_child_weight=9, classifier__n_estimators=366, classifier__subsample=0.6344676950169528;, score=(train=0.963, test=0.942) total time=   0.7s\n",
      "[CV 3/5; 7/30] START classifier__colsample_bytree=0.7267907298578761, classifier__gamma=1.2990328847987316, classifier__learning_rate=0.03803976530858473, classifier__max_depth=32, classifier__min_child_weight=9, classifier__n_estimators=366, classifier__subsample=0.6344676950169528\n",
      "[CV 3/5; 7/30] END classifier__colsample_bytree=0.7267907298578761, classifier__gamma=1.2990328847987316, classifier__learning_rate=0.03803976530858473, classifier__max_depth=32, classifier__min_child_weight=9, classifier__n_estimators=366, classifier__subsample=0.6344676950169528;, score=(train=0.965, test=0.943) total time=   0.6s\n",
      "[CV 4/5; 7/30] START classifier__colsample_bytree=0.7267907298578761, classifier__gamma=1.2990328847987316, classifier__learning_rate=0.03803976530858473, classifier__max_depth=32, classifier__min_child_weight=9, classifier__n_estimators=366, classifier__subsample=0.6344676950169528\n",
      "[CV 4/5; 7/30] END classifier__colsample_bytree=0.7267907298578761, classifier__gamma=1.2990328847987316, classifier__learning_rate=0.03803976530858473, classifier__max_depth=32, classifier__min_child_weight=9, classifier__n_estimators=366, classifier__subsample=0.6344676950169528;, score=(train=0.965, test=0.932) total time=   0.6s\n",
      "[CV 5/5; 7/30] START classifier__colsample_bytree=0.7267907298578761, classifier__gamma=1.2990328847987316, classifier__learning_rate=0.03803976530858473, classifier__max_depth=32, classifier__min_child_weight=9, classifier__n_estimators=366, classifier__subsample=0.6344676950169528\n",
      "[CV 5/5; 7/30] END classifier__colsample_bytree=0.7267907298578761, classifier__gamma=1.2990328847987316, classifier__learning_rate=0.03803976530858473, classifier__max_depth=32, classifier__min_child_weight=9, classifier__n_estimators=366, classifier__subsample=0.6344676950169528;, score=(train=0.965, test=0.928) total time=   0.7s\n",
      "[CV 1/5; 8/30] START classifier__colsample_bytree=0.9592813920159533, classifier__gamma=2.0381536029937197, classifier__learning_rate=0.08002918312782065, classifier__max_depth=40, classifier__min_child_weight=4, classifier__n_estimators=444, classifier__subsample=0.5845837427188629\n",
      "[CV 1/5; 8/30] END classifier__colsample_bytree=0.9592813920159533, classifier__gamma=2.0381536029937197, classifier__learning_rate=0.08002918312782065, classifier__max_depth=40, classifier__min_child_weight=4, classifier__n_estimators=444, classifier__subsample=0.5845837427188629;, score=(train=0.986, test=0.931) total time=   1.0s\n",
      "[CV 2/5; 8/30] START classifier__colsample_bytree=0.9592813920159533, classifier__gamma=2.0381536029937197, classifier__learning_rate=0.08002918312782065, classifier__max_depth=40, classifier__min_child_weight=4, classifier__n_estimators=444, classifier__subsample=0.5845837427188629\n",
      "[CV 2/5; 8/30] END classifier__colsample_bytree=0.9592813920159533, classifier__gamma=2.0381536029937197, classifier__learning_rate=0.08002918312782065, classifier__max_depth=40, classifier__min_child_weight=4, classifier__n_estimators=444, classifier__subsample=0.5845837427188629;, score=(train=0.984, test=0.948) total time=   1.0s\n",
      "[CV 3/5; 8/30] START classifier__colsample_bytree=0.9592813920159533, classifier__gamma=2.0381536029937197, classifier__learning_rate=0.08002918312782065, classifier__max_depth=40, classifier__min_child_weight=4, classifier__n_estimators=444, classifier__subsample=0.5845837427188629\n",
      "[CV 3/5; 8/30] END classifier__colsample_bytree=0.9592813920159533, classifier__gamma=2.0381536029937197, classifier__learning_rate=0.08002918312782065, classifier__max_depth=40, classifier__min_child_weight=4, classifier__n_estimators=444, classifier__subsample=0.5845837427188629;, score=(train=0.987, test=0.947) total time=   1.0s\n",
      "[CV 4/5; 8/30] START classifier__colsample_bytree=0.9592813920159533, classifier__gamma=2.0381536029937197, classifier__learning_rate=0.08002918312782065, classifier__max_depth=40, classifier__min_child_weight=4, classifier__n_estimators=444, classifier__subsample=0.5845837427188629\n",
      "[CV 4/5; 8/30] END classifier__colsample_bytree=0.9592813920159533, classifier__gamma=2.0381536029937197, classifier__learning_rate=0.08002918312782065, classifier__max_depth=40, classifier__min_child_weight=4, classifier__n_estimators=444, classifier__subsample=0.5845837427188629;, score=(train=0.987, test=0.929) total time=   1.0s\n",
      "[CV 5/5; 8/30] START classifier__colsample_bytree=0.9592813920159533, classifier__gamma=2.0381536029937197, classifier__learning_rate=0.08002918312782065, classifier__max_depth=40, classifier__min_child_weight=4, classifier__n_estimators=444, classifier__subsample=0.5845837427188629\n",
      "[CV 5/5; 8/30] END classifier__colsample_bytree=0.9592813920159533, classifier__gamma=2.0381536029937197, classifier__learning_rate=0.08002918312782065, classifier__max_depth=40, classifier__min_child_weight=4, classifier__n_estimators=444, classifier__subsample=0.5845837427188629;, score=(train=0.985, test=0.938) total time=   1.0s\n",
      "[CV 1/5; 9/30] START classifier__colsample_bytree=0.8850997428132492, classifier__gamma=2.0444804761323265, classifier__learning_rate=0.09068009114978247, classifier__max_depth=29, classifier__min_child_weight=1, classifier__n_estimators=304, classifier__subsample=0.89795236370281\n",
      "[CV 1/5; 9/30] END classifier__colsample_bytree=0.8850997428132492, classifier__gamma=2.0444804761323265, classifier__learning_rate=0.09068009114978247, classifier__max_depth=29, classifier__min_child_weight=1, classifier__n_estimators=304, classifier__subsample=0.89795236370281;, score=(train=0.993, test=0.936) total time=   1.4s\n",
      "[CV 2/5; 9/30] START classifier__colsample_bytree=0.8850997428132492, classifier__gamma=2.0444804761323265, classifier__learning_rate=0.09068009114978247, classifier__max_depth=29, classifier__min_child_weight=1, classifier__n_estimators=304, classifier__subsample=0.89795236370281\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 9/30] END classifier__colsample_bytree=0.8850997428132492, classifier__gamma=2.0444804761323265, classifier__learning_rate=0.09068009114978247, classifier__max_depth=29, classifier__min_child_weight=1, classifier__n_estimators=304, classifier__subsample=0.89795236370281;, score=(train=0.993, test=0.954) total time=   1.4s\n",
      "[CV 3/5; 9/30] START classifier__colsample_bytree=0.8850997428132492, classifier__gamma=2.0444804761323265, classifier__learning_rate=0.09068009114978247, classifier__max_depth=29, classifier__min_child_weight=1, classifier__n_estimators=304, classifier__subsample=0.89795236370281\n",
      "[CV 3/5; 9/30] END classifier__colsample_bytree=0.8850997428132492, classifier__gamma=2.0444804761323265, classifier__learning_rate=0.09068009114978247, classifier__max_depth=29, classifier__min_child_weight=1, classifier__n_estimators=304, classifier__subsample=0.89795236370281;, score=(train=0.994, test=0.946) total time=   1.4s\n",
      "[CV 4/5; 9/30] START classifier__colsample_bytree=0.8850997428132492, classifier__gamma=2.0444804761323265, classifier__learning_rate=0.09068009114978247, classifier__max_depth=29, classifier__min_child_weight=1, classifier__n_estimators=304, classifier__subsample=0.89795236370281\n",
      "[CV 4/5; 9/30] END classifier__colsample_bytree=0.8850997428132492, classifier__gamma=2.0444804761323265, classifier__learning_rate=0.09068009114978247, classifier__max_depth=29, classifier__min_child_weight=1, classifier__n_estimators=304, classifier__subsample=0.89795236370281;, score=(train=0.994, test=0.940) total time=   1.4s\n",
      "[CV 5/5; 9/30] START classifier__colsample_bytree=0.8850997428132492, classifier__gamma=2.0444804761323265, classifier__learning_rate=0.09068009114978247, classifier__max_depth=29, classifier__min_child_weight=1, classifier__n_estimators=304, classifier__subsample=0.89795236370281\n",
      "[CV 5/5; 9/30] END classifier__colsample_bytree=0.8850997428132492, classifier__gamma=2.0444804761323265, classifier__learning_rate=0.09068009114978247, classifier__max_depth=29, classifier__min_child_weight=1, classifier__n_estimators=304, classifier__subsample=0.89795236370281;, score=(train=0.992, test=0.946) total time=   1.4s\n",
      "[CV 1/5; 10/30] START classifier__colsample_bytree=0.9037327936103965, classifier__gamma=1.579795497359105, classifier__learning_rate=0.02239048769054121, classifier__max_depth=23, classifier__min_child_weight=3, classifier__n_estimators=275, classifier__subsample=0.7438889011256373\n",
      "[CV 1/5; 10/30] END classifier__colsample_bytree=0.9037327936103965, classifier__gamma=1.579795497359105, classifier__learning_rate=0.02239048769054121, classifier__max_depth=23, classifier__min_child_weight=3, classifier__n_estimators=275, classifier__subsample=0.7438889011256373;, score=(train=0.980, test=0.929) total time=   0.9s\n",
      "[CV 2/5; 10/30] START classifier__colsample_bytree=0.9037327936103965, classifier__gamma=1.579795497359105, classifier__learning_rate=0.02239048769054121, classifier__max_depth=23, classifier__min_child_weight=3, classifier__n_estimators=275, classifier__subsample=0.7438889011256373\n",
      "[CV 2/5; 10/30] END classifier__colsample_bytree=0.9037327936103965, classifier__gamma=1.579795497359105, classifier__learning_rate=0.02239048769054121, classifier__max_depth=23, classifier__min_child_weight=3, classifier__n_estimators=275, classifier__subsample=0.7438889011256373;, score=(train=0.979, test=0.946) total time=   1.0s\n",
      "[CV 3/5; 10/30] START classifier__colsample_bytree=0.9037327936103965, classifier__gamma=1.579795497359105, classifier__learning_rate=0.02239048769054121, classifier__max_depth=23, classifier__min_child_weight=3, classifier__n_estimators=275, classifier__subsample=0.7438889011256373\n",
      "[CV 3/5; 10/30] END classifier__colsample_bytree=0.9037327936103965, classifier__gamma=1.579795497359105, classifier__learning_rate=0.02239048769054121, classifier__max_depth=23, classifier__min_child_weight=3, classifier__n_estimators=275, classifier__subsample=0.7438889011256373;, score=(train=0.980, test=0.947) total time=   0.9s\n",
      "[CV 4/5; 10/30] START classifier__colsample_bytree=0.9037327936103965, classifier__gamma=1.579795497359105, classifier__learning_rate=0.02239048769054121, classifier__max_depth=23, classifier__min_child_weight=3, classifier__n_estimators=275, classifier__subsample=0.7438889011256373\n",
      "[CV 4/5; 10/30] END classifier__colsample_bytree=0.9037327936103965, classifier__gamma=1.579795497359105, classifier__learning_rate=0.02239048769054121, classifier__max_depth=23, classifier__min_child_weight=3, classifier__n_estimators=275, classifier__subsample=0.7438889011256373;, score=(train=0.983, test=0.939) total time=   0.9s\n",
      "[CV 5/5; 10/30] START classifier__colsample_bytree=0.9037327936103965, classifier__gamma=1.579795497359105, classifier__learning_rate=0.02239048769054121, classifier__max_depth=23, classifier__min_child_weight=3, classifier__n_estimators=275, classifier__subsample=0.7438889011256373\n",
      "[CV 5/5; 10/30] END classifier__colsample_bytree=0.9037327936103965, classifier__gamma=1.579795497359105, classifier__learning_rate=0.02239048769054121, classifier__max_depth=23, classifier__min_child_weight=3, classifier__n_estimators=275, classifier__subsample=0.7438889011256373;, score=(train=0.975, test=0.944) total time=   0.9s\n",
      "[CV 1/5; 11/30] START classifier__colsample_bytree=0.5777732289043023, classifier__gamma=2.209978620074511, classifier__learning_rate=0.09162303207639394, classifier__max_depth=7, classifier__min_child_weight=9, classifier__n_estimators=364, classifier__subsample=0.7257766458520962\n",
      "[CV 1/5; 11/30] END classifier__colsample_bytree=0.5777732289043023, classifier__gamma=2.209978620074511, classifier__learning_rate=0.09162303207639394, classifier__max_depth=7, classifier__min_child_weight=9, classifier__n_estimators=364, classifier__subsample=0.7257766458520962;, score=(train=0.972, test=0.929) total time=   0.5s\n",
      "[CV 2/5; 11/30] START classifier__colsample_bytree=0.5777732289043023, classifier__gamma=2.209978620074511, classifier__learning_rate=0.09162303207639394, classifier__max_depth=7, classifier__min_child_weight=9, classifier__n_estimators=364, classifier__subsample=0.7257766458520962\n",
      "[CV 2/5; 11/30] END classifier__colsample_bytree=0.5777732289043023, classifier__gamma=2.209978620074511, classifier__learning_rate=0.09162303207639394, classifier__max_depth=7, classifier__min_child_weight=9, classifier__n_estimators=364, classifier__subsample=0.7257766458520962;, score=(train=0.967, test=0.943) total time=   0.6s\n",
      "[CV 3/5; 11/30] START classifier__colsample_bytree=0.5777732289043023, classifier__gamma=2.209978620074511, classifier__learning_rate=0.09162303207639394, classifier__max_depth=7, classifier__min_child_weight=9, classifier__n_estimators=364, classifier__subsample=0.7257766458520962\n",
      "[CV 3/5; 11/30] END classifier__colsample_bytree=0.5777732289043023, classifier__gamma=2.209978620074511, classifier__learning_rate=0.09162303207639394, classifier__max_depth=7, classifier__min_child_weight=9, classifier__n_estimators=364, classifier__subsample=0.7257766458520962;, score=(train=0.968, test=0.943) total time=   0.6s\n",
      "[CV 4/5; 11/30] START classifier__colsample_bytree=0.5777732289043023, classifier__gamma=2.209978620074511, classifier__learning_rate=0.09162303207639394, classifier__max_depth=7, classifier__min_child_weight=9, classifier__n_estimators=364, classifier__subsample=0.7257766458520962\n",
      "[CV 4/5; 11/30] END classifier__colsample_bytree=0.5777732289043023, classifier__gamma=2.209978620074511, classifier__learning_rate=0.09162303207639394, classifier__max_depth=7, classifier__min_child_weight=9, classifier__n_estimators=364, classifier__subsample=0.7257766458520962;, score=(train=0.971, test=0.932) total time=   0.5s\n",
      "[CV 5/5; 11/30] START classifier__colsample_bytree=0.5777732289043023, classifier__gamma=2.209978620074511, classifier__learning_rate=0.09162303207639394, classifier__max_depth=7, classifier__min_child_weight=9, classifier__n_estimators=364, classifier__subsample=0.7257766458520962\n",
      "[CV 5/5; 11/30] END classifier__colsample_bytree=0.5777732289043023, classifier__gamma=2.209978620074511, classifier__learning_rate=0.09162303207639394, classifier__max_depth=7, classifier__min_child_weight=9, classifier__n_estimators=364, classifier__subsample=0.7257766458520962;, score=(train=0.968, test=0.931) total time=   0.5s\n",
      "[CV 1/5; 12/30] START classifier__colsample_bytree=0.5234916635286675, classifier__gamma=0.5812868370396975, classifier__learning_rate=0.08497030553127266, classifier__max_depth=11, classifier__min_child_weight=8, classifier__n_estimators=306, classifier__subsample=0.8856782428462995\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 12/30] END classifier__colsample_bytree=0.5234916635286675, classifier__gamma=0.5812868370396975, classifier__learning_rate=0.08497030553127266, classifier__max_depth=11, classifier__min_child_weight=8, classifier__n_estimators=306, classifier__subsample=0.8856782428462995;, score=(train=0.986, test=0.936) total time=   0.5s\n",
      "[CV 2/5; 12/30] START classifier__colsample_bytree=0.5234916635286675, classifier__gamma=0.5812868370396975, classifier__learning_rate=0.08497030553127266, classifier__max_depth=11, classifier__min_child_weight=8, classifier__n_estimators=306, classifier__subsample=0.8856782428462995\n",
      "[CV 2/5; 12/30] END classifier__colsample_bytree=0.5234916635286675, classifier__gamma=0.5812868370396975, classifier__learning_rate=0.08497030553127266, classifier__max_depth=11, classifier__min_child_weight=8, classifier__n_estimators=306, classifier__subsample=0.8856782428462995;, score=(train=0.983, test=0.951) total time=   0.6s\n",
      "[CV 3/5; 12/30] START classifier__colsample_bytree=0.5234916635286675, classifier__gamma=0.5812868370396975, classifier__learning_rate=0.08497030553127266, classifier__max_depth=11, classifier__min_child_weight=8, classifier__n_estimators=306, classifier__subsample=0.8856782428462995\n",
      "[CV 3/5; 12/30] END classifier__colsample_bytree=0.5234916635286675, classifier__gamma=0.5812868370396975, classifier__learning_rate=0.08497030553127266, classifier__max_depth=11, classifier__min_child_weight=8, classifier__n_estimators=306, classifier__subsample=0.8856782428462995;, score=(train=0.986, test=0.946) total time=   0.6s\n",
      "[CV 4/5; 12/30] START classifier__colsample_bytree=0.5234916635286675, classifier__gamma=0.5812868370396975, classifier__learning_rate=0.08497030553127266, classifier__max_depth=11, classifier__min_child_weight=8, classifier__n_estimators=306, classifier__subsample=0.8856782428462995\n",
      "[CV 4/5; 12/30] END classifier__colsample_bytree=0.5234916635286675, classifier__gamma=0.5812868370396975, classifier__learning_rate=0.08497030553127266, classifier__max_depth=11, classifier__min_child_weight=8, classifier__n_estimators=306, classifier__subsample=0.8856782428462995;, score=(train=0.987, test=0.929) total time=   0.5s\n",
      "[CV 5/5; 12/30] START classifier__colsample_bytree=0.5234916635286675, classifier__gamma=0.5812868370396975, classifier__learning_rate=0.08497030553127266, classifier__max_depth=11, classifier__min_child_weight=8, classifier__n_estimators=306, classifier__subsample=0.8856782428462995\n",
      "[CV 5/5; 12/30] END classifier__colsample_bytree=0.5234916635286675, classifier__gamma=0.5812868370396975, classifier__learning_rate=0.08497030553127266, classifier__max_depth=11, classifier__min_child_weight=8, classifier__n_estimators=306, classifier__subsample=0.8856782428462995;, score=(train=0.984, test=0.936) total time=   0.5s\n",
      "[CV 1/5; 13/30] START classifier__colsample_bytree=0.6939915261524168, classifier__gamma=0.4779130283580364, classifier__learning_rate=0.05372504018945344, classifier__max_depth=43, classifier__min_child_weight=8, classifier__n_estimators=252, classifier__subsample=0.8447459348054007\n",
      "[CV 1/5; 13/30] END classifier__colsample_bytree=0.6939915261524168, classifier__gamma=0.4779130283580364, classifier__learning_rate=0.05372504018945344, classifier__max_depth=43, classifier__min_child_weight=8, classifier__n_estimators=252, classifier__subsample=0.8447459348054007;, score=(train=0.979, test=0.931) total time=   0.5s\n",
      "[CV 2/5; 13/30] START classifier__colsample_bytree=0.6939915261524168, classifier__gamma=0.4779130283580364, classifier__learning_rate=0.05372504018945344, classifier__max_depth=43, classifier__min_child_weight=8, classifier__n_estimators=252, classifier__subsample=0.8447459348054007\n",
      "[CV 2/5; 13/30] END classifier__colsample_bytree=0.6939915261524168, classifier__gamma=0.4779130283580364, classifier__learning_rate=0.05372504018945344, classifier__max_depth=43, classifier__min_child_weight=8, classifier__n_estimators=252, classifier__subsample=0.8447459348054007;, score=(train=0.977, test=0.952) total time=   0.6s\n",
      "[CV 3/5; 13/30] START classifier__colsample_bytree=0.6939915261524168, classifier__gamma=0.4779130283580364, classifier__learning_rate=0.05372504018945344, classifier__max_depth=43, classifier__min_child_weight=8, classifier__n_estimators=252, classifier__subsample=0.8447459348054007\n",
      "[CV 3/5; 13/30] END classifier__colsample_bytree=0.6939915261524168, classifier__gamma=0.4779130283580364, classifier__learning_rate=0.05372504018945344, classifier__max_depth=43, classifier__min_child_weight=8, classifier__n_estimators=252, classifier__subsample=0.8447459348054007;, score=(train=0.978, test=0.950) total time=   0.6s\n",
      "[CV 4/5; 13/30] START classifier__colsample_bytree=0.6939915261524168, classifier__gamma=0.4779130283580364, classifier__learning_rate=0.05372504018945344, classifier__max_depth=43, classifier__min_child_weight=8, classifier__n_estimators=252, classifier__subsample=0.8447459348054007\n",
      "[CV 4/5; 13/30] END classifier__colsample_bytree=0.6939915261524168, classifier__gamma=0.4779130283580364, classifier__learning_rate=0.05372504018945344, classifier__max_depth=43, classifier__min_child_weight=8, classifier__n_estimators=252, classifier__subsample=0.8447459348054007;, score=(train=0.981, test=0.936) total time=   0.5s\n",
      "[CV 5/5; 13/30] START classifier__colsample_bytree=0.6939915261524168, classifier__gamma=0.4779130283580364, classifier__learning_rate=0.05372504018945344, classifier__max_depth=43, classifier__min_child_weight=8, classifier__n_estimators=252, classifier__subsample=0.8447459348054007\n",
      "[CV 5/5; 13/30] END classifier__colsample_bytree=0.6939915261524168, classifier__gamma=0.4779130283580364, classifier__learning_rate=0.05372504018945344, classifier__max_depth=43, classifier__min_child_weight=8, classifier__n_estimators=252, classifier__subsample=0.8447459348054007;, score=(train=0.976, test=0.936) total time=   0.5s\n",
      "[CV 1/5; 14/30] START classifier__colsample_bytree=0.6322502615579774, classifier__gamma=1.6745454139502411, classifier__learning_rate=0.03706622569174634, classifier__max_depth=31, classifier__min_child_weight=10, classifier__n_estimators=306, classifier__subsample=0.8760149941898048\n",
      "[CV 1/5; 14/30] END classifier__colsample_bytree=0.6322502615579774, classifier__gamma=1.6745454139502411, classifier__learning_rate=0.03706622569174634, classifier__max_depth=31, classifier__min_child_weight=10, classifier__n_estimators=306, classifier__subsample=0.8760149941898048;, score=(train=0.969, test=0.929) total time=   0.6s\n",
      "[CV 2/5; 14/30] START classifier__colsample_bytree=0.6322502615579774, classifier__gamma=1.6745454139502411, classifier__learning_rate=0.03706622569174634, classifier__max_depth=31, classifier__min_child_weight=10, classifier__n_estimators=306, classifier__subsample=0.8760149941898048\n",
      "[CV 2/5; 14/30] END classifier__colsample_bytree=0.6322502615579774, classifier__gamma=1.6745454139502411, classifier__learning_rate=0.03706622569174634, classifier__max_depth=31, classifier__min_child_weight=10, classifier__n_estimators=306, classifier__subsample=0.8760149941898048;, score=(train=0.966, test=0.944) total time=   0.6s\n",
      "[CV 3/5; 14/30] START classifier__colsample_bytree=0.6322502615579774, classifier__gamma=1.6745454139502411, classifier__learning_rate=0.03706622569174634, classifier__max_depth=31, classifier__min_child_weight=10, classifier__n_estimators=306, classifier__subsample=0.8760149941898048\n",
      "[CV 3/5; 14/30] END classifier__colsample_bytree=0.6322502615579774, classifier__gamma=1.6745454139502411, classifier__learning_rate=0.03706622569174634, classifier__max_depth=31, classifier__min_child_weight=10, classifier__n_estimators=306, classifier__subsample=0.8760149941898048;, score=(train=0.965, test=0.943) total time=   0.6s\n",
      "[CV 4/5; 14/30] START classifier__colsample_bytree=0.6322502615579774, classifier__gamma=1.6745454139502411, classifier__learning_rate=0.03706622569174634, classifier__max_depth=31, classifier__min_child_weight=10, classifier__n_estimators=306, classifier__subsample=0.8760149941898048\n",
      "[CV 4/5; 14/30] END classifier__colsample_bytree=0.6322502615579774, classifier__gamma=1.6745454139502411, classifier__learning_rate=0.03706622569174634, classifier__max_depth=31, classifier__min_child_weight=10, classifier__n_estimators=306, classifier__subsample=0.8760149941898048;, score=(train=0.970, test=0.938) total time=   0.6s\n",
      "[CV 5/5; 14/30] START classifier__colsample_bytree=0.6322502615579774, classifier__gamma=1.6745454139502411, classifier__learning_rate=0.03706622569174634, classifier__max_depth=31, classifier__min_child_weight=10, classifier__n_estimators=306, classifier__subsample=0.8760149941898048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 14/30] END classifier__colsample_bytree=0.6322502615579774, classifier__gamma=1.6745454139502411, classifier__learning_rate=0.03706622569174634, classifier__max_depth=31, classifier__min_child_weight=10, classifier__n_estimators=306, classifier__subsample=0.8760149941898048;, score=(train=0.968, test=0.931) total time=   0.6s\n",
      "[CV 1/5; 15/30] START classifier__colsample_bytree=0.8609662221831338, classifier__gamma=1.3133193743300127, classifier__learning_rate=0.09726767275974331, classifier__max_depth=29, classifier__min_child_weight=9, classifier__n_estimators=240, classifier__subsample=0.5383549656432263\n",
      "[CV 1/5; 15/30] END classifier__colsample_bytree=0.8609662221831338, classifier__gamma=1.3133193743300127, classifier__learning_rate=0.09726767275974331, classifier__max_depth=29, classifier__min_child_weight=9, classifier__n_estimators=240, classifier__subsample=0.5383549656432263;, score=(train=0.967, test=0.923) total time=   0.4s\n",
      "[CV 2/5; 15/30] START classifier__colsample_bytree=0.8609662221831338, classifier__gamma=1.3133193743300127, classifier__learning_rate=0.09726767275974331, classifier__max_depth=29, classifier__min_child_weight=9, classifier__n_estimators=240, classifier__subsample=0.5383549656432263\n",
      "[CV 2/5; 15/30] END classifier__colsample_bytree=0.8609662221831338, classifier__gamma=1.3133193743300127, classifier__learning_rate=0.09726767275974331, classifier__max_depth=29, classifier__min_child_weight=9, classifier__n_estimators=240, classifier__subsample=0.5383549656432263;, score=(train=0.965, test=0.942) total time=   0.4s\n",
      "[CV 3/5; 15/30] START classifier__colsample_bytree=0.8609662221831338, classifier__gamma=1.3133193743300127, classifier__learning_rate=0.09726767275974331, classifier__max_depth=29, classifier__min_child_weight=9, classifier__n_estimators=240, classifier__subsample=0.5383549656432263\n",
      "[CV 3/5; 15/30] END classifier__colsample_bytree=0.8609662221831338, classifier__gamma=1.3133193743300127, classifier__learning_rate=0.09726767275974331, classifier__max_depth=29, classifier__min_child_weight=9, classifier__n_estimators=240, classifier__subsample=0.5383549656432263;, score=(train=0.968, test=0.946) total time=   0.4s\n",
      "[CV 4/5; 15/30] START classifier__colsample_bytree=0.8609662221831338, classifier__gamma=1.3133193743300127, classifier__learning_rate=0.09726767275974331, classifier__max_depth=29, classifier__min_child_weight=9, classifier__n_estimators=240, classifier__subsample=0.5383549656432263\n",
      "[CV 4/5; 15/30] END classifier__colsample_bytree=0.8609662221831338, classifier__gamma=1.3133193743300127, classifier__learning_rate=0.09726767275974331, classifier__max_depth=29, classifier__min_child_weight=9, classifier__n_estimators=240, classifier__subsample=0.5383549656432263;, score=(train=0.970, test=0.933) total time=   0.4s\n",
      "[CV 5/5; 15/30] START classifier__colsample_bytree=0.8609662221831338, classifier__gamma=1.3133193743300127, classifier__learning_rate=0.09726767275974331, classifier__max_depth=29, classifier__min_child_weight=9, classifier__n_estimators=240, classifier__subsample=0.5383549656432263\n",
      "[CV 5/5; 15/30] END classifier__colsample_bytree=0.8609662221831338, classifier__gamma=1.3133193743300127, classifier__learning_rate=0.09726767275974331, classifier__max_depth=29, classifier__min_child_weight=9, classifier__n_estimators=240, classifier__subsample=0.5383549656432263;, score=(train=0.968, test=0.931) total time=   0.4s\n",
      "[CV 1/5; 16/30] START classifier__colsample_bytree=0.8727894621048347, classifier__gamma=0.5937424121700385, classifier__learning_rate=0.08729545981149495, classifier__max_depth=16, classifier__min_child_weight=8, classifier__n_estimators=234, classifier__subsample=0.5235778669195507\n",
      "[CV 1/5; 16/30] END classifier__colsample_bytree=0.8727894621048347, classifier__gamma=0.5937424121700385, classifier__learning_rate=0.08729545981149495, classifier__max_depth=16, classifier__min_child_weight=8, classifier__n_estimators=234, classifier__subsample=0.5235778669195507;, score=(train=0.970, test=0.923) total time=   0.4s\n",
      "[CV 2/5; 16/30] START classifier__colsample_bytree=0.8727894621048347, classifier__gamma=0.5937424121700385, classifier__learning_rate=0.08729545981149495, classifier__max_depth=16, classifier__min_child_weight=8, classifier__n_estimators=234, classifier__subsample=0.5235778669195507\n",
      "[CV 2/5; 16/30] END classifier__colsample_bytree=0.8727894621048347, classifier__gamma=0.5937424121700385, classifier__learning_rate=0.08729545981149495, classifier__max_depth=16, classifier__min_child_weight=8, classifier__n_estimators=234, classifier__subsample=0.5235778669195507;, score=(train=0.969, test=0.939) total time=   0.4s\n",
      "[CV 3/5; 16/30] START classifier__colsample_bytree=0.8727894621048347, classifier__gamma=0.5937424121700385, classifier__learning_rate=0.08729545981149495, classifier__max_depth=16, classifier__min_child_weight=8, classifier__n_estimators=234, classifier__subsample=0.5235778669195507\n",
      "[CV 3/5; 16/30] END classifier__colsample_bytree=0.8727894621048347, classifier__gamma=0.5937424121700385, classifier__learning_rate=0.08729545981149495, classifier__max_depth=16, classifier__min_child_weight=8, classifier__n_estimators=234, classifier__subsample=0.5235778669195507;, score=(train=0.972, test=0.944) total time=   0.4s\n",
      "[CV 4/5; 16/30] START classifier__colsample_bytree=0.8727894621048347, classifier__gamma=0.5937424121700385, classifier__learning_rate=0.08729545981149495, classifier__max_depth=16, classifier__min_child_weight=8, classifier__n_estimators=234, classifier__subsample=0.5235778669195507\n",
      "[CV 4/5; 16/30] END classifier__colsample_bytree=0.8727894621048347, classifier__gamma=0.5937424121700385, classifier__learning_rate=0.08729545981149495, classifier__max_depth=16, classifier__min_child_weight=8, classifier__n_estimators=234, classifier__subsample=0.5235778669195507;, score=(train=0.972, test=0.923) total time=   0.4s\n",
      "[CV 5/5; 16/30] START classifier__colsample_bytree=0.8727894621048347, classifier__gamma=0.5937424121700385, classifier__learning_rate=0.08729545981149495, classifier__max_depth=16, classifier__min_child_weight=8, classifier__n_estimators=234, classifier__subsample=0.5235778669195507\n",
      "[CV 5/5; 16/30] END classifier__colsample_bytree=0.8727894621048347, classifier__gamma=0.5937424121700385, classifier__learning_rate=0.08729545981149495, classifier__max_depth=16, classifier__min_child_weight=8, classifier__n_estimators=234, classifier__subsample=0.5235778669195507;, score=(train=0.968, test=0.929) total time=   0.4s\n",
      "[CV 1/5; 17/30] START classifier__colsample_bytree=0.7213525418315376, classifier__gamma=0.7412052827139403, classifier__learning_rate=0.01194345410885048, classifier__max_depth=28, classifier__min_child_weight=6, classifier__n_estimators=166, classifier__subsample=0.766267400964384\n",
      "[CV 1/5; 17/30] END classifier__colsample_bytree=0.7213525418315376, classifier__gamma=0.7412052827139403, classifier__learning_rate=0.01194345410885048, classifier__max_depth=28, classifier__min_child_weight=6, classifier__n_estimators=166, classifier__subsample=0.766267400964384;, score=(train=0.948, test=0.920) total time=   0.4s\n",
      "[CV 2/5; 17/30] START classifier__colsample_bytree=0.7213525418315376, classifier__gamma=0.7412052827139403, classifier__learning_rate=0.01194345410885048, classifier__max_depth=28, classifier__min_child_weight=6, classifier__n_estimators=166, classifier__subsample=0.766267400964384\n",
      "[CV 2/5; 17/30] END classifier__colsample_bytree=0.7213525418315376, classifier__gamma=0.7412052827139403, classifier__learning_rate=0.01194345410885048, classifier__max_depth=28, classifier__min_child_weight=6, classifier__n_estimators=166, classifier__subsample=0.766267400964384;, score=(train=0.947, test=0.925) total time=   0.4s\n",
      "[CV 3/5; 17/30] START classifier__colsample_bytree=0.7213525418315376, classifier__gamma=0.7412052827139403, classifier__learning_rate=0.01194345410885048, classifier__max_depth=28, classifier__min_child_weight=6, classifier__n_estimators=166, classifier__subsample=0.766267400964384\n",
      "[CV 3/5; 17/30] END classifier__colsample_bytree=0.7213525418315376, classifier__gamma=0.7412052827139403, classifier__learning_rate=0.01194345410885048, classifier__max_depth=28, classifier__min_child_weight=6, classifier__n_estimators=166, classifier__subsample=0.766267400964384;, score=(train=0.946, test=0.948) total time=   0.4s\n",
      "[CV 4/5; 17/30] START classifier__colsample_bytree=0.7213525418315376, classifier__gamma=0.7412052827139403, classifier__learning_rate=0.01194345410885048, classifier__max_depth=28, classifier__min_child_weight=6, classifier__n_estimators=166, classifier__subsample=0.766267400964384\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 17/30] END classifier__colsample_bytree=0.7213525418315376, classifier__gamma=0.7412052827139403, classifier__learning_rate=0.01194345410885048, classifier__max_depth=28, classifier__min_child_weight=6, classifier__n_estimators=166, classifier__subsample=0.766267400964384;, score=(train=0.948, test=0.935) total time=   0.4s\n",
      "[CV 5/5; 17/30] START classifier__colsample_bytree=0.7213525418315376, classifier__gamma=0.7412052827139403, classifier__learning_rate=0.01194345410885048, classifier__max_depth=28, classifier__min_child_weight=6, classifier__n_estimators=166, classifier__subsample=0.766267400964384\n",
      "[CV 5/5; 17/30] END classifier__colsample_bytree=0.7213525418315376, classifier__gamma=0.7412052827139403, classifier__learning_rate=0.01194345410885048, classifier__max_depth=28, classifier__min_child_weight=6, classifier__n_estimators=166, classifier__subsample=0.766267400964384;, score=(train=0.948, test=0.924) total time=   0.4s\n",
      "[CV 1/5; 18/30] START classifier__colsample_bytree=0.6000859866656636, classifier__gamma=1.1775292007508447, classifier__learning_rate=0.05096957108544224, classifier__max_depth=46, classifier__min_child_weight=5, classifier__n_estimators=263, classifier__subsample=0.6614585079140863\n",
      "[CV 1/5; 18/30] END classifier__colsample_bytree=0.6000859866656636, classifier__gamma=1.1775292007508447, classifier__learning_rate=0.05096957108544224, classifier__max_depth=46, classifier__min_child_weight=5, classifier__n_estimators=263, classifier__subsample=0.6614585079140863;, score=(train=0.979, test=0.936) total time=   0.5s\n",
      "[CV 2/5; 18/30] START classifier__colsample_bytree=0.6000859866656636, classifier__gamma=1.1775292007508447, classifier__learning_rate=0.05096957108544224, classifier__max_depth=46, classifier__min_child_weight=5, classifier__n_estimators=263, classifier__subsample=0.6614585079140863\n",
      "[CV 2/5; 18/30] END classifier__colsample_bytree=0.6000859866656636, classifier__gamma=1.1775292007508447, classifier__learning_rate=0.05096957108544224, classifier__max_depth=46, classifier__min_child_weight=5, classifier__n_estimators=263, classifier__subsample=0.6614585079140863;, score=(train=0.978, test=0.942) total time=   0.5s\n",
      "[CV 3/5; 18/30] START classifier__colsample_bytree=0.6000859866656636, classifier__gamma=1.1775292007508447, classifier__learning_rate=0.05096957108544224, classifier__max_depth=46, classifier__min_child_weight=5, classifier__n_estimators=263, classifier__subsample=0.6614585079140863\n",
      "[CV 3/5; 18/30] END classifier__colsample_bytree=0.6000859866656636, classifier__gamma=1.1775292007508447, classifier__learning_rate=0.05096957108544224, classifier__max_depth=46, classifier__min_child_weight=5, classifier__n_estimators=263, classifier__subsample=0.6614585079140863;, score=(train=0.979, test=0.946) total time=   0.5s\n",
      "[CV 4/5; 18/30] START classifier__colsample_bytree=0.6000859866656636, classifier__gamma=1.1775292007508447, classifier__learning_rate=0.05096957108544224, classifier__max_depth=46, classifier__min_child_weight=5, classifier__n_estimators=263, classifier__subsample=0.6614585079140863\n",
      "[CV 4/5; 18/30] END classifier__colsample_bytree=0.6000859866656636, classifier__gamma=1.1775292007508447, classifier__learning_rate=0.05096957108544224, classifier__max_depth=46, classifier__min_child_weight=5, classifier__n_estimators=263, classifier__subsample=0.6614585079140863;, score=(train=0.980, test=0.938) total time=   0.5s\n",
      "[CV 5/5; 18/30] START classifier__colsample_bytree=0.6000859866656636, classifier__gamma=1.1775292007508447, classifier__learning_rate=0.05096957108544224, classifier__max_depth=46, classifier__min_child_weight=5, classifier__n_estimators=263, classifier__subsample=0.6614585079140863\n",
      "[CV 5/5; 18/30] END classifier__colsample_bytree=0.6000859866656636, classifier__gamma=1.1775292007508447, classifier__learning_rate=0.05096957108544224, classifier__max_depth=46, classifier__min_child_weight=5, classifier__n_estimators=263, classifier__subsample=0.6614585079140863;, score=(train=0.978, test=0.936) total time=   0.5s\n",
      "[CV 1/5; 19/30] START classifier__colsample_bytree=0.8477255159572683, classifier__gamma=1.588270905431998, classifier__learning_rate=0.07970009585983295, classifier__max_depth=17, classifier__min_child_weight=7, classifier__n_estimators=338, classifier__subsample=0.974936073064512\n",
      "[CV 1/5; 19/30] END classifier__colsample_bytree=0.8477255159572683, classifier__gamma=1.588270905431998, classifier__learning_rate=0.07970009585983295, classifier__max_depth=17, classifier__min_child_weight=7, classifier__n_estimators=338, classifier__subsample=0.974936073064512;, score=(train=0.985, test=0.935) total time=   0.8s\n",
      "[CV 2/5; 19/30] START classifier__colsample_bytree=0.8477255159572683, classifier__gamma=1.588270905431998, classifier__learning_rate=0.07970009585983295, classifier__max_depth=17, classifier__min_child_weight=7, classifier__n_estimators=338, classifier__subsample=0.974936073064512\n",
      "[CV 2/5; 19/30] END classifier__colsample_bytree=0.8477255159572683, classifier__gamma=1.588270905431998, classifier__learning_rate=0.07970009585983295, classifier__max_depth=17, classifier__min_child_weight=7, classifier__n_estimators=338, classifier__subsample=0.974936073064512;, score=(train=0.985, test=0.957) total time=   0.8s\n",
      "[CV 3/5; 19/30] START classifier__colsample_bytree=0.8477255159572683, classifier__gamma=1.588270905431998, classifier__learning_rate=0.07970009585983295, classifier__max_depth=17, classifier__min_child_weight=7, classifier__n_estimators=338, classifier__subsample=0.974936073064512\n",
      "[CV 3/5; 19/30] END classifier__colsample_bytree=0.8477255159572683, classifier__gamma=1.588270905431998, classifier__learning_rate=0.07970009585983295, classifier__max_depth=17, classifier__min_child_weight=7, classifier__n_estimators=338, classifier__subsample=0.974936073064512;, score=(train=0.986, test=0.946) total time=   0.8s\n",
      "[CV 4/5; 19/30] START classifier__colsample_bytree=0.8477255159572683, classifier__gamma=1.588270905431998, classifier__learning_rate=0.07970009585983295, classifier__max_depth=17, classifier__min_child_weight=7, classifier__n_estimators=338, classifier__subsample=0.974936073064512\n",
      "[CV 4/5; 19/30] END classifier__colsample_bytree=0.8477255159572683, classifier__gamma=1.588270905431998, classifier__learning_rate=0.07970009585983295, classifier__max_depth=17, classifier__min_child_weight=7, classifier__n_estimators=338, classifier__subsample=0.974936073064512;, score=(train=0.987, test=0.931) total time=   0.8s\n",
      "[CV 5/5; 19/30] START classifier__colsample_bytree=0.8477255159572683, classifier__gamma=1.588270905431998, classifier__learning_rate=0.07970009585983295, classifier__max_depth=17, classifier__min_child_weight=7, classifier__n_estimators=338, classifier__subsample=0.974936073064512\n",
      "[CV 5/5; 19/30] END classifier__colsample_bytree=0.8477255159572683, classifier__gamma=1.588270905431998, classifier__learning_rate=0.07970009585983295, classifier__max_depth=17, classifier__min_child_weight=7, classifier__n_estimators=338, classifier__subsample=0.974936073064512;, score=(train=0.984, test=0.943) total time=   0.7s\n",
      "[CV 1/5; 20/30] START classifier__colsample_bytree=0.79428754815344, classifier__gamma=1.4114811129476008, classifier__learning_rate=0.04246907114005851, classifier__max_depth=19, classifier__min_child_weight=8, classifier__n_estimators=364, classifier__subsample=0.9337755034532713\n",
      "[CV 1/5; 20/30] END classifier__colsample_bytree=0.79428754815344, classifier__gamma=1.4114811129476008, classifier__learning_rate=0.04246907114005851, classifier__max_depth=19, classifier__min_child_weight=8, classifier__n_estimators=364, classifier__subsample=0.9337755034532713;, score=(train=0.979, test=0.933) total time=   0.8s\n",
      "[CV 2/5; 20/30] START classifier__colsample_bytree=0.79428754815344, classifier__gamma=1.4114811129476008, classifier__learning_rate=0.04246907114005851, classifier__max_depth=19, classifier__min_child_weight=8, classifier__n_estimators=364, classifier__subsample=0.9337755034532713\n",
      "[CV 2/5; 20/30] END classifier__colsample_bytree=0.79428754815344, classifier__gamma=1.4114811129476008, classifier__learning_rate=0.04246907114005851, classifier__max_depth=19, classifier__min_child_weight=8, classifier__n_estimators=364, classifier__subsample=0.9337755034532713;, score=(train=0.981, test=0.954) total time=   0.8s\n",
      "[CV 3/5; 20/30] START classifier__colsample_bytree=0.79428754815344, classifier__gamma=1.4114811129476008, classifier__learning_rate=0.04246907114005851, classifier__max_depth=19, classifier__min_child_weight=8, classifier__n_estimators=364, classifier__subsample=0.9337755034532713\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 20/30] END classifier__colsample_bytree=0.79428754815344, classifier__gamma=1.4114811129476008, classifier__learning_rate=0.04246907114005851, classifier__max_depth=19, classifier__min_child_weight=8, classifier__n_estimators=364, classifier__subsample=0.9337755034532713;, score=(train=0.980, test=0.943) total time=   0.8s\n",
      "[CV 4/5; 20/30] START classifier__colsample_bytree=0.79428754815344, classifier__gamma=1.4114811129476008, classifier__learning_rate=0.04246907114005851, classifier__max_depth=19, classifier__min_child_weight=8, classifier__n_estimators=364, classifier__subsample=0.9337755034532713\n",
      "[CV 4/5; 20/30] END classifier__colsample_bytree=0.79428754815344, classifier__gamma=1.4114811129476008, classifier__learning_rate=0.04246907114005851, classifier__max_depth=19, classifier__min_child_weight=8, classifier__n_estimators=364, classifier__subsample=0.9337755034532713;, score=(train=0.981, test=0.938) total time=   0.8s\n",
      "[CV 5/5; 20/30] START classifier__colsample_bytree=0.79428754815344, classifier__gamma=1.4114811129476008, classifier__learning_rate=0.04246907114005851, classifier__max_depth=19, classifier__min_child_weight=8, classifier__n_estimators=364, classifier__subsample=0.9337755034532713\n",
      "[CV 5/5; 20/30] END classifier__colsample_bytree=0.79428754815344, classifier__gamma=1.4114811129476008, classifier__learning_rate=0.04246907114005851, classifier__max_depth=19, classifier__min_child_weight=8, classifier__n_estimators=364, classifier__subsample=0.9337755034532713;, score=(train=0.978, test=0.943) total time=   0.8s\n",
      "[CV 1/5; 21/30] START classifier__colsample_bytree=0.962545809317217, classifier__gamma=0.41596243966872626, classifier__learning_rate=0.023168535868395727, classifier__max_depth=48, classifier__min_child_weight=2, classifier__n_estimators=309, classifier__subsample=0.9146727081882269\n",
      "[CV 1/5; 21/30] END classifier__colsample_bytree=0.962545809317217, classifier__gamma=0.41596243966872626, classifier__learning_rate=0.023168535868395727, classifier__max_depth=48, classifier__min_child_weight=2, classifier__n_estimators=309, classifier__subsample=0.9146727081882269;, score=(train=0.993, test=0.938) total time=   1.2s\n",
      "[CV 2/5; 21/30] START classifier__colsample_bytree=0.962545809317217, classifier__gamma=0.41596243966872626, classifier__learning_rate=0.023168535868395727, classifier__max_depth=48, classifier__min_child_weight=2, classifier__n_estimators=309, classifier__subsample=0.9146727081882269\n",
      "[CV 2/5; 21/30] END classifier__colsample_bytree=0.962545809317217, classifier__gamma=0.41596243966872626, classifier__learning_rate=0.023168535868395727, classifier__max_depth=48, classifier__min_child_weight=2, classifier__n_estimators=309, classifier__subsample=0.9146727081882269;, score=(train=0.993, test=0.952) total time=   1.3s\n",
      "[CV 3/5; 21/30] START classifier__colsample_bytree=0.962545809317217, classifier__gamma=0.41596243966872626, classifier__learning_rate=0.023168535868395727, classifier__max_depth=48, classifier__min_child_weight=2, classifier__n_estimators=309, classifier__subsample=0.9146727081882269\n",
      "[CV 3/5; 21/30] END classifier__colsample_bytree=0.962545809317217, classifier__gamma=0.41596243966872626, classifier__learning_rate=0.023168535868395727, classifier__max_depth=48, classifier__min_child_weight=2, classifier__n_estimators=309, classifier__subsample=0.9146727081882269;, score=(train=0.994, test=0.950) total time=   1.3s\n",
      "[CV 4/5; 21/30] START classifier__colsample_bytree=0.962545809317217, classifier__gamma=0.41596243966872626, classifier__learning_rate=0.023168535868395727, classifier__max_depth=48, classifier__min_child_weight=2, classifier__n_estimators=309, classifier__subsample=0.9146727081882269\n",
      "[CV 4/5; 21/30] END classifier__colsample_bytree=0.962545809317217, classifier__gamma=0.41596243966872626, classifier__learning_rate=0.023168535868395727, classifier__max_depth=48, classifier__min_child_weight=2, classifier__n_estimators=309, classifier__subsample=0.9146727081882269;, score=(train=0.995, test=0.942) total time=   1.3s\n",
      "[CV 5/5; 21/30] START classifier__colsample_bytree=0.962545809317217, classifier__gamma=0.41596243966872626, classifier__learning_rate=0.023168535868395727, classifier__max_depth=48, classifier__min_child_weight=2, classifier__n_estimators=309, classifier__subsample=0.9146727081882269\n",
      "[CV 5/5; 21/30] END classifier__colsample_bytree=0.962545809317217, classifier__gamma=0.41596243966872626, classifier__learning_rate=0.023168535868395727, classifier__max_depth=48, classifier__min_child_weight=2, classifier__n_estimators=309, classifier__subsample=0.9146727081882269;, score=(train=0.992, test=0.946) total time=   1.3s\n",
      "[CV 1/5; 22/30] START classifier__colsample_bytree=0.7976656271409582, classifier__gamma=1.0248532114979563, classifier__learning_rate=0.033665419570848704, classifier__max_depth=22, classifier__min_child_weight=7, classifier__n_estimators=264, classifier__subsample=0.9104032281632988\n",
      "[CV 1/5; 22/30] END classifier__colsample_bytree=0.7976656271409582, classifier__gamma=1.0248532114979563, classifier__learning_rate=0.033665419570848704, classifier__max_depth=22, classifier__min_child_weight=7, classifier__n_estimators=264, classifier__subsample=0.9104032281632988;, score=(train=0.978, test=0.929) total time=   0.7s\n",
      "[CV 2/5; 22/30] START classifier__colsample_bytree=0.7976656271409582, classifier__gamma=1.0248532114979563, classifier__learning_rate=0.033665419570848704, classifier__max_depth=22, classifier__min_child_weight=7, classifier__n_estimators=264, classifier__subsample=0.9104032281632988\n",
      "[CV 2/5; 22/30] END classifier__colsample_bytree=0.7976656271409582, classifier__gamma=1.0248532114979563, classifier__learning_rate=0.033665419570848704, classifier__max_depth=22, classifier__min_child_weight=7, classifier__n_estimators=264, classifier__subsample=0.9104032281632988;, score=(train=0.976, test=0.950) total time=   0.7s\n",
      "[CV 3/5; 22/30] START classifier__colsample_bytree=0.7976656271409582, classifier__gamma=1.0248532114979563, classifier__learning_rate=0.033665419570848704, classifier__max_depth=22, classifier__min_child_weight=7, classifier__n_estimators=264, classifier__subsample=0.9104032281632988\n",
      "[CV 3/5; 22/30] END classifier__colsample_bytree=0.7976656271409582, classifier__gamma=1.0248532114979563, classifier__learning_rate=0.033665419570848704, classifier__max_depth=22, classifier__min_child_weight=7, classifier__n_estimators=264, classifier__subsample=0.9104032281632988;, score=(train=0.976, test=0.943) total time=   0.7s\n",
      "[CV 4/5; 22/30] START classifier__colsample_bytree=0.7976656271409582, classifier__gamma=1.0248532114979563, classifier__learning_rate=0.033665419570848704, classifier__max_depth=22, classifier__min_child_weight=7, classifier__n_estimators=264, classifier__subsample=0.9104032281632988\n",
      "[CV 4/5; 22/30] END classifier__colsample_bytree=0.7976656271409582, classifier__gamma=1.0248532114979563, classifier__learning_rate=0.033665419570848704, classifier__max_depth=22, classifier__min_child_weight=7, classifier__n_estimators=264, classifier__subsample=0.9104032281632988;, score=(train=0.978, test=0.938) total time=   0.7s\n",
      "[CV 5/5; 22/30] START classifier__colsample_bytree=0.7976656271409582, classifier__gamma=1.0248532114979563, classifier__learning_rate=0.033665419570848704, classifier__max_depth=22, classifier__min_child_weight=7, classifier__n_estimators=264, classifier__subsample=0.9104032281632988\n",
      "[CV 5/5; 22/30] END classifier__colsample_bytree=0.7976656271409582, classifier__gamma=1.0248532114979563, classifier__learning_rate=0.033665419570848704, classifier__max_depth=22, classifier__min_child_weight=7, classifier__n_estimators=264, classifier__subsample=0.9104032281632988;, score=(train=0.975, test=0.938) total time=   0.7s\n",
      "[CV 1/5; 23/30] START classifier__colsample_bytree=0.7425719378570268, classifier__gamma=2.713562348515585, classifier__learning_rate=0.040264499265071106, classifier__max_depth=44, classifier__min_child_weight=9, classifier__n_estimators=171, classifier__subsample=0.7778327045075035\n",
      "[CV 1/5; 23/30] END classifier__colsample_bytree=0.7425719378570268, classifier__gamma=2.713562348515585, classifier__learning_rate=0.040264499265071106, classifier__max_depth=44, classifier__min_child_weight=9, classifier__n_estimators=171, classifier__subsample=0.7778327045075035;, score=(train=0.959, test=0.927) total time=   0.3s\n",
      "[CV 2/5; 23/30] START classifier__colsample_bytree=0.7425719378570268, classifier__gamma=2.713562348515585, classifier__learning_rate=0.040264499265071106, classifier__max_depth=44, classifier__min_child_weight=9, classifier__n_estimators=171, classifier__subsample=0.7778327045075035\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 23/30] END classifier__colsample_bytree=0.7425719378570268, classifier__gamma=2.713562348515585, classifier__learning_rate=0.040264499265071106, classifier__max_depth=44, classifier__min_child_weight=9, classifier__n_estimators=171, classifier__subsample=0.7778327045075035;, score=(train=0.957, test=0.947) total time=   0.3s\n",
      "[CV 3/5; 23/30] START classifier__colsample_bytree=0.7425719378570268, classifier__gamma=2.713562348515585, classifier__learning_rate=0.040264499265071106, classifier__max_depth=44, classifier__min_child_weight=9, classifier__n_estimators=171, classifier__subsample=0.7778327045075035\n",
      "[CV 3/5; 23/30] END classifier__colsample_bytree=0.7425719378570268, classifier__gamma=2.713562348515585, classifier__learning_rate=0.040264499265071106, classifier__max_depth=44, classifier__min_child_weight=9, classifier__n_estimators=171, classifier__subsample=0.7778327045075035;, score=(train=0.957, test=0.946) total time=   0.3s\n",
      "[CV 4/5; 23/30] START classifier__colsample_bytree=0.7425719378570268, classifier__gamma=2.713562348515585, classifier__learning_rate=0.040264499265071106, classifier__max_depth=44, classifier__min_child_weight=9, classifier__n_estimators=171, classifier__subsample=0.7778327045075035\n",
      "[CV 4/5; 23/30] END classifier__colsample_bytree=0.7425719378570268, classifier__gamma=2.713562348515585, classifier__learning_rate=0.040264499265071106, classifier__max_depth=44, classifier__min_child_weight=9, classifier__n_estimators=171, classifier__subsample=0.7778327045075035;, score=(train=0.960, test=0.935) total time=   0.3s\n",
      "[CV 5/5; 23/30] START classifier__colsample_bytree=0.7425719378570268, classifier__gamma=2.713562348515585, classifier__learning_rate=0.040264499265071106, classifier__max_depth=44, classifier__min_child_weight=9, classifier__n_estimators=171, classifier__subsample=0.7778327045075035\n",
      "[CV 5/5; 23/30] END classifier__colsample_bytree=0.7425719378570268, classifier__gamma=2.713562348515585, classifier__learning_rate=0.040264499265071106, classifier__max_depth=44, classifier__min_child_weight=9, classifier__n_estimators=171, classifier__subsample=0.7778327045075035;, score=(train=0.957, test=0.929) total time=   0.3s\n",
      "[CV 1/5; 24/30] START classifier__colsample_bytree=0.5183562779747775, classifier__gamma=1.4691002528548642, classifier__learning_rate=0.06530346647862398, classifier__max_depth=13, classifier__min_child_weight=6, classifier__n_estimators=202, classifier__subsample=0.905647232306031\n",
      "[CV 1/5; 24/30] END classifier__colsample_bytree=0.5183562779747775, classifier__gamma=1.4691002528548642, classifier__learning_rate=0.06530346647862398, classifier__max_depth=13, classifier__min_child_weight=6, classifier__n_estimators=202, classifier__subsample=0.905647232306031;, score=(train=0.982, test=0.938) total time=   0.4s\n",
      "[CV 2/5; 24/30] START classifier__colsample_bytree=0.5183562779747775, classifier__gamma=1.4691002528548642, classifier__learning_rate=0.06530346647862398, classifier__max_depth=13, classifier__min_child_weight=6, classifier__n_estimators=202, classifier__subsample=0.905647232306031\n",
      "[CV 2/5; 24/30] END classifier__colsample_bytree=0.5183562779747775, classifier__gamma=1.4691002528548642, classifier__learning_rate=0.06530346647862398, classifier__max_depth=13, classifier__min_child_weight=6, classifier__n_estimators=202, classifier__subsample=0.905647232306031;, score=(train=0.979, test=0.950) total time=   0.4s\n",
      "[CV 3/5; 24/30] START classifier__colsample_bytree=0.5183562779747775, classifier__gamma=1.4691002528548642, classifier__learning_rate=0.06530346647862398, classifier__max_depth=13, classifier__min_child_weight=6, classifier__n_estimators=202, classifier__subsample=0.905647232306031\n",
      "[CV 3/5; 24/30] END classifier__colsample_bytree=0.5183562779747775, classifier__gamma=1.4691002528548642, classifier__learning_rate=0.06530346647862398, classifier__max_depth=13, classifier__min_child_weight=6, classifier__n_estimators=202, classifier__subsample=0.905647232306031;, score=(train=0.981, test=0.946) total time=   0.4s\n",
      "[CV 4/5; 24/30] START classifier__colsample_bytree=0.5183562779747775, classifier__gamma=1.4691002528548642, classifier__learning_rate=0.06530346647862398, classifier__max_depth=13, classifier__min_child_weight=6, classifier__n_estimators=202, classifier__subsample=0.905647232306031\n",
      "[CV 4/5; 24/30] END classifier__colsample_bytree=0.5183562779747775, classifier__gamma=1.4691002528548642, classifier__learning_rate=0.06530346647862398, classifier__max_depth=13, classifier__min_child_weight=6, classifier__n_estimators=202, classifier__subsample=0.905647232306031;, score=(train=0.982, test=0.935) total time=   0.4s\n",
      "[CV 5/5; 24/30] START classifier__colsample_bytree=0.5183562779747775, classifier__gamma=1.4691002528548642, classifier__learning_rate=0.06530346647862398, classifier__max_depth=13, classifier__min_child_weight=6, classifier__n_estimators=202, classifier__subsample=0.905647232306031\n",
      "[CV 5/5; 24/30] END classifier__colsample_bytree=0.5183562779747775, classifier__gamma=1.4691002528548642, classifier__learning_rate=0.06530346647862398, classifier__max_depth=13, classifier__min_child_weight=6, classifier__n_estimators=202, classifier__subsample=0.905647232306031;, score=(train=0.978, test=0.938) total time=   0.4s\n",
      "[CV 1/5; 25/30] START classifier__colsample_bytree=0.6201223579493627, classifier__gamma=2.634739765858502, classifier__learning_rate=0.07339030951274318, classifier__max_depth=19, classifier__min_child_weight=4, classifier__n_estimators=299, classifier__subsample=0.7028234633944757\n",
      "[CV 1/5; 25/30] END classifier__colsample_bytree=0.6201223579493627, classifier__gamma=2.634739765858502, classifier__learning_rate=0.07339030951274318, classifier__max_depth=19, classifier__min_child_weight=4, classifier__n_estimators=299, classifier__subsample=0.7028234633944757;, score=(train=0.979, test=0.940) total time=   0.7s\n",
      "[CV 2/5; 25/30] START classifier__colsample_bytree=0.6201223579493627, classifier__gamma=2.634739765858502, classifier__learning_rate=0.07339030951274318, classifier__max_depth=19, classifier__min_child_weight=4, classifier__n_estimators=299, classifier__subsample=0.7028234633944757\n",
      "[CV 2/5; 25/30] END classifier__colsample_bytree=0.6201223579493627, classifier__gamma=2.634739765858502, classifier__learning_rate=0.07339030951274318, classifier__max_depth=19, classifier__min_child_weight=4, classifier__n_estimators=299, classifier__subsample=0.7028234633944757;, score=(train=0.978, test=0.948) total time=   0.7s\n",
      "[CV 3/5; 25/30] START classifier__colsample_bytree=0.6201223579493627, classifier__gamma=2.634739765858502, classifier__learning_rate=0.07339030951274318, classifier__max_depth=19, classifier__min_child_weight=4, classifier__n_estimators=299, classifier__subsample=0.7028234633944757\n",
      "[CV 3/5; 25/30] END classifier__colsample_bytree=0.6201223579493627, classifier__gamma=2.634739765858502, classifier__learning_rate=0.07339030951274318, classifier__max_depth=19, classifier__min_child_weight=4, classifier__n_estimators=299, classifier__subsample=0.7028234633944757;, score=(train=0.979, test=0.943) total time=   0.7s\n",
      "[CV 4/5; 25/30] START classifier__colsample_bytree=0.6201223579493627, classifier__gamma=2.634739765858502, classifier__learning_rate=0.07339030951274318, classifier__max_depth=19, classifier__min_child_weight=4, classifier__n_estimators=299, classifier__subsample=0.7028234633944757\n",
      "[CV 4/5; 25/30] END classifier__colsample_bytree=0.6201223579493627, classifier__gamma=2.634739765858502, classifier__learning_rate=0.07339030951274318, classifier__max_depth=19, classifier__min_child_weight=4, classifier__n_estimators=299, classifier__subsample=0.7028234633944757;, score=(train=0.982, test=0.936) total time=   0.7s\n",
      "[CV 5/5; 25/30] START classifier__colsample_bytree=0.6201223579493627, classifier__gamma=2.634739765858502, classifier__learning_rate=0.07339030951274318, classifier__max_depth=19, classifier__min_child_weight=4, classifier__n_estimators=299, classifier__subsample=0.7028234633944757\n",
      "[CV 5/5; 25/30] END classifier__colsample_bytree=0.6201223579493627, classifier__gamma=2.634739765858502, classifier__learning_rate=0.07339030951274318, classifier__max_depth=19, classifier__min_child_weight=4, classifier__n_estimators=299, classifier__subsample=0.7028234633944757;, score=(train=0.978, test=0.935) total time=   0.7s\n",
      "[CV 1/5; 26/30] START classifier__colsample_bytree=0.9468703732284134, classifier__gamma=0.5385718744808886, classifier__learning_rate=0.09129470016164386, classifier__max_depth=20, classifier__min_child_weight=8, classifier__n_estimators=428, classifier__subsample=0.8662050574878541\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 26/30] END classifier__colsample_bytree=0.9468703732284134, classifier__gamma=0.5385718744808886, classifier__learning_rate=0.09129470016164386, classifier__max_depth=20, classifier__min_child_weight=8, classifier__n_estimators=428, classifier__subsample=0.8662050574878541;, score=(train=0.991, test=0.929) total time=   0.9s\n",
      "[CV 2/5; 26/30] START classifier__colsample_bytree=0.9468703732284134, classifier__gamma=0.5385718744808886, classifier__learning_rate=0.09129470016164386, classifier__max_depth=20, classifier__min_child_weight=8, classifier__n_estimators=428, classifier__subsample=0.8662050574878541\n",
      "[CV 2/5; 26/30] END classifier__colsample_bytree=0.9468703732284134, classifier__gamma=0.5385718744808886, classifier__learning_rate=0.09129470016164386, classifier__max_depth=20, classifier__min_child_weight=8, classifier__n_estimators=428, classifier__subsample=0.8662050574878541;, score=(train=0.990, test=0.951) total time=   0.9s\n",
      "[CV 3/5; 26/30] START classifier__colsample_bytree=0.9468703732284134, classifier__gamma=0.5385718744808886, classifier__learning_rate=0.09129470016164386, classifier__max_depth=20, classifier__min_child_weight=8, classifier__n_estimators=428, classifier__subsample=0.8662050574878541\n",
      "[CV 3/5; 26/30] END classifier__colsample_bytree=0.9468703732284134, classifier__gamma=0.5385718744808886, classifier__learning_rate=0.09129470016164386, classifier__max_depth=20, classifier__min_child_weight=8, classifier__n_estimators=428, classifier__subsample=0.8662050574878541;, score=(train=0.991, test=0.943) total time=   0.9s\n",
      "[CV 4/5; 26/30] START classifier__colsample_bytree=0.9468703732284134, classifier__gamma=0.5385718744808886, classifier__learning_rate=0.09129470016164386, classifier__max_depth=20, classifier__min_child_weight=8, classifier__n_estimators=428, classifier__subsample=0.8662050574878541\n",
      "[CV 4/5; 26/30] END classifier__colsample_bytree=0.9468703732284134, classifier__gamma=0.5385718744808886, classifier__learning_rate=0.09129470016164386, classifier__max_depth=20, classifier__min_child_weight=8, classifier__n_estimators=428, classifier__subsample=0.8662050574878541;, score=(train=0.993, test=0.931) total time=   0.9s\n",
      "[CV 5/5; 26/30] START classifier__colsample_bytree=0.9468703732284134, classifier__gamma=0.5385718744808886, classifier__learning_rate=0.09129470016164386, classifier__max_depth=20, classifier__min_child_weight=8, classifier__n_estimators=428, classifier__subsample=0.8662050574878541\n",
      "[CV 5/5; 26/30] END classifier__colsample_bytree=0.9468703732284134, classifier__gamma=0.5385718744808886, classifier__learning_rate=0.09129470016164386, classifier__max_depth=20, classifier__min_child_weight=8, classifier__n_estimators=428, classifier__subsample=0.8662050574878541;, score=(train=0.990, test=0.940) total time=   0.9s\n",
      "[CV 1/5; 27/30] START classifier__colsample_bytree=0.8947047155749034, classifier__gamma=1.2495697052348345, classifier__learning_rate=0.024913662972690556, classifier__max_depth=32, classifier__min_child_weight=6, classifier__n_estimators=461, classifier__subsample=0.7074845203828319\n",
      "[CV 1/5; 27/30] END classifier__colsample_bytree=0.8947047155749034, classifier__gamma=1.2495697052348345, classifier__learning_rate=0.024913662972690556, classifier__max_depth=32, classifier__min_child_weight=6, classifier__n_estimators=461, classifier__subsample=0.7074845203828319;, score=(train=0.977, test=0.936) total time=   1.1s\n",
      "[CV 2/5; 27/30] START classifier__colsample_bytree=0.8947047155749034, classifier__gamma=1.2495697052348345, classifier__learning_rate=0.024913662972690556, classifier__max_depth=32, classifier__min_child_weight=6, classifier__n_estimators=461, classifier__subsample=0.7074845203828319\n",
      "[CV 2/5; 27/30] END classifier__colsample_bytree=0.8947047155749034, classifier__gamma=1.2495697052348345, classifier__learning_rate=0.024913662972690556, classifier__max_depth=32, classifier__min_child_weight=6, classifier__n_estimators=461, classifier__subsample=0.7074845203828319;, score=(train=0.977, test=0.948) total time=   1.2s\n",
      "[CV 3/5; 27/30] START classifier__colsample_bytree=0.8947047155749034, classifier__gamma=1.2495697052348345, classifier__learning_rate=0.024913662972690556, classifier__max_depth=32, classifier__min_child_weight=6, classifier__n_estimators=461, classifier__subsample=0.7074845203828319\n",
      "[CV 3/5; 27/30] END classifier__colsample_bytree=0.8947047155749034, classifier__gamma=1.2495697052348345, classifier__learning_rate=0.024913662972690556, classifier__max_depth=32, classifier__min_child_weight=6, classifier__n_estimators=461, classifier__subsample=0.7074845203828319;, score=(train=0.977, test=0.942) total time=   1.2s\n",
      "[CV 4/5; 27/30] START classifier__colsample_bytree=0.8947047155749034, classifier__gamma=1.2495697052348345, classifier__learning_rate=0.024913662972690556, classifier__max_depth=32, classifier__min_child_weight=6, classifier__n_estimators=461, classifier__subsample=0.7074845203828319\n",
      "[CV 4/5; 27/30] END classifier__colsample_bytree=0.8947047155749034, classifier__gamma=1.2495697052348345, classifier__learning_rate=0.024913662972690556, classifier__max_depth=32, classifier__min_child_weight=6, classifier__n_estimators=461, classifier__subsample=0.7074845203828319;, score=(train=0.978, test=0.932) total time=   1.1s\n",
      "[CV 5/5; 27/30] START classifier__colsample_bytree=0.8947047155749034, classifier__gamma=1.2495697052348345, classifier__learning_rate=0.024913662972690556, classifier__max_depth=32, classifier__min_child_weight=6, classifier__n_estimators=461, classifier__subsample=0.7074845203828319\n",
      "[CV 5/5; 27/30] END classifier__colsample_bytree=0.8947047155749034, classifier__gamma=1.2495697052348345, classifier__learning_rate=0.024913662972690556, classifier__max_depth=32, classifier__min_child_weight=6, classifier__n_estimators=461, classifier__subsample=0.7074845203828319;, score=(train=0.977, test=0.940) total time=   1.1s\n",
      "[CV 1/5; 28/30] START classifier__colsample_bytree=0.7414408007695954, classifier__gamma=1.4106823797858072, classifier__learning_rate=0.016169517297092012, classifier__max_depth=41, classifier__min_child_weight=7, classifier__n_estimators=231, classifier__subsample=0.7034776016317922\n",
      "[CV 1/5; 28/30] END classifier__colsample_bytree=0.7414408007695954, classifier__gamma=1.4106823797858072, classifier__learning_rate=0.016169517297092012, classifier__max_depth=41, classifier__min_child_weight=7, classifier__n_estimators=231, classifier__subsample=0.7034776016317922;, score=(train=0.955, test=0.927) total time=   0.5s\n",
      "[CV 2/5; 28/30] START classifier__colsample_bytree=0.7414408007695954, classifier__gamma=1.4106823797858072, classifier__learning_rate=0.016169517297092012, classifier__max_depth=41, classifier__min_child_weight=7, classifier__n_estimators=231, classifier__subsample=0.7034776016317922\n",
      "[CV 2/5; 28/30] END classifier__colsample_bytree=0.7414408007695954, classifier__gamma=1.4106823797858072, classifier__learning_rate=0.016169517297092012, classifier__max_depth=41, classifier__min_child_weight=7, classifier__n_estimators=231, classifier__subsample=0.7034776016317922;, score=(train=0.952, test=0.936) total time=   0.6s\n",
      "[CV 3/5; 28/30] START classifier__colsample_bytree=0.7414408007695954, classifier__gamma=1.4106823797858072, classifier__learning_rate=0.016169517297092012, classifier__max_depth=41, classifier__min_child_weight=7, classifier__n_estimators=231, classifier__subsample=0.7034776016317922\n",
      "[CV 3/5; 28/30] END classifier__colsample_bytree=0.7414408007695954, classifier__gamma=1.4106823797858072, classifier__learning_rate=0.016169517297092012, classifier__max_depth=41, classifier__min_child_weight=7, classifier__n_estimators=231, classifier__subsample=0.7034776016317922;, score=(train=0.953, test=0.952) total time=   0.5s\n",
      "[CV 4/5; 28/30] START classifier__colsample_bytree=0.7414408007695954, classifier__gamma=1.4106823797858072, classifier__learning_rate=0.016169517297092012, classifier__max_depth=41, classifier__min_child_weight=7, classifier__n_estimators=231, classifier__subsample=0.7034776016317922\n",
      "[CV 4/5; 28/30] END classifier__colsample_bytree=0.7414408007695954, classifier__gamma=1.4106823797858072, classifier__learning_rate=0.016169517297092012, classifier__max_depth=41, classifier__min_child_weight=7, classifier__n_estimators=231, classifier__subsample=0.7034776016317922;, score=(train=0.957, test=0.936) total time=   0.5s\n",
      "[CV 5/5; 28/30] START classifier__colsample_bytree=0.7414408007695954, classifier__gamma=1.4106823797858072, classifier__learning_rate=0.016169517297092012, classifier__max_depth=41, classifier__min_child_weight=7, classifier__n_estimators=231, classifier__subsample=0.7034776016317922\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 28/30] END classifier__colsample_bytree=0.7414408007695954, classifier__gamma=1.4106823797858072, classifier__learning_rate=0.016169517297092012, classifier__max_depth=41, classifier__min_child_weight=7, classifier__n_estimators=231, classifier__subsample=0.7034776016317922;, score=(train=0.954, test=0.928) total time=   0.5s\n",
      "[CV 1/5; 29/30] START classifier__colsample_bytree=0.5916655028150088, classifier__gamma=0.9332841348337217, classifier__learning_rate=0.01357111567863781, classifier__max_depth=28, classifier__min_child_weight=3, classifier__n_estimators=252, classifier__subsample=0.9776304599933507\n",
      "[CV 1/5; 29/30] END classifier__colsample_bytree=0.5916655028150088, classifier__gamma=0.9332841348337217, classifier__learning_rate=0.01357111567863781, classifier__max_depth=28, classifier__min_child_weight=3, classifier__n_estimators=252, classifier__subsample=0.9776304599933507;, score=(train=0.977, test=0.938) total time=   0.8s\n",
      "[CV 2/5; 29/30] START classifier__colsample_bytree=0.5916655028150088, classifier__gamma=0.9332841348337217, classifier__learning_rate=0.01357111567863781, classifier__max_depth=28, classifier__min_child_weight=3, classifier__n_estimators=252, classifier__subsample=0.9776304599933507\n",
      "[CV 2/5; 29/30] END classifier__colsample_bytree=0.5916655028150088, classifier__gamma=0.9332841348337217, classifier__learning_rate=0.01357111567863781, classifier__max_depth=28, classifier__min_child_weight=3, classifier__n_estimators=252, classifier__subsample=0.9776304599933507;, score=(train=0.972, test=0.940) total time=   0.8s\n",
      "[CV 3/5; 29/30] START classifier__colsample_bytree=0.5916655028150088, classifier__gamma=0.9332841348337217, classifier__learning_rate=0.01357111567863781, classifier__max_depth=28, classifier__min_child_weight=3, classifier__n_estimators=252, classifier__subsample=0.9776304599933507\n",
      "[CV 3/5; 29/30] END classifier__colsample_bytree=0.5916655028150088, classifier__gamma=0.9332841348337217, classifier__learning_rate=0.01357111567863781, classifier__max_depth=28, classifier__min_child_weight=3, classifier__n_estimators=252, classifier__subsample=0.9776304599933507;, score=(train=0.977, test=0.948) total time=   0.8s\n",
      "[CV 4/5; 29/30] START classifier__colsample_bytree=0.5916655028150088, classifier__gamma=0.9332841348337217, classifier__learning_rate=0.01357111567863781, classifier__max_depth=28, classifier__min_child_weight=3, classifier__n_estimators=252, classifier__subsample=0.9776304599933507\n",
      "[CV 4/5; 29/30] END classifier__colsample_bytree=0.5916655028150088, classifier__gamma=0.9332841348337217, classifier__learning_rate=0.01357111567863781, classifier__max_depth=28, classifier__min_child_weight=3, classifier__n_estimators=252, classifier__subsample=0.9776304599933507;, score=(train=0.979, test=0.940) total time=   0.8s\n",
      "[CV 5/5; 29/30] START classifier__colsample_bytree=0.5916655028150088, classifier__gamma=0.9332841348337217, classifier__learning_rate=0.01357111567863781, classifier__max_depth=28, classifier__min_child_weight=3, classifier__n_estimators=252, classifier__subsample=0.9776304599933507\n",
      "[CV 5/5; 29/30] END classifier__colsample_bytree=0.5916655028150088, classifier__gamma=0.9332841348337217, classifier__learning_rate=0.01357111567863781, classifier__max_depth=28, classifier__min_child_weight=3, classifier__n_estimators=252, classifier__subsample=0.9776304599933507;, score=(train=0.974, test=0.933) total time=   0.8s\n",
      "[CV 1/5; 30/30] START classifier__colsample_bytree=0.7154676449321176, classifier__gamma=2.2123409238692817, classifier__learning_rate=0.039546025359173, classifier__max_depth=6, classifier__min_child_weight=8, classifier__n_estimators=393, classifier__subsample=0.7336131319633303\n",
      "[CV 1/5; 30/30] END classifier__colsample_bytree=0.7154676449321176, classifier__gamma=2.2123409238692817, classifier__learning_rate=0.039546025359173, classifier__max_depth=6, classifier__min_child_weight=8, classifier__n_estimators=393, classifier__subsample=0.7336131319633303;, score=(train=0.968, test=0.931) total time=   0.6s\n",
      "[CV 2/5; 30/30] START classifier__colsample_bytree=0.7154676449321176, classifier__gamma=2.2123409238692817, classifier__learning_rate=0.039546025359173, classifier__max_depth=6, classifier__min_child_weight=8, classifier__n_estimators=393, classifier__subsample=0.7336131319633303\n",
      "[CV 2/5; 30/30] END classifier__colsample_bytree=0.7154676449321176, classifier__gamma=2.2123409238692817, classifier__learning_rate=0.039546025359173, classifier__max_depth=6, classifier__min_child_weight=8, classifier__n_estimators=393, classifier__subsample=0.7336131319633303;, score=(train=0.964, test=0.944) total time=   0.6s\n",
      "[CV 3/5; 30/30] START classifier__colsample_bytree=0.7154676449321176, classifier__gamma=2.2123409238692817, classifier__learning_rate=0.039546025359173, classifier__max_depth=6, classifier__min_child_weight=8, classifier__n_estimators=393, classifier__subsample=0.7336131319633303\n",
      "[CV 3/5; 30/30] END classifier__colsample_bytree=0.7154676449321176, classifier__gamma=2.2123409238692817, classifier__learning_rate=0.039546025359173, classifier__max_depth=6, classifier__min_child_weight=8, classifier__n_estimators=393, classifier__subsample=0.7336131319633303;, score=(train=0.967, test=0.943) total time=   0.7s\n",
      "[CV 4/5; 30/30] START classifier__colsample_bytree=0.7154676449321176, classifier__gamma=2.2123409238692817, classifier__learning_rate=0.039546025359173, classifier__max_depth=6, classifier__min_child_weight=8, classifier__n_estimators=393, classifier__subsample=0.7336131319633303\n",
      "[CV 4/5; 30/30] END classifier__colsample_bytree=0.7154676449321176, classifier__gamma=2.2123409238692817, classifier__learning_rate=0.039546025359173, classifier__max_depth=6, classifier__min_child_weight=8, classifier__n_estimators=393, classifier__subsample=0.7336131319633303;, score=(train=0.968, test=0.938) total time=   0.6s\n",
      "[CV 5/5; 30/30] START classifier__colsample_bytree=0.7154676449321176, classifier__gamma=2.2123409238692817, classifier__learning_rate=0.039546025359173, classifier__max_depth=6, classifier__min_child_weight=8, classifier__n_estimators=393, classifier__subsample=0.7336131319633303\n",
      "[CV 5/5; 30/30] END classifier__colsample_bytree=0.7154676449321176, classifier__gamma=2.2123409238692817, classifier__learning_rate=0.039546025359173, classifier__max_depth=6, classifier__min_child_weight=8, classifier__n_estimators=393, classifier__subsample=0.7336131319633303;, score=(train=0.965, test=0.935) total time=   0.6s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'classifier__colsample_bytree': 0.962545809317217,\n",
       " 'classifier__gamma': 0.41596243966872626,\n",
       " 'classifier__learning_rate': 0.023168535868395727,\n",
       " 'classifier__max_depth': 48,\n",
       " 'classifier__min_child_weight': 2,\n",
       " 'classifier__n_estimators': 309,\n",
       " 'classifier__subsample': 0.9146727081882269}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = Pipeline([\n",
    "    ('preprocessing', final_pipeline),\n",
    "    ('classifier', XGBClassifier())\n",
    "])\n",
    "                 \n",
    "grid_3 = RandomizedSearchCV(pipe, param_distribution, cv=kfold, return_train_score=True, verbose=10, n_iter=30)\n",
    "\n",
    "grid_3.fit(X_train, y_train)\n",
    "grid_3.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "57532d60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision_score: 0.9438202247191011\n",
      "recall_score: 0.9256198347107438\n",
      "f1_score: 0.9346314325452015\n",
      "accuracy_score: 0.9489685124864278\n"
     ]
    }
   ],
   "source": [
    "print_metrics(grid_3.best_estimator_, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d16516",
   "metadata": {},
   "source": [
    "W obu przypadkach **brak PCA** daje znacznie lepsze wyniki."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b6663c",
   "metadata": {},
   "source": [
    "## PIerwsza sieć neuronowa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "57709d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.callbacks import EarlyStopping, History\n",
    "\n",
    "keras.backend.clear_session()\n",
    "\n",
    "def build_model(n_hidden=1, n_neurons=[30], learning_rate=3e-3, input_shape=(X_train.shape[1], )):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Flatten(input_shape=input_shape))\n",
    "    for layer in range(n_hidden):\n",
    "        model.add(keras.layers.Dense(n_neurons[layer % len(n_neurons)], activation='relu'))\n",
    "        model.add(keras.layers.BatchNormalization())\n",
    "        model.add(keras.layers.Dropout(0.3))\n",
    "    model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "17a6ff9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krzys\\AppData\\Local\\Temp\\ipykernel_17116\\1152597368.py:12: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  keras_class = tf.keras.wrappers.scikit_learn.KerasClassifier(build_model)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.wrappers.scikit_learn.KerasClassifier at 0x126f020f0d0>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import LearningRateScheduler\n",
    "\n",
    "def step_decay(epoch):\n",
    "    initial_lrate = 0.01\n",
    "    drop = 0.5\n",
    "    epochs_drop = 10.0\n",
    "    lrate = initial_lrate * np.power(drop, np.floor((1+epoch)/epochs_drop))\n",
    "    return lrate\n",
    "\n",
    "lrate = LearningRateScheduler(step_decay)\n",
    "\n",
    "keras_class = tf.keras.wrappers.scikit_learn.KerasClassifier(build_model)\n",
    "keras_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "0a9dbd49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Epoch 1/64\n",
      "83/83 [==============================] - 1s 3ms/step - loss: 0.2995 - accuracy: 0.9000 - val_loss: 0.2119 - val_accuracy: 0.9186 - lr: 0.0100\n",
      "Epoch 2/64\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.2353 - accuracy: 0.9136 - val_loss: 0.2025 - val_accuracy: 0.9220 - lr: 0.0100\n",
      "Epoch 3/64\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.2301 - accuracy: 0.9219 - val_loss: 0.1880 - val_accuracy: 0.9288 - lr: 0.0100\n",
      "Epoch 4/64\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.2030 - accuracy: 0.9305 - val_loss: 0.1840 - val_accuracy: 0.9390 - lr: 0.0100\n",
      "Epoch 5/64\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.2009 - accuracy: 0.9268 - val_loss: 0.1851 - val_accuracy: 0.9186 - lr: 0.0100\n",
      "Epoch 6/64\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.2191 - accuracy: 0.9219 - val_loss: 0.1692 - val_accuracy: 0.9424 - lr: 0.0100\n",
      "Epoch 7/64\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.1995 - accuracy: 0.9332 - val_loss: 0.1725 - val_accuracy: 0.9288 - lr: 0.0100\n",
      "Epoch 8/64\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.1997 - accuracy: 0.9305 - val_loss: 0.1849 - val_accuracy: 0.9288 - lr: 0.0100\n",
      "Epoch 9/64\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.1814 - accuracy: 0.9373 - val_loss: 0.1888 - val_accuracy: 0.9254 - lr: 0.0100\n",
      "Epoch 10/64\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.1711 - accuracy: 0.9343 - val_loss: 0.1756 - val_accuracy: 0.9254 - lr: 0.0050\n",
      "Epoch 11/64\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.1700 - accuracy: 0.9419 - val_loss: 0.1877 - val_accuracy: 0.9119 - lr: 0.0050\n",
      "Epoch 12/64\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.1666 - accuracy: 0.9392 - val_loss: 0.1716 - val_accuracy: 0.9390 - lr: 0.0050\n",
      "Epoch 13/64\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.1704 - accuracy: 0.9392 - val_loss: 0.1724 - val_accuracy: 0.9322 - lr: 0.0050\n",
      "Epoch 14/64\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.1517 - accuracy: 0.9449 - val_loss: 0.1654 - val_accuracy: 0.9356 - lr: 0.0050\n",
      "Epoch 15/64\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.1521 - accuracy: 0.9460 - val_loss: 0.1715 - val_accuracy: 0.9288 - lr: 0.0050\n",
      "Epoch 16/64\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.1559 - accuracy: 0.9422 - val_loss: 0.1609 - val_accuracy: 0.9390 - lr: 0.0050\n",
      "Epoch 17/64\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.1487 - accuracy: 0.9517 - val_loss: 0.1668 - val_accuracy: 0.9322 - lr: 0.0050\n",
      "Epoch 18/64\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.1452 - accuracy: 0.9505 - val_loss: 0.1606 - val_accuracy: 0.9458 - lr: 0.0050\n",
      "Epoch 19/64\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.1411 - accuracy: 0.9539 - val_loss: 0.1680 - val_accuracy: 0.9288 - lr: 0.0050\n",
      "Epoch 20/64\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.1441 - accuracy: 0.9456 - val_loss: 0.1594 - val_accuracy: 0.9424 - lr: 0.0025\n",
      "Epoch 21/64\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.1271 - accuracy: 0.9543 - val_loss: 0.1604 - val_accuracy: 0.9390 - lr: 0.0025\n",
      "Epoch 22/64\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.1363 - accuracy: 0.9505 - val_loss: 0.1618 - val_accuracy: 0.9356 - lr: 0.0025\n",
      "Epoch 23/64\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.1258 - accuracy: 0.9562 - val_loss: 0.1627 - val_accuracy: 0.9458 - lr: 0.0025\n",
      "Epoch 24/64\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.1300 - accuracy: 0.9566 - val_loss: 0.1631 - val_accuracy: 0.9424 - lr: 0.0025\n",
      "Epoch 25/64\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.1311 - accuracy: 0.9521 - val_loss: 0.1750 - val_accuracy: 0.9288 - lr: 0.0025\n",
      "Epoch 26/64\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.1379 - accuracy: 0.9479 - val_loss: 0.1675 - val_accuracy: 0.9424 - lr: 0.0025\n",
      "Epoch 27/64\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.1312 - accuracy: 0.9509 - val_loss: 0.1681 - val_accuracy: 0.9322 - lr: 0.0025\n",
      "Epoch 28/64\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.1249 - accuracy: 0.9573 - val_loss: 0.1620 - val_accuracy: 0.9390 - lr: 0.0025\n",
      "Epoch 29/64\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.1279 - accuracy: 0.9539 - val_loss: 0.1683 - val_accuracy: 0.9390 - lr: 0.0025\n",
      "Epoch 30/64\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.1265 - accuracy: 0.9581 - val_loss: 0.1571 - val_accuracy: 0.9492 - lr: 0.0012\n",
      "Epoch 31/64\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.1162 - accuracy: 0.9592 - val_loss: 0.1560 - val_accuracy: 0.9390 - lr: 0.0012\n",
      "Epoch 32/64\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.1182 - accuracy: 0.9607 - val_loss: 0.1581 - val_accuracy: 0.9424 - lr: 0.0012\n",
      "Epoch 33/64\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.1173 - accuracy: 0.9585 - val_loss: 0.1583 - val_accuracy: 0.9424 - lr: 0.0012\n",
      "Epoch 34/64\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.1183 - accuracy: 0.9619 - val_loss: 0.1630 - val_accuracy: 0.9390 - lr: 0.0012\n",
      "Epoch 35/64\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.1150 - accuracy: 0.9596 - val_loss: 0.1620 - val_accuracy: 0.9390 - lr: 0.0012\n",
      "Epoch 36/64\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.1248 - accuracy: 0.9547 - val_loss: 0.1618 - val_accuracy: 0.9424 - lr: 0.0012\n",
      "Epoch 37/64\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.1177 - accuracy: 0.9622 - val_loss: 0.1623 - val_accuracy: 0.9424 - lr: 0.0012\n",
      "Epoch 38/64\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.1090 - accuracy: 0.9611 - val_loss: 0.1603 - val_accuracy: 0.9458 - lr: 0.0012\n",
      "Epoch 39/64\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.1202 - accuracy: 0.9596 - val_loss: 0.1633 - val_accuracy: 0.9424 - lr: 0.0012\n",
      "Epoch 40/64\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.1131 - accuracy: 0.9619 - val_loss: 0.1613 - val_accuracy: 0.9390 - lr: 6.2500e-04\n",
      "Epoch 41/64\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.1176 - accuracy: 0.9543 - val_loss: 0.1633 - val_accuracy: 0.9424 - lr: 6.2500e-04\n",
      "Epoch 41: early stopping\n",
      "23/23 [==============================] - 0s 897us/step - loss: 0.2115 - accuracy: 0.9185\n",
      "[CV] END classifier__batch_size=32, classifier__callbacks=[<keras.callbacks.EarlyStopping object at 0x00000126ECE69250>, <keras.callbacks.LearningRateScheduler object at 0x00000126FADC8650>, <__main__.TrainingHistory object at 0x00000126FCDBA590>], classifier__epochs=64, classifier__n_hidden=1, classifier__n_neurons=[100], classifier__validation_split=0.1; total time=   6.2s\n",
      "Epoch 1/64\n",
      "83/83 [==============================] - 1s 3ms/step - loss: 0.2942 - accuracy: 0.8939 - val_loss: 0.2199 - val_accuracy: 0.9119 - lr: 0.0100\n",
      "Epoch 2/64\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.2189 - accuracy: 0.9219 - val_loss: 0.2120 - val_accuracy: 0.9220 - lr: 0.0100\n",
      "Epoch 3/64\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.2188 - accuracy: 0.9245 - val_loss: 0.1988 - val_accuracy: 0.9322 - lr: 0.0100\n",
      "Epoch 4/64\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.2005 - accuracy: 0.9241 - val_loss: 0.2003 - val_accuracy: 0.9322 - lr: 0.0100\n",
      "Epoch 5/64\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.1993 - accuracy: 0.9249 - val_loss: 0.2069 - val_accuracy: 0.9288 - lr: 0.0100\n",
      "Epoch 6/64\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.1835 - accuracy: 0.9351 - val_loss: 0.1885 - val_accuracy: 0.9254 - lr: 0.0100\n",
      "Epoch 7/64\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.1969 - accuracy: 0.9320 - val_loss: 0.2144 - val_accuracy: 0.9322 - lr: 0.0100\n",
      "Epoch 8/64\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.1701 - accuracy: 0.9347 - val_loss: 0.2096 - val_accuracy: 0.9288 - lr: 0.0100\n",
      "Epoch 9/64\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.1856 - accuracy: 0.9313 - val_loss: 0.1939 - val_accuracy: 0.9390 - lr: 0.0100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/64\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.1701 - accuracy: 0.9373 - val_loss: 0.2141 - val_accuracy: 0.9288 - lr: 0.0050\n",
      "Epoch 11/64\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.1643 - accuracy: 0.9343 - val_loss: 0.1950 - val_accuracy: 0.9390 - lr: 0.0050\n",
      "Epoch 12/64\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.1486 - accuracy: 0.9456 - val_loss: 0.2053 - val_accuracy: 0.9356 - lr: 0.0050\n",
      "Epoch 13/64\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.1460 - accuracy: 0.9419 - val_loss: 0.2063 - val_accuracy: 0.9288 - lr: 0.0050\n",
      "Epoch 14/64\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.1444 - accuracy: 0.9521 - val_loss: 0.2028 - val_accuracy: 0.9390 - lr: 0.0050\n",
      "Epoch 15/64\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.1533 - accuracy: 0.9441 - val_loss: 0.1930 - val_accuracy: 0.9390 - lr: 0.0050\n",
      "Epoch 16/64\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.1423 - accuracy: 0.9509 - val_loss: 0.1960 - val_accuracy: 0.9322 - lr: 0.0050\n",
      "Epoch 16: early stopping\n",
      "23/23 [==============================] - 0s 954us/step - loss: 0.2324 - accuracy: 0.9198\n",
      "[CV] END classifier__batch_size=32, classifier__callbacks=[<keras.callbacks.EarlyStopping object at 0x00000126ECE69250>, <keras.callbacks.LearningRateScheduler object at 0x00000126FADC8650>, <__main__.TrainingHistory object at 0x00000126FCDBA590>], classifier__epochs=64, classifier__n_hidden=1, classifier__n_neurons=[100], classifier__validation_split=0.1; total time=   3.0s\n",
      "Epoch 1/64\n",
      "83/83 [==============================] - 1s 3ms/step - loss: 0.3142 - accuracy: 0.8784 - val_loss: 0.2248 - val_accuracy: 0.9186 - lr: 0.0100\n",
      "Epoch 2/64\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.2353 - accuracy: 0.9166 - val_loss: 0.2095 - val_accuracy: 0.9153 - lr: 0.0100\n",
      "Epoch 3/64\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.2351 - accuracy: 0.9132 - val_loss: 0.2049 - val_accuracy: 0.9186 - lr: 0.0100\n",
      "Epoch 4/64\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.2073 - accuracy: 0.9192 - val_loss: 0.1862 - val_accuracy: 0.9322 - lr: 0.0100\n",
      "Epoch 5/64\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.2187 - accuracy: 0.9237 - val_loss: 0.2284 - val_accuracy: 0.9051 - lr: 0.0100\n",
      "Epoch 6/64\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.2052 - accuracy: 0.9264 - val_loss: 0.1744 - val_accuracy: 0.9254 - lr: 0.0100\n",
      "Epoch 7/64\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.2104 - accuracy: 0.9215 - val_loss: 0.1738 - val_accuracy: 0.9322 - lr: 0.0100\n",
      "Epoch 8/64\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.1979 - accuracy: 0.9260 - val_loss: 0.1836 - val_accuracy: 0.9220 - lr: 0.0100\n",
      "Epoch 9/64\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.1955 - accuracy: 0.9264 - val_loss: 0.2116 - val_accuracy: 0.9085 - lr: 0.0100\n",
      "Epoch 10/64\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.1875 - accuracy: 0.9317 - val_loss: 0.1957 - val_accuracy: 0.9119 - lr: 0.0050\n",
      "Epoch 11/64\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.1769 - accuracy: 0.9358 - val_loss: 0.2102 - val_accuracy: 0.9153 - lr: 0.0050\n",
      "Epoch 12/64\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.1723 - accuracy: 0.9358 - val_loss: 0.1805 - val_accuracy: 0.9254 - lr: 0.0050\n",
      "Epoch 13/64\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.1751 - accuracy: 0.9377 - val_loss: 0.1867 - val_accuracy: 0.9186 - lr: 0.0050\n",
      "Epoch 14/64\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.1753 - accuracy: 0.9332 - val_loss: 0.1850 - val_accuracy: 0.9119 - lr: 0.0050\n",
      "Epoch 15/64\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.1702 - accuracy: 0.9381 - val_loss: 0.1895 - val_accuracy: 0.9254 - lr: 0.0050\n",
      "Epoch 16/64\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.1647 - accuracy: 0.9358 - val_loss: 0.1834 - val_accuracy: 0.9254 - lr: 0.0050\n",
      "Epoch 17/64\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.1680 - accuracy: 0.9422 - val_loss: 0.1759 - val_accuracy: 0.9220 - lr: 0.0050\n",
      "Epoch 17: early stopping\n",
      "23/23 [==============================] - 0s 938us/step - loss: 0.1823 - accuracy: 0.9429\n",
      "[CV] END classifier__batch_size=32, classifier__callbacks=[<keras.callbacks.EarlyStopping object at 0x00000126ECE69250>, <keras.callbacks.LearningRateScheduler object at 0x00000126FADC8650>, <__main__.TrainingHistory object at 0x00000126FCDBA590>], classifier__epochs=64, classifier__n_hidden=1, classifier__n_neurons=[100], classifier__validation_split=0.1; total time=   3.2s\n",
      "Epoch 1/64\n",
      "83/83 [==============================] - 1s 3ms/step - loss: 0.3057 - accuracy: 0.8898 - val_loss: 0.2053 - val_accuracy: 0.9220 - lr: 0.0100\n",
      "Epoch 2/64\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.2447 - accuracy: 0.9120 - val_loss: 0.2063 - val_accuracy: 0.9119 - lr: 0.0100\n",
      "Epoch 3/64\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.2211 - accuracy: 0.9215 - val_loss: 0.1854 - val_accuracy: 0.9220 - lr: 0.0100\n",
      "Epoch 4/64\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.2119 - accuracy: 0.9181 - val_loss: 0.2072 - val_accuracy: 0.9220 - lr: 0.0100\n",
      "Epoch 5/64\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.2112 - accuracy: 0.9234 - val_loss: 0.2302 - val_accuracy: 0.9186 - lr: 0.0100\n",
      "Epoch 6/64\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.1926 - accuracy: 0.9309 - val_loss: 0.1751 - val_accuracy: 0.9322 - lr: 0.0100\n",
      "Epoch 7/64\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.2038 - accuracy: 0.9237 - val_loss: 0.1917 - val_accuracy: 0.9254 - lr: 0.0100\n",
      "Epoch 8/64\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.1832 - accuracy: 0.9328 - val_loss: 0.1943 - val_accuracy: 0.9186 - lr: 0.0100\n",
      "Epoch 9/64\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.1921 - accuracy: 0.9241 - val_loss: 0.1932 - val_accuracy: 0.9288 - lr: 0.0100\n",
      "Epoch 10/64\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.1741 - accuracy: 0.9336 - val_loss: 0.1848 - val_accuracy: 0.9254 - lr: 0.0050\n",
      "Epoch 11/64\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.1650 - accuracy: 0.9366 - val_loss: 0.1818 - val_accuracy: 0.9356 - lr: 0.0050\n",
      "Epoch 12/64\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.1694 - accuracy: 0.9377 - val_loss: 0.1769 - val_accuracy: 0.9424 - lr: 0.0050\n",
      "Epoch 13/64\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.1642 - accuracy: 0.9373 - val_loss: 0.1778 - val_accuracy: 0.9356 - lr: 0.0050\n",
      "Epoch 14/64\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.1671 - accuracy: 0.9392 - val_loss: 0.1775 - val_accuracy: 0.9390 - lr: 0.0050\n",
      "Epoch 15/64\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.1552 - accuracy: 0.9434 - val_loss: 0.1840 - val_accuracy: 0.9356 - lr: 0.0050\n",
      "Epoch 16/64\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.1555 - accuracy: 0.9415 - val_loss: 0.1949 - val_accuracy: 0.9288 - lr: 0.0050\n",
      "Epoch 16: early stopping\n",
      "23/23 [==============================] - 0s 870us/step - loss: 0.2330 - accuracy: 0.9375\n",
      "[CV] END classifier__batch_size=32, classifier__callbacks=[<keras.callbacks.EarlyStopping object at 0x00000126ECE69250>, <keras.callbacks.LearningRateScheduler object at 0x00000126FADC8650>, <__main__.TrainingHistory object at 0x00000126FCDBA590>], classifier__epochs=64, classifier__n_hidden=1, classifier__n_neurons=[100], classifier__validation_split=0.1; total time=   3.2s\n",
      "Epoch 1/64\n",
      "83/83 [==============================] - 1s 3ms/step - loss: 0.3156 - accuracy: 0.8834 - val_loss: 0.2277 - val_accuracy: 0.9051 - lr: 0.0100\n",
      "Epoch 2/64\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.2550 - accuracy: 0.9049 - val_loss: 0.2296 - val_accuracy: 0.9254 - lr: 0.0100\n",
      "Epoch 3/64\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.2298 - accuracy: 0.9124 - val_loss: 0.2496 - val_accuracy: 0.9119 - lr: 0.0100\n",
      "Epoch 4/64\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.2193 - accuracy: 0.9166 - val_loss: 0.1976 - val_accuracy: 0.9153 - lr: 0.0100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/64\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.2094 - accuracy: 0.9234 - val_loss: 0.1946 - val_accuracy: 0.9186 - lr: 0.0100\n",
      "Epoch 6/64\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.2058 - accuracy: 0.9253 - val_loss: 0.1918 - val_accuracy: 0.9186 - lr: 0.0100\n",
      "Epoch 7/64\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.2058 - accuracy: 0.9226 - val_loss: 0.1884 - val_accuracy: 0.9220 - lr: 0.0100\n",
      "Epoch 8/64\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.2028 - accuracy: 0.9230 - val_loss: 0.1954 - val_accuracy: 0.9119 - lr: 0.0100\n",
      "Epoch 9/64\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.1964 - accuracy: 0.9200 - val_loss: 0.1997 - val_accuracy: 0.9288 - lr: 0.0100\n",
      "Epoch 10/64\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.1908 - accuracy: 0.9290 - val_loss: 0.1925 - val_accuracy: 0.9220 - lr: 0.0050\n",
      "Epoch 11/64\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.1768 - accuracy: 0.9347 - val_loss: 0.1963 - val_accuracy: 0.9153 - lr: 0.0050\n",
      "Epoch 12/64\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.1625 - accuracy: 0.9381 - val_loss: 0.1895 - val_accuracy: 0.9254 - lr: 0.0050\n",
      "Epoch 13/64\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.1731 - accuracy: 0.9351 - val_loss: 0.1819 - val_accuracy: 0.9390 - lr: 0.0050\n",
      "Epoch 14/64\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.1575 - accuracy: 0.9426 - val_loss: 0.1841 - val_accuracy: 0.9220 - lr: 0.0050\n",
      "Epoch 15/64\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.1488 - accuracy: 0.9456 - val_loss: 0.1937 - val_accuracy: 0.9220 - lr: 0.0050\n",
      "Epoch 16/64\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.1580 - accuracy: 0.9407 - val_loss: 0.2048 - val_accuracy: 0.9119 - lr: 0.0050\n",
      "Epoch 17/64\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.1615 - accuracy: 0.9441 - val_loss: 0.1884 - val_accuracy: 0.9186 - lr: 0.0050\n",
      "Epoch 18/64\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.1654 - accuracy: 0.9370 - val_loss: 0.1965 - val_accuracy: 0.9153 - lr: 0.0050\n",
      "Epoch 19/64\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.1620 - accuracy: 0.9381 - val_loss: 0.1899 - val_accuracy: 0.9322 - lr: 0.0050\n",
      "Epoch 20/64\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.1488 - accuracy: 0.9445 - val_loss: 0.1886 - val_accuracy: 0.9288 - lr: 0.0025\n",
      "Epoch 21/64\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.1551 - accuracy: 0.9426 - val_loss: 0.1850 - val_accuracy: 0.9288 - lr: 0.0025\n",
      "Epoch 22/64\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.1445 - accuracy: 0.9517 - val_loss: 0.1880 - val_accuracy: 0.9322 - lr: 0.0025\n",
      "Epoch 23/64\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.1395 - accuracy: 0.9494 - val_loss: 0.1854 - val_accuracy: 0.9322 - lr: 0.0025\n",
      "Epoch 23: early stopping\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 0.2953 - accuracy: 0.8750WARNING:tensorflow:Callback method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0003s vs `on_test_batch_end` time: 0.0003s). Check your callbacks.\n",
      "23/23 [==============================] - 0s 925us/step - loss: 0.1793 - accuracy: 0.9416\n",
      "[CV] END classifier__batch_size=32, classifier__callbacks=[<keras.callbacks.EarlyStopping object at 0x00000126ECE69250>, <keras.callbacks.LearningRateScheduler object at 0x00000126FADC8650>, <__main__.TrainingHistory object at 0x00000126FCDBA590>], classifier__epochs=64, classifier__n_hidden=1, classifier__n_neurons=[100], classifier__validation_split=0.1; total time=   3.9s\n",
      "Epoch 1/64\n",
      "104/104 [==============================] - 1s 3ms/step - loss: 0.2743 - accuracy: 0.9004 - val_loss: 0.2231 - val_accuracy: 0.9049 - lr: 0.0100\n",
      "Epoch 2/64\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.2334 - accuracy: 0.9097 - val_loss: 0.2037 - val_accuracy: 0.9103 - lr: 0.0100\n",
      "Epoch 3/64\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.2203 - accuracy: 0.9155 - val_loss: 0.1875 - val_accuracy: 0.9293 - lr: 0.0100\n",
      "Epoch 4/64\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.2211 - accuracy: 0.9170 - val_loss: 0.1961 - val_accuracy: 0.9185 - lr: 0.0100\n",
      "Epoch 5/64\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.2065 - accuracy: 0.9257 - val_loss: 0.1808 - val_accuracy: 0.9266 - lr: 0.0100\n",
      "Epoch 6/64\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.1984 - accuracy: 0.9287 - val_loss: 0.1814 - val_accuracy: 0.9212 - lr: 0.0100\n",
      "Epoch 7/64\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.1962 - accuracy: 0.9309 - val_loss: 0.1948 - val_accuracy: 0.9239 - lr: 0.0100\n",
      "Epoch 8/64\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.1958 - accuracy: 0.9284 - val_loss: 0.2035 - val_accuracy: 0.9185 - lr: 0.0100\n",
      "Epoch 9/64\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.1959 - accuracy: 0.9278 - val_loss: 0.1915 - val_accuracy: 0.9185 - lr: 0.0100\n",
      "Epoch 10/64\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.1787 - accuracy: 0.9333 - val_loss: 0.1926 - val_accuracy: 0.9212 - lr: 0.0050\n",
      "Epoch 11/64\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.1793 - accuracy: 0.9372 - val_loss: 0.1899 - val_accuracy: 0.9266 - lr: 0.0050\n",
      "Epoch 12/64\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.1670 - accuracy: 0.9408 - val_loss: 0.1835 - val_accuracy: 0.9212 - lr: 0.0050\n",
      "Epoch 13/64\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.1602 - accuracy: 0.9396 - val_loss: 0.1804 - val_accuracy: 0.9239 - lr: 0.0050\n",
      "Epoch 14/64\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.1682 - accuracy: 0.9345 - val_loss: 0.1854 - val_accuracy: 0.9158 - lr: 0.0050\n",
      "Epoch 15/64\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.1625 - accuracy: 0.9423 - val_loss: 0.1885 - val_accuracy: 0.9293 - lr: 0.0050\n",
      "Epoch 16/64\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.1626 - accuracy: 0.9414 - val_loss: 0.1946 - val_accuracy: 0.9185 - lr: 0.0050\n",
      "Epoch 17/64\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.1676 - accuracy: 0.9396 - val_loss: 0.1856 - val_accuracy: 0.9293 - lr: 0.0050\n",
      "Epoch 18/64\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.1570 - accuracy: 0.9429 - val_loss: 0.1806 - val_accuracy: 0.9266 - lr: 0.0050\n",
      "Epoch 19/64\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.1574 - accuracy: 0.9426 - val_loss: 0.1784 - val_accuracy: 0.9212 - lr: 0.0050\n",
      "Epoch 20/64\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.1468 - accuracy: 0.9484 - val_loss: 0.1737 - val_accuracy: 0.9293 - lr: 0.0025\n",
      "Epoch 21/64\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.1441 - accuracy: 0.9484 - val_loss: 0.1693 - val_accuracy: 0.9375 - lr: 0.0025\n",
      "Epoch 22/64\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.1371 - accuracy: 0.9526 - val_loss: 0.1777 - val_accuracy: 0.9348 - lr: 0.0025\n",
      "Epoch 23/64\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.1444 - accuracy: 0.9490 - val_loss: 0.2008 - val_accuracy: 0.9103 - lr: 0.0025\n",
      "Epoch 24/64\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.1491 - accuracy: 0.9447 - val_loss: 0.1659 - val_accuracy: 0.9348 - lr: 0.0025\n",
      "Epoch 25/64\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.1359 - accuracy: 0.9556 - val_loss: 0.1802 - val_accuracy: 0.9321 - lr: 0.0025\n",
      "Epoch 26/64\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.1442 - accuracy: 0.9505 - val_loss: 0.1728 - val_accuracy: 0.9348 - lr: 0.0025\n",
      "Epoch 27/64\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.1513 - accuracy: 0.9487 - val_loss: 0.1814 - val_accuracy: 0.9321 - lr: 0.0025\n",
      "Epoch 28/64\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.1394 - accuracy: 0.9526 - val_loss: 0.1706 - val_accuracy: 0.9348 - lr: 0.0025\n",
      "Epoch 29/64\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.1328 - accuracy: 0.9511 - val_loss: 0.1732 - val_accuracy: 0.9348 - lr: 0.0025\n",
      "Epoch 30/64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104/104 [==============================] - 0s 1ms/step - loss: 0.1265 - accuracy: 0.9526 - val_loss: 0.1708 - val_accuracy: 0.9375 - lr: 0.0012\n",
      "Epoch 31/64\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.1476 - accuracy: 0.9490 - val_loss: 0.1738 - val_accuracy: 0.9348 - lr: 0.0012\n",
      "Epoch 32/64\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.1277 - accuracy: 0.9562 - val_loss: 0.1765 - val_accuracy: 0.9348 - lr: 0.0012\n",
      "Epoch 33/64\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.1233 - accuracy: 0.9565 - val_loss: 0.1759 - val_accuracy: 0.9348 - lr: 0.0012\n",
      "Epoch 34/64\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.1316 - accuracy: 0.9535 - val_loss: 0.1774 - val_accuracy: 0.9348 - lr: 0.0012\n",
      "Epoch 34: early stopping\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-8 {color: black;background-color: white;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=1337, shuffle=True),\n",
       "             estimator=Pipeline(steps=[(&#x27;preprocessing&#x27;,\n",
       "                                        Pipeline(steps=[(&#x27;fill&#x27;,\n",
       "                                                         FeatureUnion(transformer_list=[(&#x27;median&#x27;,\n",
       "                                                                                         Pipeline(steps=[(&#x27;selector&#x27;,\n",
       "                                                                                                          DataFrameSelector(attribute_names=[&#x27;word_freq_make&#x27;,\n",
       "                                                                                                                                             &#x27;word_freq_address&#x27;,\n",
       "                                                                                                                                             &#x27;word_freq_all&#x27;,\n",
       "                                                                                                                                             &#x27;word_freq_3d&#x27;,\n",
       "                                                                                                                                             &#x27;word_freq_our&#x27;,\n",
       "                                                                                                                                             &#x27;word_freq_over&#x27;,\n",
       "                                                                                                                                             &#x27;wo...\n",
       "             param_grid={&#x27;classifier__batch_size&#x27;: [32],\n",
       "                         &#x27;classifier__callbacks&#x27;: [[&lt;keras.callbacks.EarlyStopping object at 0x00000126ECE69250&gt;,\n",
       "                                                    &lt;keras.callbacks.LearningRateScheduler object at 0x00000126FADC8650&gt;,\n",
       "                                                    &lt;__main__.TrainingHistory object at 0x00000126FCDBA590&gt;]],\n",
       "                         &#x27;classifier__epochs&#x27;: [64],\n",
       "                         &#x27;classifier__n_hidden&#x27;: [1],\n",
       "                         &#x27;classifier__n_neurons&#x27;: [[100]],\n",
       "                         &#x27;classifier__validation_split&#x27;: [0.1]},\n",
       "             verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-71\" type=\"checkbox\" ><label for=\"sk-estimator-id-71\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=1337, shuffle=True),\n",
       "             estimator=Pipeline(steps=[(&#x27;preprocessing&#x27;,\n",
       "                                        Pipeline(steps=[(&#x27;fill&#x27;,\n",
       "                                                         FeatureUnion(transformer_list=[(&#x27;median&#x27;,\n",
       "                                                                                         Pipeline(steps=[(&#x27;selector&#x27;,\n",
       "                                                                                                          DataFrameSelector(attribute_names=[&#x27;word_freq_make&#x27;,\n",
       "                                                                                                                                             &#x27;word_freq_address&#x27;,\n",
       "                                                                                                                                             &#x27;word_freq_all&#x27;,\n",
       "                                                                                                                                             &#x27;word_freq_3d&#x27;,\n",
       "                                                                                                                                             &#x27;word_freq_our&#x27;,\n",
       "                                                                                                                                             &#x27;word_freq_over&#x27;,\n",
       "                                                                                                                                             &#x27;wo...\n",
       "             param_grid={&#x27;classifier__batch_size&#x27;: [32],\n",
       "                         &#x27;classifier__callbacks&#x27;: [[&lt;keras.callbacks.EarlyStopping object at 0x00000126ECE69250&gt;,\n",
       "                                                    &lt;keras.callbacks.LearningRateScheduler object at 0x00000126FADC8650&gt;,\n",
       "                                                    &lt;__main__.TrainingHistory object at 0x00000126FCDBA590&gt;]],\n",
       "                         &#x27;classifier__epochs&#x27;: [64],\n",
       "                         &#x27;classifier__n_hidden&#x27;: [1],\n",
       "                         &#x27;classifier__n_neurons&#x27;: [[100]],\n",
       "                         &#x27;classifier__validation_split&#x27;: [0.1]},\n",
       "             verbose=2)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-72\" type=\"checkbox\" ><label for=\"sk-estimator-id-72\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;preprocessing&#x27;,\n",
       "                 Pipeline(steps=[(&#x27;fill&#x27;,\n",
       "                                  FeatureUnion(transformer_list=[(&#x27;median&#x27;,\n",
       "                                                                  Pipeline(steps=[(&#x27;selector&#x27;,\n",
       "                                                                                   DataFrameSelector(attribute_names=[&#x27;word_freq_make&#x27;,\n",
       "                                                                                                                      &#x27;word_freq_address&#x27;,\n",
       "                                                                                                                      &#x27;word_freq_all&#x27;,\n",
       "                                                                                                                      &#x27;word_freq_3d&#x27;,\n",
       "                                                                                                                      &#x27;word_freq_our&#x27;,\n",
       "                                                                                                                      &#x27;word_freq_over&#x27;,\n",
       "                                                                                                                      &#x27;word_freq_remove&#x27;,\n",
       "                                                                                                                      &#x27;word_freq_internet&#x27;,\n",
       "                                                                                                                      &#x27;word_freq_order&#x27;,\n",
       "                                                                                                                      &#x27;word_freq_mail&#x27;,\n",
       "                                                                                                                      &#x27;word_freq_re...\n",
       "                                                                                   SimpleImputer(strategy=&#x27;median&#x27;))])),\n",
       "                                                                 (&#x27;average&#x27;,\n",
       "                                                                  Pipeline(steps=[(&#x27;selector&#x27;,\n",
       "                                                                                   DataFrameSelector(attribute_names=[&#x27;char_freq_%3B&#x27;,\n",
       "                                                                                                                      &#x27;char_freq_%28&#x27;,\n",
       "                                                                                                                      &#x27;char_freq_%5B&#x27;,\n",
       "                                                                                                                      &#x27;char_freq_%21&#x27;,\n",
       "                                                                                                                      &#x27;char_freq_%24&#x27;,\n",
       "                                                                                                                      &#x27;char_freq_%23&#x27;])),\n",
       "                                                                                  (&#x27;imputer&#x27;,\n",
       "                                                                                   SimpleImputer())]))])),\n",
       "                                 (&#x27;scale&#x27;, StandardScaler())])),\n",
       "                (&#x27;classifier&#x27;,\n",
       "                 &lt;keras.wrappers.scikit_learn.KerasClassifier object at 0x00000126F020F0D0&gt;)])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-73\" type=\"checkbox\" ><label for=\"sk-estimator-id-73\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">preprocessing: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;fill&#x27;,\n",
       "                 FeatureUnion(transformer_list=[(&#x27;median&#x27;,\n",
       "                                                 Pipeline(steps=[(&#x27;selector&#x27;,\n",
       "                                                                  DataFrameSelector(attribute_names=[&#x27;word_freq_make&#x27;,\n",
       "                                                                                                     &#x27;word_freq_address&#x27;,\n",
       "                                                                                                     &#x27;word_freq_all&#x27;,\n",
       "                                                                                                     &#x27;word_freq_3d&#x27;,\n",
       "                                                                                                     &#x27;word_freq_our&#x27;,\n",
       "                                                                                                     &#x27;word_freq_over&#x27;,\n",
       "                                                                                                     &#x27;word_freq_remove&#x27;,\n",
       "                                                                                                     &#x27;word_freq_internet&#x27;,\n",
       "                                                                                                     &#x27;word_freq_order&#x27;,\n",
       "                                                                                                     &#x27;word_freq_mail&#x27;,\n",
       "                                                                                                     &#x27;word_freq_receive&#x27;,\n",
       "                                                                                                     &#x27;word_freq_will&#x27;,\n",
       "                                                                                                     &#x27;word_fre...\n",
       "                                                                                                     &#x27;word_freq_lab&#x27;,\n",
       "                                                                                                     &#x27;word_freq_labs&#x27;,\n",
       "                                                                                                     &#x27;word_freq_telnet&#x27;,\n",
       "                                                                                                     &#x27;word_freq_857&#x27;, ...])),\n",
       "                                                                 (&#x27;imputer&#x27;,\n",
       "                                                                  SimpleImputer(strategy=&#x27;median&#x27;))])),\n",
       "                                                (&#x27;average&#x27;,\n",
       "                                                 Pipeline(steps=[(&#x27;selector&#x27;,\n",
       "                                                                  DataFrameSelector(attribute_names=[&#x27;char_freq_%3B&#x27;,\n",
       "                                                                                                     &#x27;char_freq_%28&#x27;,\n",
       "                                                                                                     &#x27;char_freq_%5B&#x27;,\n",
       "                                                                                                     &#x27;char_freq_%21&#x27;,\n",
       "                                                                                                     &#x27;char_freq_%24&#x27;,\n",
       "                                                                                                     &#x27;char_freq_%23&#x27;])),\n",
       "                                                                 (&#x27;imputer&#x27;,\n",
       "                                                                  SimpleImputer())]))])),\n",
       "                (&#x27;scale&#x27;, StandardScaler())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-74\" type=\"checkbox\" ><label for=\"sk-estimator-id-74\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">fill: FeatureUnion</label><div class=\"sk-toggleable__content\"><pre>FeatureUnion(transformer_list=[(&#x27;median&#x27;,\n",
       "                                Pipeline(steps=[(&#x27;selector&#x27;,\n",
       "                                                 DataFrameSelector(attribute_names=[&#x27;word_freq_make&#x27;,\n",
       "                                                                                    &#x27;word_freq_address&#x27;,\n",
       "                                                                                    &#x27;word_freq_all&#x27;,\n",
       "                                                                                    &#x27;word_freq_3d&#x27;,\n",
       "                                                                                    &#x27;word_freq_our&#x27;,\n",
       "                                                                                    &#x27;word_freq_over&#x27;,\n",
       "                                                                                    &#x27;word_freq_remove&#x27;,\n",
       "                                                                                    &#x27;word_freq_internet&#x27;,\n",
       "                                                                                    &#x27;word_freq_order&#x27;,\n",
       "                                                                                    &#x27;word_freq_mail&#x27;,\n",
       "                                                                                    &#x27;word_freq_receive&#x27;,\n",
       "                                                                                    &#x27;word_freq_will&#x27;,\n",
       "                                                                                    &#x27;word_freq_people&#x27;,\n",
       "                                                                                    &#x27;word_freq_rep...\n",
       "                                                                                    &#x27;word_freq_hp&#x27;,\n",
       "                                                                                    &#x27;word_freq_hpl&#x27;,\n",
       "                                                                                    &#x27;word_freq_lab&#x27;,\n",
       "                                                                                    &#x27;word_freq_labs&#x27;,\n",
       "                                                                                    &#x27;word_freq_telnet&#x27;,\n",
       "                                                                                    &#x27;word_freq_857&#x27;, ...])),\n",
       "                                                (&#x27;imputer&#x27;,\n",
       "                                                 SimpleImputer(strategy=&#x27;median&#x27;))])),\n",
       "                               (&#x27;average&#x27;,\n",
       "                                Pipeline(steps=[(&#x27;selector&#x27;,\n",
       "                                                 DataFrameSelector(attribute_names=[&#x27;char_freq_%3B&#x27;,\n",
       "                                                                                    &#x27;char_freq_%28&#x27;,\n",
       "                                                                                    &#x27;char_freq_%5B&#x27;,\n",
       "                                                                                    &#x27;char_freq_%21&#x27;,\n",
       "                                                                                    &#x27;char_freq_%24&#x27;,\n",
       "                                                                                    &#x27;char_freq_%23&#x27;])),\n",
       "                                                (&#x27;imputer&#x27;,\n",
       "                                                 SimpleImputer())]))])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>median</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-75\" type=\"checkbox\" ><label for=\"sk-estimator-id-75\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DataFrameSelector</label><div class=\"sk-toggleable__content\"><pre>DataFrameSelector(attribute_names=[&#x27;word_freq_make&#x27;, &#x27;word_freq_address&#x27;,\n",
       "                                   &#x27;word_freq_all&#x27;, &#x27;word_freq_3d&#x27;,\n",
       "                                   &#x27;word_freq_our&#x27;, &#x27;word_freq_over&#x27;,\n",
       "                                   &#x27;word_freq_remove&#x27;, &#x27;word_freq_internet&#x27;,\n",
       "                                   &#x27;word_freq_order&#x27;, &#x27;word_freq_mail&#x27;,\n",
       "                                   &#x27;word_freq_receive&#x27;, &#x27;word_freq_will&#x27;,\n",
       "                                   &#x27;word_freq_people&#x27;, &#x27;word_freq_report&#x27;,\n",
       "                                   &#x27;word_freq_addresses&#x27;, &#x27;word_freq_free&#x27;,\n",
       "                                   &#x27;word_freq_business&#x27;, &#x27;word_freq_email&#x27;,\n",
       "                                   &#x27;word_freq_you&#x27;, &#x27;word_freq_credit&#x27;,\n",
       "                                   &#x27;word_freq_your&#x27;, &#x27;word_freq_font&#x27;,\n",
       "                                   &#x27;word_freq_000&#x27;, &#x27;word_freq_money&#x27;,\n",
       "                                   &#x27;word_freq_hp&#x27;, &#x27;word_freq_hpl&#x27;,\n",
       "                                   &#x27;word_freq_lab&#x27;, &#x27;word_freq_labs&#x27;,\n",
       "                                   &#x27;word_freq_telnet&#x27;, &#x27;word_freq_857&#x27;, ...])</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-76\" type=\"checkbox\" ><label for=\"sk-estimator-id-76\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(strategy=&#x27;median&#x27;)</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>average</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-77\" type=\"checkbox\" ><label for=\"sk-estimator-id-77\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DataFrameSelector</label><div class=\"sk-toggleable__content\"><pre>DataFrameSelector(attribute_names=[&#x27;char_freq_%3B&#x27;, &#x27;char_freq_%28&#x27;,\n",
       "                                   &#x27;char_freq_%5B&#x27;, &#x27;char_freq_%21&#x27;,\n",
       "                                   &#x27;char_freq_%24&#x27;, &#x27;char_freq_%23&#x27;])</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-78\" type=\"checkbox\" ><label for=\"sk-estimator-id-78\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer()</pre></div></div></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-79\" type=\"checkbox\" ><label for=\"sk-estimator-id-79\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-80\" type=\"checkbox\" ><label for=\"sk-estimator-id-80\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KerasClassifier</label><div class=\"sk-toggleable__content\"><pre>&lt;keras.wrappers.scikit_learn.KerasClassifier object at 0x00000126F020F0D0&gt;</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=1337, shuffle=True),\n",
       "             estimator=Pipeline(steps=[('preprocessing',\n",
       "                                        Pipeline(steps=[('fill',\n",
       "                                                         FeatureUnion(transformer_list=[('median',\n",
       "                                                                                         Pipeline(steps=[('selector',\n",
       "                                                                                                          DataFrameSelector(attribute_names=['word_freq_make',\n",
       "                                                                                                                                             'word_freq_address',\n",
       "                                                                                                                                             'word_freq_all',\n",
       "                                                                                                                                             'word_freq_3d',\n",
       "                                                                                                                                             'word_freq_our',\n",
       "                                                                                                                                             'word_freq_over',\n",
       "                                                                                                                                             'wo...\n",
       "             param_grid={'classifier__batch_size': [32],\n",
       "                         'classifier__callbacks': [[<keras.callbacks.EarlyStopping object at 0x00000126ECE69250>,\n",
       "                                                    <keras.callbacks.LearningRateScheduler object at 0x00000126FADC8650>,\n",
       "                                                    <__main__.TrainingHistory object at 0x00000126FCDBA590>]],\n",
       "                         'classifier__epochs': [64],\n",
       "                         'classifier__n_hidden': [1],\n",
       "                         'classifier__n_neurons': [[100]],\n",
       "                         'classifier__validation_split': [0.1]},\n",
       "             verbose=2)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, StratifiedKFold\n",
    "\n",
    "training_histories = []\n",
    "\n",
    "# Define a custom callback to collect the training history\n",
    "class TrainingHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs=None):\n",
    "        self.epoch_history = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        self.epoch_history.append(logs)\n",
    "\n",
    "    def on_train_end(self, logs=None):\n",
    "        training_histories.append(self.epoch_history)\n",
    "\n",
    "param_grid = {\n",
    "    'classifier__n_hidden': [1],#[1, 2, 3, 4],\n",
    "    'classifier__n_neurons': [[100]], #[[300], [100], [50], [20], [100, 50, 20], [300, 150, 50, 10], [50, 10]],\n",
    "    'classifier__epochs': [64],\n",
    "    'classifier__batch_size': [32],\n",
    "    'classifier__validation_split': [0.1],\n",
    "    'classifier__callbacks': [[\n",
    "        EarlyStopping(monitor='val_loss', patience=10, mode='min', verbose=1), \n",
    "        LearningRateScheduler(step_decay),\n",
    "        TrainingHistory(),\n",
    "    ]],\n",
    "}\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=5, random_state=seed, shuffle=True)\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('preprocessing', final_pipeline),\n",
    "    ('classifier', keras_class)\n",
    "])\n",
    "\n",
    "grid_4 = GridSearchCV(pipe, param_grid, cv=kfold, verbose=2)\n",
    "grid_4.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "699f358d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier__batch_size': 32,\n",
       " 'classifier__callbacks': [<keras.callbacks.EarlyStopping at 0x126ece69250>,\n",
       "  <keras.callbacks.LearningRateScheduler at 0x126fadc8650>,\n",
       "  <__main__.TrainingHistory at 0x126fcdba590>],\n",
       " 'classifier__epochs': 64,\n",
       " 'classifier__n_hidden': 1,\n",
       " 'classifier__n_neurons': [100],\n",
       " 'classifier__validation_split': 0.1}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_4.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a4d1f375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 0s 700us/step\n",
      "precision_score: 0.940677966101695\n",
      "29/29 [==============================] - 0s 722us/step\n",
      "recall_score: 0.9173553719008265\n",
      "29/29 [==============================] - 0s 672us/step\n",
      "f1_score: 0.9288702928870294\n",
      "29/29 [==============================] - 0s 710us/step\n",
      "accuracy_score: 0.9446254071661238\n"
     ]
    }
   ],
   "source": [
    "print_metrics(grid_4, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "3f0237d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'loss': 0.2994946539402008,\n",
       "   'accuracy': 0.8999622464179993,\n",
       "   'val_loss': 0.21188753843307495,\n",
       "   'val_accuracy': 0.9186440706253052,\n",
       "   'lr': 0.01},\n",
       "  {'loss': 0.23529121279716492,\n",
       "   'accuracy': 0.9135522842407227,\n",
       "   'val_loss': 0.20245757699012756,\n",
       "   'val_accuracy': 0.9220339059829712,\n",
       "   'lr': 0.01},\n",
       "  {'loss': 0.23012864589691162,\n",
       "   'accuracy': 0.9218572974205017,\n",
       "   'val_loss': 0.18795499205589294,\n",
       "   'val_accuracy': 0.9288135766983032,\n",
       "   'lr': 0.01},\n",
       "  {'loss': 0.2030031383037567,\n",
       "   'accuracy': 0.9305398464202881,\n",
       "   'val_loss': 0.1840004026889801,\n",
       "   'val_accuracy': 0.9389830231666565,\n",
       "   'lr': 0.01},\n",
       "  {'loss': 0.20093822479248047,\n",
       "   'accuracy': 0.9267648458480835,\n",
       "   'val_loss': 0.18506020307540894,\n",
       "   'val_accuracy': 0.9186440706253052,\n",
       "   'lr': 0.01},\n",
       "  {'loss': 0.21907266974449158,\n",
       "   'accuracy': 0.9218572974205017,\n",
       "   'val_loss': 0.16923581063747406,\n",
       "   'val_accuracy': 0.9423728585243225,\n",
       "   'lr': 0.01},\n",
       "  {'loss': 0.19954131543636322,\n",
       "   'accuracy': 0.9331823587417603,\n",
       "   'val_loss': 0.17253048717975616,\n",
       "   'val_accuracy': 0.9288135766983032,\n",
       "   'lr': 0.01},\n",
       "  {'loss': 0.19970183074474335,\n",
       "   'accuracy': 0.9305398464202881,\n",
       "   'val_loss': 0.18491682410240173,\n",
       "   'val_accuracy': 0.9288135766983032,\n",
       "   'lr': 0.01},\n",
       "  {'loss': 0.1814015656709671,\n",
       "   'accuracy': 0.9373348355293274,\n",
       "   'val_loss': 0.18876126408576965,\n",
       "   'val_accuracy': 0.9254237413406372,\n",
       "   'lr': 0.01},\n",
       "  {'loss': 0.17114467918872833,\n",
       "   'accuracy': 0.9343148469924927,\n",
       "   'val_loss': 0.1755540668964386,\n",
       "   'val_accuracy': 0.9254237413406372,\n",
       "   'lr': 0.005},\n",
       "  {'loss': 0.16998347640037537,\n",
       "   'accuracy': 0.9418648481369019,\n",
       "   'val_loss': 0.18766671419143677,\n",
       "   'val_accuracy': 0.9118643999099731,\n",
       "   'lr': 0.005},\n",
       "  {'loss': 0.16658252477645874,\n",
       "   'accuracy': 0.9392223358154297,\n",
       "   'val_loss': 0.1715678870677948,\n",
       "   'val_accuracy': 0.9389830231666565,\n",
       "   'lr': 0.005},\n",
       "  {'loss': 0.17040550708770752,\n",
       "   'accuracy': 0.9392223358154297,\n",
       "   'val_loss': 0.17244429886341095,\n",
       "   'val_accuracy': 0.9322034120559692,\n",
       "   'lr': 0.005},\n",
       "  {'loss': 0.1516566425561905,\n",
       "   'accuracy': 0.9448848366737366,\n",
       "   'val_loss': 0.16540391743183136,\n",
       "   'val_accuracy': 0.9355932474136353,\n",
       "   'lr': 0.005},\n",
       "  {'loss': 0.1520536243915558,\n",
       "   'accuracy': 0.9460173845291138,\n",
       "   'val_loss': 0.1714872568845749,\n",
       "   'val_accuracy': 0.9288135766983032,\n",
       "   'lr': 0.005},\n",
       "  {'loss': 0.1559392213821411,\n",
       "   'accuracy': 0.9422423839569092,\n",
       "   'val_loss': 0.16088899970054626,\n",
       "   'val_accuracy': 0.9389830231666565,\n",
       "   'lr': 0.005},\n",
       "  {'loss': 0.14865997433662415,\n",
       "   'accuracy': 0.9516798853874207,\n",
       "   'val_loss': 0.1668197214603424,\n",
       "   'val_accuracy': 0.9322034120559692,\n",
       "   'lr': 0.005},\n",
       "  {'loss': 0.145246222615242,\n",
       "   'accuracy': 0.9505473971366882,\n",
       "   'val_loss': 0.16057699918746948,\n",
       "   'val_accuracy': 0.9457626938819885,\n",
       "   'lr': 0.005},\n",
       "  {'loss': 0.14107631146907806,\n",
       "   'accuracy': 0.9539448618888855,\n",
       "   'val_loss': 0.168031245470047,\n",
       "   'val_accuracy': 0.9288135766983032,\n",
       "   'lr': 0.005},\n",
       "  {'loss': 0.14409233629703522,\n",
       "   'accuracy': 0.9456398487091064,\n",
       "   'val_loss': 0.159363254904747,\n",
       "   'val_accuracy': 0.9423728585243225,\n",
       "   'lr': 0.0025},\n",
       "  {'loss': 0.12710152566432953,\n",
       "   'accuracy': 0.9543223977088928,\n",
       "   'val_loss': 0.16041290760040283,\n",
       "   'val_accuracy': 0.9389830231666565,\n",
       "   'lr': 0.0025},\n",
       "  {'loss': 0.1362701952457428,\n",
       "   'accuracy': 0.9505473971366882,\n",
       "   'val_loss': 0.16183334589004517,\n",
       "   'val_accuracy': 0.9355932474136353,\n",
       "   'lr': 0.0025},\n",
       "  {'loss': 0.12579697370529175,\n",
       "   'accuracy': 0.9562098979949951,\n",
       "   'val_loss': 0.16265667974948883,\n",
       "   'val_accuracy': 0.9457626938819885,\n",
       "   'lr': 0.0025},\n",
       "  {'loss': 0.12996284663677216,\n",
       "   'accuracy': 0.9565873742103577,\n",
       "   'val_loss': 0.16305145621299744,\n",
       "   'val_accuracy': 0.9423728585243225,\n",
       "   'lr': 0.0025},\n",
       "  {'loss': 0.13105452060699463,\n",
       "   'accuracy': 0.9520573616027832,\n",
       "   'val_loss': 0.1750330626964569,\n",
       "   'val_accuracy': 0.9288135766983032,\n",
       "   'lr': 0.0025},\n",
       "  {'loss': 0.13792406022548676,\n",
       "   'accuracy': 0.9479048848152161,\n",
       "   'val_loss': 0.16749612987041473,\n",
       "   'val_accuracy': 0.9423728585243225,\n",
       "   'lr': 0.0025},\n",
       "  {'loss': 0.13115465641021729,\n",
       "   'accuracy': 0.9509248733520508,\n",
       "   'val_loss': 0.1681338995695114,\n",
       "   'val_accuracy': 0.9322034120559692,\n",
       "   'lr': 0.0025},\n",
       "  {'loss': 0.12485029548406601,\n",
       "   'accuracy': 0.9573423862457275,\n",
       "   'val_loss': 0.16202254593372345,\n",
       "   'val_accuracy': 0.9389830231666565,\n",
       "   'lr': 0.0025},\n",
       "  {'loss': 0.12787699699401855,\n",
       "   'accuracy': 0.9539448618888855,\n",
       "   'val_loss': 0.16829830408096313,\n",
       "   'val_accuracy': 0.9389830231666565,\n",
       "   'lr': 0.0025},\n",
       "  {'loss': 0.12650762498378754,\n",
       "   'accuracy': 0.9580973982810974,\n",
       "   'val_loss': 0.15714968740940094,\n",
       "   'val_accuracy': 0.9491525292396545,\n",
       "   'lr': 0.00125},\n",
       "  {'loss': 0.11617185920476913,\n",
       "   'accuracy': 0.9592298865318298,\n",
       "   'val_loss': 0.15604983270168304,\n",
       "   'val_accuracy': 0.9389830231666565,\n",
       "   'lr': 0.00125},\n",
       "  {'loss': 0.11816530674695969,\n",
       "   'accuracy': 0.9607399106025696,\n",
       "   'val_loss': 0.1581369936466217,\n",
       "   'val_accuracy': 0.9423728585243225,\n",
       "   'lr': 0.00125},\n",
       "  {'loss': 0.11729387938976288,\n",
       "   'accuracy': 0.95847487449646,\n",
       "   'val_loss': 0.15834161639213562,\n",
       "   'val_accuracy': 0.9423728585243225,\n",
       "   'lr': 0.00125},\n",
       "  {'loss': 0.11832909286022186,\n",
       "   'accuracy': 0.961872398853302,\n",
       "   'val_loss': 0.16300390660762787,\n",
       "   'val_accuracy': 0.9389830231666565,\n",
       "   'lr': 0.00125},\n",
       "  {'loss': 0.1150323674082756,\n",
       "   'accuracy': 0.9596074223518372,\n",
       "   'val_loss': 0.16202127933502197,\n",
       "   'val_accuracy': 0.9389830231666565,\n",
       "   'lr': 0.00125},\n",
       "  {'loss': 0.12476514279842377,\n",
       "   'accuracy': 0.9546998739242554,\n",
       "   'val_loss': 0.16177262365818024,\n",
       "   'val_accuracy': 0.9423728585243225,\n",
       "   'lr': 0.00125},\n",
       "  {'loss': 0.11771368235349655,\n",
       "   'accuracy': 0.9622499346733093,\n",
       "   'val_loss': 0.16234464943408966,\n",
       "   'val_accuracy': 0.9423728585243225,\n",
       "   'lr': 0.00125},\n",
       "  {'loss': 0.10903116315603256,\n",
       "   'accuracy': 0.9611173868179321,\n",
       "   'val_loss': 0.16032955050468445,\n",
       "   'val_accuracy': 0.9457626938819885,\n",
       "   'lr': 0.00125},\n",
       "  {'loss': 0.12019405514001846,\n",
       "   'accuracy': 0.9596074223518372,\n",
       "   'val_loss': 0.16329540312290192,\n",
       "   'val_accuracy': 0.9423728585243225,\n",
       "   'lr': 0.00125},\n",
       "  {'loss': 0.11306104809045792,\n",
       "   'accuracy': 0.961872398853302,\n",
       "   'val_loss': 0.16131576895713806,\n",
       "   'val_accuracy': 0.9389830231666565,\n",
       "   'lr': 0.000625},\n",
       "  {'loss': 0.11764849722385406,\n",
       "   'accuracy': 0.9543223977088928,\n",
       "   'val_loss': 0.1632552295923233,\n",
       "   'val_accuracy': 0.9423728585243225,\n",
       "   'lr': 0.000625}],\n",
       " [{'loss': 0.29421567916870117,\n",
       "   'accuracy': 0.8939222097396851,\n",
       "   'val_loss': 0.2198629081249237,\n",
       "   'val_accuracy': 0.9118643999099731,\n",
       "   'lr': 0.01},\n",
       "  {'loss': 0.21890349686145782,\n",
       "   'accuracy': 0.9218572974205017,\n",
       "   'val_loss': 0.21196381747722626,\n",
       "   'val_accuracy': 0.9220339059829712,\n",
       "   'lr': 0.01},\n",
       "  {'loss': 0.21879799664020538,\n",
       "   'accuracy': 0.9244998097419739,\n",
       "   'val_loss': 0.19879373908042908,\n",
       "   'val_accuracy': 0.9322034120559692,\n",
       "   'lr': 0.01},\n",
       "  {'loss': 0.20054157078266144,\n",
       "   'accuracy': 0.9241223335266113,\n",
       "   'val_loss': 0.20025421679019928,\n",
       "   'val_accuracy': 0.9322034120559692,\n",
       "   'lr': 0.01},\n",
       "  {'loss': 0.1993190050125122,\n",
       "   'accuracy': 0.9248772859573364,\n",
       "   'val_loss': 0.20689666271209717,\n",
       "   'val_accuracy': 0.9288135766983032,\n",
       "   'lr': 0.01},\n",
       "  {'loss': 0.18349848687648773,\n",
       "   'accuracy': 0.9350698590278625,\n",
       "   'val_loss': 0.18854308128356934,\n",
       "   'val_accuracy': 0.9254237413406372,\n",
       "   'lr': 0.01},\n",
       "  {'loss': 0.19691789150238037,\n",
       "   'accuracy': 0.9320498108863831,\n",
       "   'val_loss': 0.21444857120513916,\n",
       "   'val_accuracy': 0.9322034120559692,\n",
       "   'lr': 0.01},\n",
       "  {'loss': 0.17012518644332886,\n",
       "   'accuracy': 0.9346923232078552,\n",
       "   'val_loss': 0.20964036881923676,\n",
       "   'val_accuracy': 0.9288135766983032,\n",
       "   'lr': 0.01},\n",
       "  {'loss': 0.1856042891740799,\n",
       "   'accuracy': 0.9312947988510132,\n",
       "   'val_loss': 0.19387008249759674,\n",
       "   'val_accuracy': 0.9389830231666565,\n",
       "   'lr': 0.01},\n",
       "  {'loss': 0.17010018229484558,\n",
       "   'accuracy': 0.9373348355293274,\n",
       "   'val_loss': 0.21410715579986572,\n",
       "   'val_accuracy': 0.9288135766983032,\n",
       "   'lr': 0.005},\n",
       "  {'loss': 0.16432848572731018,\n",
       "   'accuracy': 0.9343148469924927,\n",
       "   'val_loss': 0.1950114518404007,\n",
       "   'val_accuracy': 0.9389830231666565,\n",
       "   'lr': 0.005},\n",
       "  {'loss': 0.14858676493167877,\n",
       "   'accuracy': 0.9456398487091064,\n",
       "   'val_loss': 0.20526663959026337,\n",
       "   'val_accuracy': 0.9355932474136353,\n",
       "   'lr': 0.005},\n",
       "  {'loss': 0.14601051807403564,\n",
       "   'accuracy': 0.9418648481369019,\n",
       "   'val_loss': 0.20631355047225952,\n",
       "   'val_accuracy': 0.9288135766983032,\n",
       "   'lr': 0.005},\n",
       "  {'loss': 0.14440959692001343,\n",
       "   'accuracy': 0.9520573616027832,\n",
       "   'val_loss': 0.20276018977165222,\n",
       "   'val_accuracy': 0.9389830231666565,\n",
       "   'lr': 0.005},\n",
       "  {'loss': 0.1533140391111374,\n",
       "   'accuracy': 0.9441298842430115,\n",
       "   'val_loss': 0.19296053051948547,\n",
       "   'val_accuracy': 0.9389830231666565,\n",
       "   'lr': 0.005},\n",
       "  {'loss': 0.14234676957130432,\n",
       "   'accuracy': 0.9509248733520508,\n",
       "   'val_loss': 0.19604232907295227,\n",
       "   'val_accuracy': 0.9322034120559692,\n",
       "   'lr': 0.005}],\n",
       " [{'loss': 0.3141915500164032,\n",
       "   'accuracy': 0.8784446716308594,\n",
       "   'val_loss': 0.22481906414031982,\n",
       "   'val_accuracy': 0.9186440706253052,\n",
       "   'lr': 0.01},\n",
       "  {'loss': 0.23528511822223663,\n",
       "   'accuracy': 0.9165722727775574,\n",
       "   'val_loss': 0.2094581127166748,\n",
       "   'val_accuracy': 0.9152542352676392,\n",
       "   'lr': 0.01},\n",
       "  {'loss': 0.23512475192546844,\n",
       "   'accuracy': 0.9131748080253601,\n",
       "   'val_loss': 0.20485888421535492,\n",
       "   'val_accuracy': 0.9186440706253052,\n",
       "   'lr': 0.01},\n",
       "  {'loss': 0.2073431760072708,\n",
       "   'accuracy': 0.9192147850990295,\n",
       "   'val_loss': 0.1861601024866104,\n",
       "   'val_accuracy': 0.9322034120559692,\n",
       "   'lr': 0.01},\n",
       "  {'loss': 0.21873117983341217,\n",
       "   'accuracy': 0.923744797706604,\n",
       "   'val_loss': 0.22836756706237793,\n",
       "   'val_accuracy': 0.9050847291946411,\n",
       "   'lr': 0.01},\n",
       "  {'loss': 0.2051904946565628,\n",
       "   'accuracy': 0.9263873100280762,\n",
       "   'val_loss': 0.1744377762079239,\n",
       "   'val_accuracy': 0.9254237413406372,\n",
       "   'lr': 0.01},\n",
       "  {'loss': 0.21043917536735535,\n",
       "   'accuracy': 0.9214798212051392,\n",
       "   'val_loss': 0.17379286885261536,\n",
       "   'val_accuracy': 0.9322034120559692,\n",
       "   'lr': 0.01},\n",
       "  {'loss': 0.19787748157978058,\n",
       "   'accuracy': 0.9260098338127136,\n",
       "   'val_loss': 0.18359360098838806,\n",
       "   'val_accuracy': 0.9220339059829712,\n",
       "   'lr': 0.01},\n",
       "  {'loss': 0.19551825523376465,\n",
       "   'accuracy': 0.9263873100280762,\n",
       "   'val_loss': 0.21156267821788788,\n",
       "   'val_accuracy': 0.9084745645523071,\n",
       "   'lr': 0.01},\n",
       "  {'loss': 0.1875288337469101,\n",
       "   'accuracy': 0.9316723346710205,\n",
       "   'val_loss': 0.195684552192688,\n",
       "   'val_accuracy': 0.9118643999099731,\n",
       "   'lr': 0.005},\n",
       "  {'loss': 0.17689314484596252,\n",
       "   'accuracy': 0.9358248114585876,\n",
       "   'val_loss': 0.2102135568857193,\n",
       "   'val_accuracy': 0.9152542352676392,\n",
       "   'lr': 0.005},\n",
       "  {'loss': 0.17229856550693512,\n",
       "   'accuracy': 0.9358248114585876,\n",
       "   'val_loss': 0.1804896593093872,\n",
       "   'val_accuracy': 0.9254237413406372,\n",
       "   'lr': 0.005},\n",
       "  {'loss': 0.17508500814437866,\n",
       "   'accuracy': 0.9377123713493347,\n",
       "   'val_loss': 0.18669891357421875,\n",
       "   'val_accuracy': 0.9186440706253052,\n",
       "   'lr': 0.005},\n",
       "  {'loss': 0.17533834278583527,\n",
       "   'accuracy': 0.9331823587417603,\n",
       "   'val_loss': 0.18500709533691406,\n",
       "   'val_accuracy': 0.9118643999099731,\n",
       "   'lr': 0.005},\n",
       "  {'loss': 0.17018695175647736,\n",
       "   'accuracy': 0.9380898475646973,\n",
       "   'val_loss': 0.18954722583293915,\n",
       "   'val_accuracy': 0.9254237413406372,\n",
       "   'lr': 0.005},\n",
       "  {'loss': 0.16469626128673553,\n",
       "   'accuracy': 0.9358248114585876,\n",
       "   'val_loss': 0.18340042233467102,\n",
       "   'val_accuracy': 0.9254237413406372,\n",
       "   'lr': 0.005},\n",
       "  {'loss': 0.1679757982492447,\n",
       "   'accuracy': 0.9422423839569092,\n",
       "   'val_loss': 0.17585574090480804,\n",
       "   'val_accuracy': 0.9220339059829712,\n",
       "   'lr': 0.005}],\n",
       " [{'loss': 0.3057178854942322,\n",
       "   'accuracy': 0.8897697329521179,\n",
       "   'val_loss': 0.20530197024345398,\n",
       "   'val_accuracy': 0.9220339059829712,\n",
       "   'lr': 0.01},\n",
       "  {'loss': 0.2447485625743866,\n",
       "   'accuracy': 0.9120422601699829,\n",
       "   'val_loss': 0.206316739320755,\n",
       "   'val_accuracy': 0.9118643999099731,\n",
       "   'lr': 0.01},\n",
       "  {'loss': 0.22106143832206726,\n",
       "   'accuracy': 0.9214798212051392,\n",
       "   'val_loss': 0.18535885214805603,\n",
       "   'val_accuracy': 0.9220339059829712,\n",
       "   'lr': 0.01},\n",
       "  {'loss': 0.21194779872894287,\n",
       "   'accuracy': 0.9180822968482971,\n",
       "   'val_loss': 0.2071913629770279,\n",
       "   'val_accuracy': 0.9220339059829712,\n",
       "   'lr': 0.01},\n",
       "  {'loss': 0.21121267974376678,\n",
       "   'accuracy': 0.9233673214912415,\n",
       "   'val_loss': 0.230230450630188,\n",
       "   'val_accuracy': 0.9186440706253052,\n",
       "   'lr': 0.01},\n",
       "  {'loss': 0.1925651729106903,\n",
       "   'accuracy': 0.9309173226356506,\n",
       "   'val_loss': 0.17513932287693024,\n",
       "   'val_accuracy': 0.9322034120559692,\n",
       "   'lr': 0.01},\n",
       "  {'loss': 0.20379778742790222,\n",
       "   'accuracy': 0.923744797706604,\n",
       "   'val_loss': 0.19173899292945862,\n",
       "   'val_accuracy': 0.9254237413406372,\n",
       "   'lr': 0.01},\n",
       "  {'loss': 0.18316522240638733,\n",
       "   'accuracy': 0.9328048229217529,\n",
       "   'val_loss': 0.19430530071258545,\n",
       "   'val_accuracy': 0.9186440706253052,\n",
       "   'lr': 0.01},\n",
       "  {'loss': 0.19208258390426636,\n",
       "   'accuracy': 0.9241223335266113,\n",
       "   'val_loss': 0.19323593378067017,\n",
       "   'val_accuracy': 0.9288135766983032,\n",
       "   'lr': 0.01},\n",
       "  {'loss': 0.17413084208965302,\n",
       "   'accuracy': 0.9335598349571228,\n",
       "   'val_loss': 0.1847991943359375,\n",
       "   'val_accuracy': 0.9254237413406372,\n",
       "   'lr': 0.005},\n",
       "  {'loss': 0.16504769027233124,\n",
       "   'accuracy': 0.9365798234939575,\n",
       "   'val_loss': 0.18183131515979767,\n",
       "   'val_accuracy': 0.9355932474136353,\n",
       "   'lr': 0.005},\n",
       "  {'loss': 0.1694091409444809,\n",
       "   'accuracy': 0.9377123713493347,\n",
       "   'val_loss': 0.17691819369792938,\n",
       "   'val_accuracy': 0.9423728585243225,\n",
       "   'lr': 0.005},\n",
       "  {'loss': 0.16423745453357697,\n",
       "   'accuracy': 0.9373348355293274,\n",
       "   'val_loss': 0.17780502140522003,\n",
       "   'val_accuracy': 0.9355932474136353,\n",
       "   'lr': 0.005},\n",
       "  {'loss': 0.16714324057102203,\n",
       "   'accuracy': 0.9392223358154297,\n",
       "   'val_loss': 0.1775139570236206,\n",
       "   'val_accuracy': 0.9389830231666565,\n",
       "   'lr': 0.005},\n",
       "  {'loss': 0.15523594617843628,\n",
       "   'accuracy': 0.9433748722076416,\n",
       "   'val_loss': 0.18397760391235352,\n",
       "   'val_accuracy': 0.9355932474136353,\n",
       "   'lr': 0.005},\n",
       "  {'loss': 0.1555301398038864,\n",
       "   'accuracy': 0.9414873719215393,\n",
       "   'val_loss': 0.19488736987113953,\n",
       "   'val_accuracy': 0.9288135766983032,\n",
       "   'lr': 0.005}],\n",
       " [{'loss': 0.31555840373039246,\n",
       "   'accuracy': 0.8833522200584412,\n",
       "   'val_loss': 0.22769786417484283,\n",
       "   'val_accuracy': 0.9050847291946411,\n",
       "   'lr': 0.01},\n",
       "  {'loss': 0.255009263753891,\n",
       "   'accuracy': 0.9048697352409363,\n",
       "   'val_loss': 0.22964756190776825,\n",
       "   'val_accuracy': 0.9254237413406372,\n",
       "   'lr': 0.01},\n",
       "  {'loss': 0.2298191338777542,\n",
       "   'accuracy': 0.9124197959899902,\n",
       "   'val_loss': 0.24961094558238983,\n",
       "   'val_accuracy': 0.9118643999099731,\n",
       "   'lr': 0.01},\n",
       "  {'loss': 0.21927987039089203,\n",
       "   'accuracy': 0.9165722727775574,\n",
       "   'val_loss': 0.19763527810573578,\n",
       "   'val_accuracy': 0.9152542352676392,\n",
       "   'lr': 0.01},\n",
       "  {'loss': 0.20935502648353577,\n",
       "   'accuracy': 0.9233673214912415,\n",
       "   'val_loss': 0.19463583827018738,\n",
       "   'val_accuracy': 0.9186440706253052,\n",
       "   'lr': 0.01},\n",
       "  {'loss': 0.20578739047050476,\n",
       "   'accuracy': 0.9252548217773438,\n",
       "   'val_loss': 0.1918322890996933,\n",
       "   'val_accuracy': 0.9186440706253052,\n",
       "   'lr': 0.01},\n",
       "  {'loss': 0.20575681328773499,\n",
       "   'accuracy': 0.9226123094558716,\n",
       "   'val_loss': 0.18842041492462158,\n",
       "   'val_accuracy': 0.9220339059829712,\n",
       "   'lr': 0.01},\n",
       "  {'loss': 0.20282404124736786,\n",
       "   'accuracy': 0.9229897856712341,\n",
       "   'val_loss': 0.19540464878082275,\n",
       "   'val_accuracy': 0.9118643999099731,\n",
       "   'lr': 0.01},\n",
       "  {'loss': 0.1964198350906372,\n",
       "   'accuracy': 0.9199697971343994,\n",
       "   'val_loss': 0.19965270161628723,\n",
       "   'val_accuracy': 0.9288135766983032,\n",
       "   'lr': 0.01},\n",
       "  {'loss': 0.19079327583312988,\n",
       "   'accuracy': 0.9290298223495483,\n",
       "   'val_loss': 0.19247007369995117,\n",
       "   'val_accuracy': 0.9220339059829712,\n",
       "   'lr': 0.005},\n",
       "  {'loss': 0.17682577669620514,\n",
       "   'accuracy': 0.9346923232078552,\n",
       "   'val_loss': 0.19628475606441498,\n",
       "   'val_accuracy': 0.9152542352676392,\n",
       "   'lr': 0.005},\n",
       "  {'loss': 0.16254578530788422,\n",
       "   'accuracy': 0.9380898475646973,\n",
       "   'val_loss': 0.18945512175559998,\n",
       "   'val_accuracy': 0.9254237413406372,\n",
       "   'lr': 0.005},\n",
       "  {'loss': 0.17310042679309845,\n",
       "   'accuracy': 0.9350698590278625,\n",
       "   'val_loss': 0.18189413845539093,\n",
       "   'val_accuracy': 0.9389830231666565,\n",
       "   'lr': 0.005},\n",
       "  {'loss': 0.15748265385627747,\n",
       "   'accuracy': 0.9426198601722717,\n",
       "   'val_loss': 0.18408970534801483,\n",
       "   'val_accuracy': 0.9220339059829712,\n",
       "   'lr': 0.005},\n",
       "  {'loss': 0.14884118735790253,\n",
       "   'accuracy': 0.9456398487091064,\n",
       "   'val_loss': 0.1937042474746704,\n",
       "   'val_accuracy': 0.9220339059829712,\n",
       "   'lr': 0.005},\n",
       "  {'loss': 0.15801115334033966,\n",
       "   'accuracy': 0.9407323598861694,\n",
       "   'val_loss': 0.20475439727306366,\n",
       "   'val_accuracy': 0.9118643999099731,\n",
       "   'lr': 0.005},\n",
       "  {'loss': 0.161525160074234,\n",
       "   'accuracy': 0.9441298842430115,\n",
       "   'val_loss': 0.18839913606643677,\n",
       "   'val_accuracy': 0.9186440706253052,\n",
       "   'lr': 0.005},\n",
       "  {'loss': 0.165445014834404,\n",
       "   'accuracy': 0.9369573593139648,\n",
       "   'val_loss': 0.1965041607618332,\n",
       "   'val_accuracy': 0.9152542352676392,\n",
       "   'lr': 0.005},\n",
       "  {'loss': 0.16197849810123444,\n",
       "   'accuracy': 0.9380898475646973,\n",
       "   'val_loss': 0.18989060819149017,\n",
       "   'val_accuracy': 0.9322034120559692,\n",
       "   'lr': 0.005},\n",
       "  {'loss': 0.1488182693719864,\n",
       "   'accuracy': 0.944507360458374,\n",
       "   'val_loss': 0.18859699368476868,\n",
       "   'val_accuracy': 0.9288135766983032,\n",
       "   'lr': 0.0025},\n",
       "  {'loss': 0.15514414012432098,\n",
       "   'accuracy': 0.9426198601722717,\n",
       "   'val_loss': 0.18495257198810577,\n",
       "   'val_accuracy': 0.9288135766983032,\n",
       "   'lr': 0.0025},\n",
       "  {'loss': 0.1444556713104248,\n",
       "   'accuracy': 0.9516798853874207,\n",
       "   'val_loss': 0.18798629939556122,\n",
       "   'val_accuracy': 0.9322034120559692,\n",
       "   'lr': 0.0025},\n",
       "  {'loss': 0.13950085639953613,\n",
       "   'accuracy': 0.949414849281311,\n",
       "   'val_loss': 0.18540313839912415,\n",
       "   'val_accuracy': 0.9322034120559692,\n",
       "   'lr': 0.0025}],\n",
       " [{'loss': 0.2743266522884369,\n",
       "   'accuracy': 0.9003623127937317,\n",
       "   'val_loss': 0.22305625677108765,\n",
       "   'val_accuracy': 0.904891312122345,\n",
       "   'lr': 0.01},\n",
       "  {'loss': 0.23344683647155762,\n",
       "   'accuracy': 0.9097222089767456,\n",
       "   'val_loss': 0.20374849438667297,\n",
       "   'val_accuracy': 0.9103260636329651,\n",
       "   'lr': 0.01},\n",
       "  {'loss': 0.22034946084022522,\n",
       "   'accuracy': 0.9154589176177979,\n",
       "   'val_loss': 0.1874709278345108,\n",
       "   'val_accuracy': 0.929347813129425,\n",
       "   'lr': 0.01},\n",
       "  {'loss': 0.22114945948123932,\n",
       "   'accuracy': 0.916968584060669,\n",
       "   'val_loss': 0.19606192409992218,\n",
       "   'val_accuracy': 0.91847825050354,\n",
       "   'lr': 0.01},\n",
       "  {'loss': 0.2065146416425705,\n",
       "   'accuracy': 0.9257246255874634,\n",
       "   'val_loss': 0.1807519644498825,\n",
       "   'val_accuracy': 0.926630437374115,\n",
       "   'lr': 0.01},\n",
       "  {'loss': 0.198358416557312,\n",
       "   'accuracy': 0.9287439584732056,\n",
       "   'val_loss': 0.18139152228832245,\n",
       "   'val_accuracy': 0.9211956262588501,\n",
       "   'lr': 0.01},\n",
       "  {'loss': 0.19619262218475342,\n",
       "   'accuracy': 0.9308574795722961,\n",
       "   'val_loss': 0.19484849274158478,\n",
       "   'val_accuracy': 0.9239130616188049,\n",
       "   'lr': 0.01},\n",
       "  {'loss': 0.19575634598731995,\n",
       "   'accuracy': 0.9284420013427734,\n",
       "   'val_loss': 0.2034732848405838,\n",
       "   'val_accuracy': 0.91847825050354,\n",
       "   'lr': 0.01},\n",
       "  {'loss': 0.1959332972764969,\n",
       "   'accuracy': 0.927838146686554,\n",
       "   'val_loss': 0.19150899350643158,\n",
       "   'val_accuracy': 0.91847825050354,\n",
       "   'lr': 0.01},\n",
       "  {'loss': 0.17870184779167175,\n",
       "   'accuracy': 0.9332729578018188,\n",
       "   'val_loss': 0.19263432919979095,\n",
       "   'val_accuracy': 0.9211956262588501,\n",
       "   'lr': 0.005},\n",
       "  {'loss': 0.17932087182998657,\n",
       "   'accuracy': 0.9371980428695679,\n",
       "   'val_loss': 0.1898985058069229,\n",
       "   'val_accuracy': 0.926630437374115,\n",
       "   'lr': 0.005},\n",
       "  {'loss': 0.167023703455925,\n",
       "   'accuracy': 0.9408212304115295,\n",
       "   'val_loss': 0.1834680140018463,\n",
       "   'val_accuracy': 0.9211956262588501,\n",
       "   'lr': 0.005},\n",
       "  {'loss': 0.16024567186832428,\n",
       "   'accuracy': 0.9396135210990906,\n",
       "   'val_loss': 0.18044136464595795,\n",
       "   'val_accuracy': 0.9239130616188049,\n",
       "   'lr': 0.005},\n",
       "  {'loss': 0.16820308566093445,\n",
       "   'accuracy': 0.9344806671142578,\n",
       "   'val_loss': 0.1853550225496292,\n",
       "   'val_accuracy': 0.91576087474823,\n",
       "   'lr': 0.005},\n",
       "  {'loss': 0.16249242424964905,\n",
       "   'accuracy': 0.9423308968544006,\n",
       "   'val_loss': 0.18850164115428925,\n",
       "   'val_accuracy': 0.929347813129425,\n",
       "   'lr': 0.005},\n",
       "  {'loss': 0.16255803406238556,\n",
       "   'accuracy': 0.9414251446723938,\n",
       "   'val_loss': 0.1945507824420929,\n",
       "   'val_accuracy': 0.91847825050354,\n",
       "   'lr': 0.005},\n",
       "  {'loss': 0.16759507358074188,\n",
       "   'accuracy': 0.9396135210990906,\n",
       "   'val_loss': 0.1855754256248474,\n",
       "   'val_accuracy': 0.929347813129425,\n",
       "   'lr': 0.005},\n",
       "  {'loss': 0.1570262759923935,\n",
       "   'accuracy': 0.9429348111152649,\n",
       "   'val_loss': 0.1806175857782364,\n",
       "   'val_accuracy': 0.926630437374115,\n",
       "   'lr': 0.005},\n",
       "  {'loss': 0.15735748410224915,\n",
       "   'accuracy': 0.9426328539848328,\n",
       "   'val_loss': 0.17844490706920624,\n",
       "   'val_accuracy': 0.9211956262588501,\n",
       "   'lr': 0.005},\n",
       "  {'loss': 0.14677157998085022,\n",
       "   'accuracy': 0.948369562625885,\n",
       "   'val_loss': 0.17365004122257233,\n",
       "   'val_accuracy': 0.929347813129425,\n",
       "   'lr': 0.0025},\n",
       "  {'loss': 0.1441061794757843,\n",
       "   'accuracy': 0.948369562625885,\n",
       "   'val_loss': 0.16929219663143158,\n",
       "   'val_accuracy': 0.9375,\n",
       "   'lr': 0.0025},\n",
       "  {'loss': 0.13711118698120117,\n",
       "   'accuracy': 0.9525966048240662,\n",
       "   'val_loss': 0.17771084606647491,\n",
       "   'val_accuracy': 0.9347826242446899,\n",
       "   'lr': 0.0025},\n",
       "  {'loss': 0.14436133205890656,\n",
       "   'accuracy': 0.9489734172821045,\n",
       "   'val_loss': 0.2008286565542221,\n",
       "   'val_accuracy': 0.9103260636329651,\n",
       "   'lr': 0.0025},\n",
       "  {'loss': 0.14906375110149384,\n",
       "   'accuracy': 0.9447463750839233,\n",
       "   'val_loss': 0.16589413583278656,\n",
       "   'val_accuracy': 0.9347826242446899,\n",
       "   'lr': 0.0025},\n",
       "  {'loss': 0.13586227595806122,\n",
       "   'accuracy': 0.9556159377098083,\n",
       "   'val_loss': 0.1802258938550949,\n",
       "   'val_accuracy': 0.9320651888847351,\n",
       "   'lr': 0.0025},\n",
       "  {'loss': 0.14418524503707886,\n",
       "   'accuracy': 0.9504830837249756,\n",
       "   'val_loss': 0.17280469834804535,\n",
       "   'val_accuracy': 0.9347826242446899,\n",
       "   'lr': 0.0025},\n",
       "  {'loss': 0.15127745270729065,\n",
       "   'accuracy': 0.9486715197563171,\n",
       "   'val_loss': 0.18138380348682404,\n",
       "   'val_accuracy': 0.9320651888847351,\n",
       "   'lr': 0.0025},\n",
       "  {'loss': 0.13944236934185028,\n",
       "   'accuracy': 0.9525966048240662,\n",
       "   'val_loss': 0.17058850824832916,\n",
       "   'val_accuracy': 0.9347826242446899,\n",
       "   'lr': 0.0025},\n",
       "  {'loss': 0.1327926218509674,\n",
       "   'accuracy': 0.9510869383811951,\n",
       "   'val_loss': 0.17321819067001343,\n",
       "   'val_accuracy': 0.9347826242446899,\n",
       "   'lr': 0.0025},\n",
       "  {'loss': 0.12651903927326202,\n",
       "   'accuracy': 0.9525966048240662,\n",
       "   'val_loss': 0.17080406844615936,\n",
       "   'val_accuracy': 0.9375,\n",
       "   'lr': 0.00125},\n",
       "  {'loss': 0.14757879078388214,\n",
       "   'accuracy': 0.9489734172821045,\n",
       "   'val_loss': 0.17375603318214417,\n",
       "   'val_accuracy': 0.9347826242446899,\n",
       "   'lr': 0.00125},\n",
       "  {'loss': 0.12766142189502716,\n",
       "   'accuracy': 0.9562197923660278,\n",
       "   'val_loss': 0.17653074860572815,\n",
       "   'val_accuracy': 0.9347826242446899,\n",
       "   'lr': 0.00125},\n",
       "  {'loss': 0.12334372103214264,\n",
       "   'accuracy': 0.95652174949646,\n",
       "   'val_loss': 0.17594410479068756,\n",
       "   'val_accuracy': 0.9347826242446899,\n",
       "   'lr': 0.00125},\n",
       "  {'loss': 0.13159193098545074,\n",
       "   'accuracy': 0.9535024166107178,\n",
       "   'val_loss': 0.1774468570947647,\n",
       "   'val_accuracy': 0.9347826242446899,\n",
       "   'lr': 0.00125}]]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_histories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "0abb158e",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_history = training_histories[grid_4.best_index_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "8f1fa6dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(learning_history).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1)\n",
    "plt.show()\n",
    "\n",
    "# print(learning_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc26716",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
